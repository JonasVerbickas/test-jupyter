{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "17LEN96rLy13y9e32ceU_O0XiEURgcrVQ",
      "authorship_tag": "ABX9TyM5IyOSZhyL/sETRaJ1AjI/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonasVerbickas/test-jupyter/blob/main/NLP_CW2_Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvI835jinwKk"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import torch\n",
        "import os\n",
        "import re\n",
        "import collections\n",
        "import random\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "porter = nltk.PorterStemmer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2oxf4e9pDRj",
        "outputId": "fbf5e16f-0b3c-462e-af6a-82b37773d27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_REVIEWS = \"/content/drive/MyDrive/Colab Notebooks/product_reviews\""
      ],
      "metadata": {
        "id": "gqPx_Zhjn_Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_contents = \"\"\n",
        "for filename in os.listdir(PATH_TO_REVIEWS):\n",
        "  # skip readme\n",
        "  if filename == 'README.txt':\n",
        "    continue\n",
        "  # append contents of other files to file_contents string\n",
        "  starting_corpus_size = len(file_contents)\n",
        "  with open(os.path.join(PATH_TO_REVIEWS, filename)) as f:\n",
        "    file_contents += f.read()\n",
        "  print(\"After appending\", filename, \"corpus sized increased to\", starting_corpus_size, \"->\", len(file_contents))"
      ],
      "metadata": {
        "id": "HxJBU3SlolFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aaa935a-9414-48e5-b11b-a0e13da7883a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After appending Nokia_6600.txt corpus sized increased to 0 -> 56093\n",
            "After appending norton.txt corpus sized increased to 56093 -> 95013\n",
            "After appending Linksys_Router.txt corpus sized increased to 95013 -> 151947\n",
            "After appending MicroMP3.txt corpus sized increased to 151947 -> 259727\n",
            "After appending Diaper_Champ.txt corpus sized increased to 259727 -> 294831\n",
            "After appending Hitachi_router.txt corpus sized increased to 294831 -> 325078\n",
            "After appending Canon_S100.txt corpus sized increased to 325078 -> 353887\n",
            "After appending Canon_PowerShot_SD500.txt corpus sized increased to 353887 -> 378520\n",
            "After appending ipod.txt corpus sized increased to 378520 -> 436566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_sentences = nltk.tokenize.sent_tokenize(file_contents)\n",
        "list_of_sentences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1MNbAJnh2mL",
        "outputId": "f02d9fed-8f8d-4bf8-ea25-2d6f96260c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"[t]\\nphone[+3][u]##I've had this beauty for nearly 2 months now and I truely love it.\",\n",
              " 'battery life[-2]##The only disappointment so far has been battery life.',\n",
              " \"battery life[-2][u]##Mine generally requires a charege every 48 hours or so and I don't really talk on it that much.\",\n",
              " '##Why is this phone so great?',\n",
              " '##Simple.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preprocessing\n"
      ],
      "metadata": {
        "id": "XPQIVJVR3bgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def textPreprocessing(list_of_sentences):\n",
        "  output = []\n",
        "  for text_as_string in list_of_sentences:\n",
        "    processed_sentence = []\n",
        "    case_folded = text_as_string.casefold()\n",
        "    tokenized = nltk.tokenize.word_tokenize(case_folded)\n",
        "    for token in tokenized:\n",
        "      if token in nltk.corpus.stopwords.words('english'):\n",
        "        continue\n",
        "      # if token doesn't contain alphanumeric characters\n",
        "      if re.match('^\\W+$', token):\n",
        "        continue\n",
        "      # if token is encodes semantic information\n",
        "      if re.match('^[+-]\\d$', token):\n",
        "        continue\n",
        "      stemmed = porter.stem(token)\n",
        "      processed_sentence.append(stemmed)\n",
        "    output.append(processed_sentence)\n",
        "  return output"
      ],
      "metadata": {
        "id": "3QFP7EDPwif2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_and_preprocessed = textPreprocessing(list_of_sentences)\n",
        "tokenized_and_preprocessed[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhnXHvIprKnb",
        "outputId": "8b0175a1-08c7-450f-8235-9bc88c91e75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['phone', 'u', \"'ve\", 'beauti', 'nearli', '2', 'month', 'trueli', 'love'],\n",
              " ['batteri', 'life', 'disappoint', 'far', 'batteri', 'life'],\n",
              " ['batteri',\n",
              "  'life',\n",
              "  'u',\n",
              "  'mine',\n",
              "  'gener',\n",
              "  'requir',\n",
              "  'chareg',\n",
              "  'everi',\n",
              "  '48',\n",
              "  'hour',\n",
              "  \"n't\",\n",
              "  'realli',\n",
              "  'talk',\n",
              "  'much'],\n",
              " ['phone', 'great'],\n",
              " ['simpl']]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Pseudowords"
      ],
      "metadata": {
        "id": "nkY5sKxy3iqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getTop50Words(list_of_tokenized_sentences):\n",
        "  # unwrap the sublists\n",
        "  list_of_all_tokens = [token for sent in list_of_tokenized_sentences for token in sent]\n",
        "  top_50_tokens = collections.Counter(list_of_all_tokens).most_common()[:50]\n",
        "  # top_50_tokens has a format of ('word', number_of_occurances)\n",
        "  # in our case we only need to check if tokens match and don't need the number of occurances\n",
        "  top_50_without_freq = [t[0] for t in top_50_tokens]\n",
        "  return top_50_without_freq"
      ],
      "metadata": {
        "id": "jx4POw-7yC1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceTopWordsWithPseudo(list_of_tokenized_sentences, top_50_without_freq):\n",
        "  output = []\n",
        "  for list_of_tokenized_words in list_of_tokenized_sentences:\n",
        "    pseudoworded_sentence = []\n",
        "    for token in list_of_tokenized_words:\n",
        "      if token not in top_50_without_freq:\n",
        "        continue\n",
        "      # reverse 50% of occurances\n",
        "      if random.uniform(0, 1) > 0.5:\n",
        "        pseudoworded_sentence.append(token[::-1])\n",
        "      else:\n",
        "        pseudoworded_sentence.append(token)\n",
        "    if len(pseudoworded_sentence) > 0:\n",
        "      output.append(pseudoworded_sentence)\n",
        "  return output\n",
        "      "
      ],
      "metadata": {
        "id": "OAy8YHjx4F8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_50_words = getTop50Words(tokenized_and_preprocessed)\n",
        "top_50_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cb70EVyy5Ap",
        "outputId": "8b6c520c-6a15-46e6-d471-3bf46e5caec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['use',\n",
              " \"n't\",\n",
              " \"'s\",\n",
              " 'phone',\n",
              " 'u',\n",
              " 'router',\n",
              " 'one',\n",
              " 'get',\n",
              " 'ipod',\n",
              " 'camera',\n",
              " 'player',\n",
              " 'work',\n",
              " 'batteri',\n",
              " 'diaper',\n",
              " 'like',\n",
              " 'product',\n",
              " 'great',\n",
              " 'time',\n",
              " 'featur',\n",
              " 'problem',\n",
              " 'good',\n",
              " 'would',\n",
              " 'look',\n",
              " 'zen',\n",
              " 'qualiti',\n",
              " \"'ve\",\n",
              " 'instal',\n",
              " 'also',\n",
              " 'sound',\n",
              " 'take',\n",
              " 'need',\n",
              " 'softwar',\n",
              " 'comput',\n",
              " 'pictur',\n",
              " 'want',\n",
              " 'realli',\n",
              " 'micro',\n",
              " 'go',\n",
              " 'well',\n",
              " 'even',\n",
              " 'thing',\n",
              " 'easi',\n",
              " 'buy',\n",
              " \"'m\",\n",
              " 'creativ',\n",
              " 'first',\n",
              " 'review',\n",
              " 'make',\n",
              " 'much',\n",
              " 'bag']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "half_replaced_with_pseudo = replaceTopWordsWithPseudo(tokenized_and_preprocessed,\n",
        "                                                      top_50_words)\n",
        "half_replaced_with_pseudo[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxuyXpj2yHKq",
        "outputId": "4b8e9786-b9f9-430d-9239-3812a7492812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['enohp', 'u', \"'ve\"],\n",
              " ['batteri', 'batteri'],\n",
              " ['batteri', 'u', \"n't\", 'illaer', 'much'],\n",
              " ['phone', 'taerg'],\n",
              " ['phone']]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. D-dimensional vector to encode top 50"
      ],
      "metadata": {
        "id": "ECmKLC3k7fkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model = Word2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=2)"
      ],
      "metadata": {
        "id": "PsiO1PUrp8LQ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.build_vocab(half_replaced_with_pseudo, progress_per=10000)"
      ],
      "metadata": {
        "id": "P_N7qpqtrqdA"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.train(half_replaced_with_pseudo, total_examples=w2v_model.corpus_count, epochs=1000, report_delay=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWbRNPgDryWV",
        "outputId": "02546e38-f556-4889-c43a-37f14931b7b6"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(830583, 10296000)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare model for inference\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "metadata": {
        "id": "BJ75pk5yr7bG"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model.wv.most_similar(positive=[\"batteri\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSmr9EA_sLL6",
        "outputId": "68b55919-d26b-4be2-b132-92cc64262ab5"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('irettab', 0.9293215274810791),\n",
              " (\"s'\", 0.8212628364562988),\n",
              " ('og', 0.81708824634552),\n",
              " ('one', 0.7709792852401733),\n",
              " ('doog', 0.769716739654541),\n",
              " ('reyalp', 0.7568912506103516),\n",
              " (\"m'\", 0.7543979287147522),\n",
              " ('rutaef', 0.750193178653717),\n",
              " ('dluow', 0.746510922908783),\n",
              " ('much', 0.7316174507141113)]"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Apply clustering"
      ],
      "metadata": {
        "id": "zE0UFtz-2KIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClustererWrapper:\n",
        "  def __init__(self, cluster_fn, classify_fn):\n",
        "    self.cluster_fn = cluster_fn\n",
        "    self.classify_fn = classify_fn"
      ],
      "metadata": {
        "id": "otfIC8Av4wWA"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testClusteringAlgo(matrix, clusterer):\n",
        "  clusterer.cluster_fn(matrix)\n",
        "  correct_clusterings = 0\n",
        "  incorrect_clusterings = 0\n",
        "  for word in top_50_words:\n",
        "    pseudoword = word[::-1]\n",
        "    word_vector = w2v_model.wv[word]\n",
        "    pseudoword_vector = w2v_model.wv[pseudoword] \n",
        "    word_class = clusterer.classify_fn(word_vector)\n",
        "    pseudoword_class = clusterer.classify_fn(pseudoword_vector)\n",
        "    if word_class == pseudoword_class:\n",
        "      correct_clusterings += 1\n",
        "    else:\n",
        "      print(\"Incorrectly classified:\")\n",
        "      incorrect_clusterings += 1\n",
        "    \n",
        "  print(\"correct_clusterings\", correct_clusterings)\n",
        "  print(\"incorrect_clusterings\", incorrect_clusterings)"
      ],
      "metadata": {
        "id": "JjtzNn6h4HpC"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = [] \n",
        "for word in top_50_words:\n",
        "  matrix.append(w2v_model.wv[word])\n",
        "  matrix.append(w2v_model.wv[word[::-1]])"
      ],
      "metadata": {
        "id": "9ke3SsBAsN20"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Check whether word and its corresponding pseudoword are grouped together"
      ],
      "metadata": {
        "id": "AcY9PyGE2O2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clusterer = nltk.cluster.KMeansClusterer(2, nltk.cluster.euclidean_distance, avoid_empty_clusters=True)\n",
        "wrapped_clusterer = ClustererWrapper(cluster_fn=lambda matrix: clusterer.cluster(matrix, True),\n",
        "                                     classify_fn=lambda word: clusterer.classify(word))\n",
        "testClusteringAlgo(matrix, wrapped_clusterer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsAZICEo0pXP",
        "outputId": "6818460b-0d00-4859-8f84-ed04f47ee125"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct_clusterings 47\n",
            "incorrect_clusterings 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-6CL3cBP4WqW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}