{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonasVerbickas/test-jupyter/blob/main/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import time\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "from collections import UserDict\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "BTTGCTeE65K-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A59xTdZA0OzU",
        "outputId": "2f10bf22-b4ea-49f6-e432-ed4f190c61cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter = nltk.PorterStemmer()"
      ],
      "metadata": {
        "id": "9Kh-pY5D8H1e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXosFc5y2vyH",
        "outputId": "965da312-c121-4309-b0f3-5604bca2f69c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StringWithDocId:\n",
        "  def __init__(self, string, doc_id):\n",
        "    self.string = string\n",
        "    self.doc_id = doc_id\n",
        "  \n",
        "  def __lt__(token_with_doc_A, token_with_doc_B):\n",
        "    if token_with_doc_A.string == token_with_doc_B.string:\n",
        "      return token_with_doc_A.doc_id < token_with_doc_B.doc_id\n",
        "    else:\n",
        "      return token_with_doc_A.string < token_with_doc_B.string\n",
        "    \n",
        "  def __str__(self):\n",
        "    return f\"{self.string}: {self.doc_id}\"\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"{self.string}: {self.doc_id}\""
      ],
      "metadata": {
        "id": "P_X_2vKt8lbK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StringWithDocIdAndPosition(StringWithDocId):\n",
        "  def __init__(self, string, doc_id, position):\n",
        "    super().__init__(string, doc_id)\n",
        "    self.position = position\n",
        "  \n",
        "  def __lt__(token_with_doc_A, token_with_doc_B):\n",
        "    if token_with_doc_A.string != token_with_doc_B.string:\n",
        "      return token_with_doc_A.string < token_with_doc_B.string\n",
        "    elif token_with_doc_A.doc_id != token_with_doc_B.doc_id:\n",
        "      return token_with_doc_A.doc_id < token_with_doc_B.doc_id\n",
        "    else:\n",
        "      return token_with_doc_A.position < token_with_doc_B.position"
      ],
      "metadata": {
        "id": "XSBSe0-PxlCV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Posting(UserDict):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.posting_dic = {}\n",
        "    self.total_occurances = 0\n",
        "  \n",
        "  def __contains__(self, doc_id):\n",
        "    return doc_id in self.posting_dic\n",
        "  \n",
        "  def __iter__(self):\n",
        "      return iter(self.posting_dic.items())\n",
        "\n",
        "  def __getitem__(self, doc_id):\n",
        "      return self.posting_dic[doc_id]\n",
        "    \n",
        "  def get(self, k, default=None):\n",
        "    return self[k]\n",
        "  \n",
        "  def __len__(self):\n",
        "      return len(self.posting_dic)\n",
        "\n",
        "  def add(self, doc_id, position):\n",
        "    if doc_id in self.posting_dic:\n",
        "      self.posting_dic[doc_id].append(position)\n",
        "    else:\n",
        "      self.posting_dic[doc_id] = [position]\n",
        "    self.total_occurances += 1\n",
        "  \n",
        "  def __str__(self):\n",
        "    return f\"{self.total_occurances} total occurances: {[f'{len(positions)} in {doc_id}: {positions}' for doc_id, positions in self.posting_dic.items()]}\"\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return str(self)"
      ],
      "metadata": {
        "id": "1Ts7G2B6TGRX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wikipediaPreprocessing(text):\n",
        "  text = unicodedata.normalize('NFKC', text)\n",
        "  text = text.replace('\\n', '')\n",
        "  text = re.sub(r'\\[.*?\\]+', '', text)\n",
        "  text = re.sub(r'Contents\\s+1\\s+Plot.+Plot', '', text) \n",
        "  text = re.sub(r'^.+From Wikipedia, the free encyclopedia.+List of episodes', '', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "gpJRsN2bk5Iw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4WtSmBsrzqE7"
      },
      "outputs": [],
      "source": [
        "STOP_WORDS = nltk.corpus.stopwords.words('english')\n",
        "class InvertedIndex:\n",
        "    \"\"\"\n",
        "    Construct Inverted Index\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.inverted_index = {}\n",
        "        self.csv_terms = set()\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self.inverted_index[key]\n",
        "      \n",
        "    def keys(self):\n",
        "      return self.inverted_index.keys()\n",
        "\n",
        "    # def appendCSV(self, path):\n",
        "    #   df = pd.read_csv(path)\n",
        "    #   set_of_csv_entries = df['name']\n",
        "    #   # for term in df['name']\n",
        "    #   processed_csv_entries = self.processListOfTokens(set_of_csv_entries)\n",
        "    #   # remove any duplicate entries\n",
        "    #   print(processed_csv_entries[:10])\n",
        "    #   without_duplicates = set(processed_csv_entries)\n",
        "    #   self.csv_terms = self.csv_terms.union(without_duplicates)\n",
        "\n",
        "    def read_data(self, path: str) -> list:\n",
        "        \"\"\"\n",
        "        Read files from a directory and then append the data of each file into a list.\n",
        "        \"\"\"\n",
        "        output = []\n",
        "        for file in os.listdir(path):\n",
        "          filename_with_path = os.path.join(path, file)\n",
        "          if (file[-3:]).lower() == 'txt':\n",
        "            with open(filename_with_path, 'r') as f:\n",
        "              output.append(StringWithDocId(f.read(), file))\n",
        "          # elif (file[-3:]).lower() == 'csv':\n",
        "          #   self.appendCSV(filename_with_path)\n",
        "          else:\n",
        "            print(filename_with_path, \"will be skipped\")\n",
        "        print(len(output))\n",
        "        return output\n",
        "      \n",
        "    def processListOfTokens(self, tokenized):\n",
        "      output = []\n",
        "      for token in tokenized:\n",
        "        token = token.lower()\n",
        "        # 2. ignore stop-words\n",
        "        if token in STOP_WORDS or token == 'the':\n",
        "          continue\n",
        "        # ignore tokens that have punctuation only\n",
        "        if not re.search('\\w', token):\n",
        "          continue\n",
        "        # 3. porter stemmer makes everything lowercase as well\n",
        "        stemmed = porter.stem(token)\n",
        "        output.append(stemmed)\n",
        "      return output\n",
        "\n",
        "    def process_document(self, document: str, wordpunct_tokenize=True) -> list:\n",
        "        \"\"\"\n",
        "        pre-process a document and return a list of its terms\n",
        "        str->list\"\"\"\n",
        "        # 1. Wikipedia hyperlinks should be removed\n",
        "        # 4. Use multi-word character/location names from .csv files\n",
        "        text = wikipediaPreprocessing(document)\n",
        "        if wordpunct_tokenize:\n",
        "          tokenized  = nltk.tokenize.wordpunct_tokenize(text)\n",
        "        else:\n",
        "          tokenized  = nltk.tokenize.word_tokenize(text)\n",
        "        # remove stop-words & apply stemming\n",
        "        filtered_tokens = self.processListOfTokens(tokenized)\n",
        "        return filtered_tokens\n",
        "    \n",
        "    def index_corpus(self, documents: list) -> None:\n",
        "        \"\"\"\n",
        "        index given documents\n",
        "        list->None\"\"\"\n",
        "        starting_time = time.perf_counter()\n",
        "        token_list = []\n",
        "        # 1. Generate token sequence\n",
        "        for doc in documents:\n",
        "          curr_doc_id = doc.doc_id\n",
        "          processed_string = self.process_document(doc.string)\n",
        "          for i, token in enumerate(processed_string):\n",
        "            token_with_doc_id_and_pos = StringWithDocIdAndPosition(token, curr_doc_id, i)\n",
        "            token_list.append(token_with_doc_id_and_pos)\n",
        "        # 2. Sort\n",
        "        sorted_token_list = sorted(token_list)\n",
        "        print(\"First 10 of sorted_token_list:\", sorted_token_list[:10])\n",
        "        # 3. Convert into dictionary of postings\n",
        "        for token in sorted_token_list:\n",
        "          if token.string not in self.inverted_index:\n",
        "            self.inverted_index[token.string] = Posting()\n",
        "          self.inverted_index[token.string].add(token.doc_id, token.position)\n",
        "        # Print out some details about the dataset\n",
        "        total_time_taken = round(time.perf_counter() - starting_time, 4)\n",
        "        print(f\"It took: {total_time_taken} seconds to index the whole corpus.\")\n",
        "        print(f\"It has {len(self.inverted_index)} entries in total.\")\n",
        "      \n",
        "    def dump(self, path: str) -> None:\n",
        "        \"\"\"\n",
        "        provide a dump function to show index entries for a given set of terms        \n",
        "        \"\"\"\n",
        "        if os.path.exists(path) == False:\n",
        "          print(\"Path to file you provided doesn't exist\")\n",
        "          return\n",
        "        with open(path, 'r') as f:\n",
        "          file_contents = f.read()\n",
        "          examples = file_contents.split('\\n')\n",
        "          for e in examples:\n",
        "            processed_e = \" \".join(self.process_document(e))\n",
        "            try:\n",
        "              print(self.inverted_index[processed_e])\n",
        "            except KeyError:\n",
        "              print(e, \"was not found\")\n",
        "     \n",
        "    def proximity_search(self, term1: str, term2: str, window_size: int = 3) -> dict:\n",
        "        \"\"\"\n",
        "        1) check whether given two terms appear within a window\n",
        "        2) calculate the number of their co-existance in a document\n",
        "        3) add the document id and the number of matches into a dict\n",
        "        return the dict\"\"\"\n",
        "        term1 = self.processListOfTokens(self.process_document(term1))[0]\n",
        "        term2 = self.processListOfTokens(self.process_document(term2))[0]\n",
        "        print(\"Doc_ids containing the term1:\", self.inverted_index[term1].keys())\n",
        "        print(\"Doc_ids containing the term2:\", self.inverted_index[term2].keys())\n",
        "        documents_containing_both_terms = {}\n",
        "        for term1_doc_id, term1_positions in self.inverted_index[term1]:\n",
        "          # if both terms can be found in the same document\n",
        "          if term1_doc_id in self.inverted_index[term2]:\n",
        "            documents_containing_both_terms[term1_doc_id] = []\n",
        "            for term1_position in term1_positions:\n",
        "              print(\"- term1_position\",term1_position)\n",
        "              for term2_position in self.inverted_index[term2][term1_doc_id]:\n",
        "                print(\"-- term2_position\",term2_position)\n",
        "                # abs doesn't work here for some weird reason (as in this evaluates as if abs function call didn't exist)\n",
        "                if abs(term2_position - term1_position) < window_size:\n",
        "                  documents_containing_both_terms[term1_doc_id].append((term1_position, term2_position))\n",
        "                  print(f'Appended! abs({term2_position} - {term1_position})=', abs(term2_position - term1_position))\n",
        "                # if term2 has passed the window of term1, move on to another term1 position\n",
        "                elif term2_position - term1_position > window_size:\n",
        "                  break\n",
        "        return documents_containing_both_terms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testReadData():\n",
        "  index = InvertedIndex()\n",
        "  corpus = index.read_data('/content/drive/MyDrive/Colab Notebooks/Simpsons2022')\n",
        "  return (corpus[0]).string\n",
        "testReadData()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "nSvu_GKR_03l",
        "outputId": "3cfcbc4b-ecb2-4c29-e955-7e06051b8d22"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Simpsons2022/simpsons_characters - row.csv will be skipped\n",
            "/content/drive/MyDrive/Colab Notebooks/Simpsons2022/simpsons_locations row.csv will be skipped\n",
            "118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mr. Lisa Goes to Washington\\nFrom Wikipedia, the free encyclopedia\\n\\n\\n\\nJump to navigation\\nJump to search\\n\"Mr. Lisa Goes to Washington\"\\nThe Simpsons\\xa0episode\\nEpisode\\xa0no.\\nSeason\\xa03\\nEpisode 2\\nDirected by\\nWes Archer\\nWritten by\\nGeorge Meyer\\nProduction code\\n8F01\\nOriginal air date\\nSeptember 26, 1991[1]\\n\\nEpisode features\\nChalkboard gag\\n\"Spitwads are not free speech\"\\nCouch gag\\nThe family sits down and Homer pulls\\xa0Santa\\'s Little Helper\\xa0from under him.\\nCommentary\\nMatt Groening\\nAl Jean\\nMike Reiss\\nJulie Kavner\\nWes Archer\\nDavid Silverman\\nEpisode chronology\\n←\\xa0Previous\\n\"Stark Raving Dad\"\\nNext\\xa0→\\n\"When Flanders Failed\"\\nThe Simpsons\\xa0(season 3)\\nList of episodes\\n\"Mr. Lisa Goes to Washington\" is the second episode of the\\xa0third season\\xa0of the American animated television series\\xa0The Simpsons. It originally aired on the\\xa0Fox network\\xa0in the United States on September 26, 1991. In the episode,\\xa0Lisa\\xa0wins a patriotic essay contest about the\\xa0United States. She and her family attend the contest finals in\\xa0Washington, D.C., where she is dismayed after watching a\\xa0congressman\\xa0accept a bribe. Lisa loses the contest when she pens a scathing screed condemning the\\xa0government system, but the corrupt congressman is jailed and removed from office, restoring her faith in government.\\nThe episode was written by\\xa0George Meyer\\xa0and directed by\\xa0Wes Archer. It was the first episode for which\\xa0Al Jean\\xa0and\\xa0Mike Reiss\\xa0served as\\xa0show runners. It features multiple references to the 1939 film\\xa0Mr. Smith Goes to Washington, including the scene in which Lisa appeals to Lincoln\\'s statue at the\\xa0Lincoln Memorial\\xa0for advice. Other Washington landmarks referenced in the episode include the\\xa0White House, the\\xa0Watergate Hotel, the\\xa0Jefferson Memorial, the\\xa0Washington Monument, the\\xa0National Air and Space Museum\\xa0and the\\xa0Kennedy Center for the Performing Arts.\\nThe episode acquired a\\xa0Nielsen rating\\xa0of 12.9, and was the third highest-rated show on Fox the week it aired. It received mostly positive reviews from television critics, who praised the episode for its satire on American politics. The\\xa0timber industry\\xa0criticized the scene in which Lisa witnesses a timber industry lobbyist offering a bribe to the congressman to allow loggers to raze the Springfield Forest. The scene was described as \"an easy shot at hard-working people whose only crime is to have been born in a timber town\".[2]\\nContents\\n\\t\\t1\\n\\t\\tPlot\\n\\t\\t2\\n\\t\\tProduction\\n\\t\\t3\\n\\t\\tCultural references\\n\\t\\t4\\n\\t\\tThemes and analysis\\n\\t\\t5\\n\\t\\tReception\\n\\t\\t5.1\\n\\t\\tBroadcast and re-releases\\n\\t\\t5.2\\n\\t\\tCritical reviews\\n\\t\\t5.3\\n\\t\\tResponse from the timber industry\\n\\t\\t6\\n\\t\\tReferences\\n\\t\\t7\\n\\t\\tExternal links\\nPlot[edit]\\nHomer\\xa0sees an ad for a children\\'s essay contest in the\\xa0Reading Digest\\xa0magazine.\\xa0Lisa\\xa0submits an essay on the contest\\'s topic — \"what makes America great\" — after visiting Springfield Forest and seeing a\\xa0bald eagle\\xa0land nearby. The Simpsons travel to Washington, D.C. after Lisa\\'s essay, \"The Roots of Democracy\", earns her a spot in the national finals there.\\nWhile\\xa0Bart\\xa0and Homer enjoy the all-expenses-paid perks of their trip, Lisa visits famous monuments for inspiration. At a shrine to a\\xa0feminist\\xa0icon, she sees a corrupt\\xa0congressman, Bob Arnold, taking a bribe from a timber industry\\xa0lobbyist\\xa0to allow loggers to\\xa0clearcut\\xa0Springfield Forest. Heartbroken and disillusioned by government corruption, Lisa destroys her winning essay. She pens a scathing indictment, \"Cesspool on the\\xa0Potomac\", which condemns government greed and corruption and names the politician involved in the bribery.\\nLisa\\'s essay elicits a hostile reaction from the judges and audience members. When word of her speech quickly spreads through the\\xa0capital, Congressman Arnold is arrested, removed from office and sent to prison, where he becomes a\\xa0born-again\\xa0Christian. Lisa\\'s essay fails to win the contest, but her faith in government is restored and the contest winner commends her courage and honesty.\\nProduction[edit]\\n\\n\\nMike Reiss\\xa0(left) and\\xa0Al Jean\\xa0(right) took over as\\xa0show runners\\xa0for the third season.\\nThe episode was written by\\xa0George Meyer. It is one of\\xa0The Simpsons\\xa0creator\\xa0Matt Groening\\'s favorite episodes of the earlier seasons because he thought it took the show to another level.[3]\\xa0Meyer said he has a \"deep suspicion of social institutions and tradition in general,\" which affected the way he wrote the episode.[4]\\xa0Al Jean\\xa0and\\xa0Mike Reiss, who had written for\\xa0The Simpsons\\xa0since the start of the show, took over as\\xa0show runners\\xa0for the third season. Their first episode as show runners was \"Mr. Lisa Goes to Washington\" and they felt a lot of pressure about running the show. Jean and Reiss were so pressured that they did six to seven rewrites of the script to make it funnier.[5]\\xa0Jean said \"one reason for doing all these rewrites is because I kept thinking \\'It\\'s not good enough. It\\'s not good enough\\',\"[5]\\xa0and Reiss added that \"we were definitely scared. We had never run anything before, and they dumped us on this.\"[6]\\nWes Archer\\xa0directed \"Mr. Lisa Goes to Washington\", which was one of the first episodes to feature the Simpson family traveling to a real-life location.[7]\\xa0Because much of the episode takes place outside of Springfield, new background and character designs had to be animated. The Simpson family visits several real-life landmarks in Washington, which the animators were able to draw with the help of photographs from the animation studio\\'s library.\\xa0The Simpsons\\xa0director\\xa0David Silverman\\xa0grew up in the Washington area so he was able to help out with the designs.[8]\\xa0Marge\\'s voice actor,\\xa0Julie Kavner, said she loved the charm of the family \"just being on a trip and experiencing the hotel room they\\'re staying at, and the integrity of Bart\\'s character. You know, you just want to kill him for doing all those tricks and pranks.\"[9]\\xa0Jean believes this is one of the secrets of the show\\'s success, the fact that it is about a family and the writers can use experiences from their own or their family\\'s life as an inspiration in their writing. He thought \"Mr. Lisa Goes to Washington\" was a perfectly constructed episode in that sense.[5]\\nCultural references[edit]\\n\\n\\nLisa seeks advice from the\\xa0Abraham Lincoln statue\\xa0at the\\xa0Lincoln Memorial.\\nThe title and plot of the episode are parodies of the 1939 film\\xa0Mr. Smith Goes to Washington,[10]\\xa0in which the character Jefferson Smith comes to Washington with patriotic enthusiasm, but is instead shocked to see evidence of corruption in the government.[11][12]\\xa0The Tampa Tribune\\'s Curtis Ross called this reference one of the best film references in\\xa0The Simpsons\\'\\xa0history.[13]\\xa0Lisa\\'s visit to the\\xa0Lincoln Memorial\\xa0is a direct reference to\\xa0Mr. Smith Goes to Washington, in which Smith appeals to\\xa0Lincoln\\'s statue\\xa0for inspiration like Lisa did in the episode.[14]\\xa0In his book\\xa0Abraham Lincoln in the Post-Heroic Era, Barry Schwartz writes that the scene with Lisa at the crowded monument shows how \"thoroughly Lincoln\\'s moral and emotional significance has waned\".[15]\\xa0Mark Reinhart writes in the book\\xa0Abraham Lincoln on Screen\\xa0that the scene sums up \"with brilliant wit\" the American society\\'s \"annoying and ultimately useless tendency to ask [themselves] \\'What would Lincoln have done?\\' whenever [they] face a political or social dilemma\".[16]\\xa0Mr. Smith Goes to Washington\\xa0was once again referenced on\\xa0The Simpsons\\xa0in the\\xa0season fourteen\\xa0episode \"Mr. Spritz Goes to Washington\".[11]\\n\\n\\nThe family visit the\\xa0White House, where they meet then\\xa0First Lady\\xa0Barbara Bush.\\nIn addition to the Lincoln Memorial, other Washington, D.C. landmarks visited include the\\xa0Jefferson Memorial,[16][17]\\xa0the\\xa0Watergate Hotel\\xa0(where the family stays),[18]\\xa0the\\xa0Kennedy Center for the Performing Arts,[2]\\xa0the\\xa0White House,[19]\\xa0the\\xa0National Air and Space Museum, and the\\xa0Washington Monument.[5]\\xa0When the family visits the White House, they encounter then-First Lady\\xa0Barbara Bush\\xa0in the bathtub of one of the many bathrooms.[19]\\xa0Another American landmark mentioned in the episode is\\xa0Mount Rushmore.[1]\\xa0In addition, Lisa proposes that the family attend the memorial of the fictional Winifred Beecher Howe, an early crusader for women\\'s rights who later appeared on the unpopular 75-cent coins, according to Lisa. This is a reference to the\\xa0Susan B. Anthony dollar, which was minted for only three years and never became popular.[20]\\nThe episode makes references to several real-life persons. The piano-playing satirist who annoys Bart is a reference to\\xa0Mark Russell.[5]\\xa0Bob Arnold, the corrupt congressman, tells Lisa that there are quite a few women senators, but Lisa asserts that there are only two. (At the time, there were indeed only two,\\xa0Nancy Landon Kassebaum\\xa0of Kansas and\\xa0Barbara Mikulski\\xa0of Maryland.)[1]\\xa0Then-President\\xa0George H. W. Bush\\xa0is featured briefly in the episode. Shortly after it aired, Bush disparaged\\xa0The Simpsons\\xa0in a speech during his re-election campaign on January 27, 1992. At that point, family values were the cornerstone of Bush\\'s campaign platform, so he gave the following speech at the\\xa0National Religious Broadcasters\\' convention in Washington: \"We are going to keep on trying to strengthen the American family, to make American families a lot more like\\xa0the Waltons\\xa0and a lot less like the Simpsons.\"[21]\\xa0As a result, Bush appeared in future episodes in a more negative light.[21]\\nThemes and analysis[edit]\\n\\n\\nLisa\\'s role in the episode has been compared to\\xa0Henry David Thoreau.\\n\"Mr. Lisa Goes to Washington\" has been labeled as a satire on American politics. Michael Bitzer, in an edited book by Joseph Foy and Stanley Schultz entitled\\xa0Homer Simpson Goes to Washington, said this episode \"espouses the virtues, vices, and varieties of American political culture, public opinion, and ultimately the\\xa0American Dream\".[22]\\xa0Bitzer also wrote that\\xa0The Simpsons, through \"skillful\" use of satire, demonstrates with this episode \"insights into the underlying political culture and public opinion of the United States\\' governing system (and, more broadly, society at large)\".[22]\\xa0In his book\\xa0Gilligan Unbound: Pop Culture in the Age of Globalization, Paul Arthur Cantor said he was amazed by how far the episode was \"willing to take its corrosive satire of national politics\".[23]\\xa0He said it \"attacks the federal government at its foundation, the patriotic myths upon which its legitimacy lies. It makes fun of the very process by which patriotism is inculcated in the nation\\'s youth, the hokey contests that lead children to outdo each other in progovernment effusions.\"[23]\\xa0When the corrupt congressman is arrested, Lisa proclaims \"The system works!\" Benedict Anderson wrote in the book\\xa0The Spectre of Comparisons\\xa0that series creator Matt Groening \"assumes that his tickled audience is confident that the system barely works [...] So why does he need to show a patriot at all, especially one who is a deluded little female block-head? Probably because he, too, wishes to be seen as giving America another chance. Mr. Lisa guarantees his good intentions.\"[10]\\nGünter Beck, a lecturer for the\\xa0German Academic Exchange Service\\xa0(DAAD) at the Haifa Center for German and European Studies at the\\xa0University of Haifa\\xa0in Israel, compared Lisa\\'s role in the episode to the nineteenth-century American poet and philosopher\\xa0Henry David Thoreau. He writes that Lisa stands up against the public\\'s indifference towards the political system that Thoreau criticized, and comments that the emphasis should be \"on the brave moral decision to stand up for principles and against the broad public. By this courageous act, \\'to do what is right\\', an individual could save the well-being of the whole community. And indeed, Lisa\\'s bravery is the impulse for the state\\'s representatives to carry out their democratic obligations, so she can gladly notice \\'The system works!\\' — her trust in democracy and its institutions is restored. Thoreau on the other hand, had no lasting trust in the system but only in the people themselves and in the individual\\'s capacity to realize development and democracy.\"[24]\\nReception[edit]\\nBroadcast and re-releases[edit]\\n\"Mr. Lisa Goes to Washington\" originally aired on the Fox network in the United States on September 26, 1991.[1]\\xa0The episode finished 36th in the ratings for the week of September 23–29, 1991, with a\\xa0Nielsen rating\\xa0of 12.9, equivalent to approximately 11.9 million viewing households.\\xa0The Simpsons\\xa0was the third highest-rated show on Fox that week, following\\xa0Married... with Children\\xa0and\\xa0In Living Color.[25]\\xa0\"Mr. Lisa Goes to Washington\" and the episode \"When Flanders Failed\" were released on videocassette in 1999, entitled\\xa0The Best of the Simpsons.[26]\\xa0The episode was later included on the\\xa0Simpsons\\xa0season three DVD set that was released on August 26, 2003. Wes Archer, David Silverman, Matt Groening, Al Jean, Mike Reiss, and Julie Kavner participated in the DVD\\'s\\xa0audio commentary\\xa0of the episode.[27]\\nCritical reviews[edit]\\nSince airing, the episode has received mostly positive reviews from television critics. The authors of the book\\xa0I Can\\'t Believe It\\'s a Bigger and Better Updated Unofficial Simpsons Guide, Warren Martyn and Adrian Wood, praised the episode for being one of the best Lisa-centric episodes, and called Lisa\\'s talk with\\xa0Thomas Jefferson\\xa0and her nightmare vision of politicians as pigs \"especially worthy of note\".[28]\\xa0Nate Meyers of Digitally Obsessed gave the episode a 4.5 rating and said it is one of the best episodes featuring Lisa, \"complete with poignant observations about politics\".[29]\\xa0He particularly enjoyed the appearance of Barbara Bush at the White House.[29]\\nThe\\xa0Austin American-Statesman\\'s Steven Stein said this was the first episode of\\xa0The Simpsons\\xa0he saw. Even though he did not understand half the pop culture references, by the end of the episode he was a \"Simpsons\\xa0convert\".[18]\\xa0He thought there was \"something exotic about an issue as serious as political corruption being dealt with in a cartoon and being interrupted by jokes about beer and, yes, doughnuts\".[18]\\xa0The episode was praised for its political satire. Bill Gibron of DVD Verdict called the episode a \"biting political satire in the guise of a children\\'s oratory contest [which] signifies that this season of the series will be all over the map, both emotionally and logically\".[30]\\xa0Gibron added: \"Everything, from the\\xa0Reader\\'s Digest\\xa0rants to the formulaic speeches of the youths, has a resounding ring of truth. And once the story moves to Washington D.C, our nation\\'s capital is in for a royal reaming as well.\"[30]\\nBryce Wilson of Cinema Blend said the episode solidified the series\\' politically satirical voice as it \"bitch slapped the Bush administration\" that\\xa0would later badmouth\\xa0The Simpsons.[31]\\xa0DVD Movie Guide\\'s Colin Jacobson, however, gave the episode a more negative review, stating that it \"has its moments but never seems like one of the series\\' better programs. Part of that stems from its somewhat icky ending. The show exhibits a tone that feels more appropriate to a less biting and cynical series. It starts well with Homer\\'s obsession with\\xa0Reading Digest. After that, the show seems more erratic, and it remains pretty average overall.\"[32]\\nResponse from the timber industry[edit]\\nAccording to\\xa0The Plain Dealer\\'s Rodney Ferguson, the\\xa0timber industry\\xa0was insulted by the scene in which a timber industry lobbyist offers a bribe to the corrupt congressman so that he can demolish Springfield Forest. The Oregon Lands Coalition, a pro-timber group in\\xa0Salem, Oregon, \"bombarded\" the producers of the show with phone calls and mail protesting the episode.[33]\\xa0The coalition said it portrayed loggers unfairly and is \"allowing itself to be used by environmental extremists\".[2]\\xa0In an open letter to\\xa0The Simpsons\\xa0executive producer\\xa0James L. Brooks, the coalition wrote: \"Rather than approach this issue with genuine concern for Mother Earth, you took an easy shot at hard-working people whose only crime is [having been] born in a timber town.\"[2]\\xa0Karen Clark, a payroll clerk for a timber company in\\xa0Stayton, Oregon, said: \"The Simpsons\\xa0portrayed us as greedy, bribery-type people. It didn\\'t portray us as the everyday people—mothers, fathers, good members of society—that we are.\"[33]\\xa0Luke Popovich, vice president of the American Forest Council, wrote a letter to the show\\'s producer to protest \"the fuzzy-headed characterizations that pass for political correctness, the thinking in Hollywood where people are not very serious about these issues, but interested in pushing the right hot buttons, scoring the right points with audiences\".[33]\\n\\n\\nMatt Groening, creator of\\xa0The Simpsons, responded to the criticism of the episode.\\nThe Simpsons\\xa0creator Matt Groening responded to the criticism in an interview with\\xa0TV Guide, in which he said he did \"research on the ecological damage caused by clear-cutting and over-logging [and] it\\'s really appalling\".[33]\\xa0Jackie Lang, a timber industry activist in Salem who helped lead the protest against the Fox network and Groening, said she was appalled by Groening\\'s response, and \"He will be sorry he ever made it.\"[33]\\xa0Jake Hogan, supervising producer of the show, defended Groening: \"[The episodes] are just little stories, little comedies—stories that make people laugh.\"[33]\\xa0On October 15, 1991, Groening issued another statement to the public, in which he said: \"So now a few lumber companies have joined the nuclear power industry, right-wing preachers and high-ranking Republicans in attacking\\xa0The Simpsons. We must be doing something right. I must point out\\xa0The Simpsons\\xa0is a cartoon show—not\\xa060 Minutes. Later in the show, the same lobbyist proposed drilling for oil in\\xa0Teddy Roosevelt\\'s head at Mount Rushmore. Please don\\'t tell the oil companies about this.\"[34]\\nDavid Reinhard of\\xa0The Oregonian\\xa0commented on the criticism: \"Hollywood sharpsters can always make a group from the great American hinterland look ridiculous when it zeroes in on one show, particularly if that show is a cartoon. And the Oregon Lands Coalition\\'s protest was a bit of an overreaction. But the environmental sloganeering of\\xa0The Simpsons\\xa0as well as Groening\\'s cartoon commentary are symptomatic of a Hollywood and a popular culture that are hostile to the concerns and values of most Americans.\"[34]\\xa0After the episode aired, media researchers Robert Lichter and Linda S. Lichter found in a study of prime-time television that when shows dealt with business themes, 89 percent portrayed businessmen as swindlers or liars.[34]\\nThe same day Groening released his second statement,\\xa0The Simpsons\\xa0publicist Antonia Coffman was invited by Wayne Giesy, sales manager of Hull-Oakes Lumber Co. in\\xa0Bellfountain, Oregon, to visit Oregon and see \"responsible timber management\".[2]\\xa0Giesy said they wanted to show the producers \"how we log, how we manufacture, what goods we produce for everyone and how we replant for future generations. What most timber companies are interested in is a balanced program.\"[2]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testTokenzination():\n",
        "    index = InvertedIndex() # initilaise the index\n",
        "    corpus = index.read_data('/content/drive/MyDrive/Colab Notebooks/Simpsons2022') # specify the directory path in which files are located\n",
        "    text = (corpus[0]).string\n",
        "    start_time = time.perf_counter()\n",
        "    tokenized = index.process_document(text)\n",
        "    print(\"Time taken\", time.perf_counter()-start_time)\n",
        "    counter = Counter(tokenized).most_common(10)\n",
        "    x = [x for x, _ in counter]\n",
        "    print(x)\n",
        "    y = [y for _, y in counter]\n",
        "    plt.bar(x,y)\n",
        "testTokenzination()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "ZJGAK55tDxZB",
        "outputId": "6c67c836-144b-4bae-f214-770266524351"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Simpsons2022/simpsons_characters - row.csv will be skipped\n",
            "/content/drive/MyDrive/Colab Notebooks/Simpsons2022/simpsons_locations row.csv will be skipped\n",
            "118\n",
            "Time taken 0.14935372800027835\n",
            "['episod', 'lisa', 'simpson', 'washington', 'show', 'said', 'american', 'mr', 'goe', 'famili']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testTokenzination():\n",
        "    index = InvertedIndex() # initilaise the index\n",
        "    corpus = index.read_data('/content/drive/MyDrive/Colab Notebooks/Simpsons2022') # specify the directory path in which files are located\n",
        "    text = (corpus[0]).string\n",
        "    start_time = time.perf_counter()\n",
        "    tokenized = index.process_document(text, False)\n",
        "    print(\"Time taken\", time.perf_counter()-start_time)\n",
        "    return tokenized\n",
        "testTokenzination()[:60]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkZoP1P6BxZ4",
        "outputId": "fcec8815-ec2c-4603-b1e4-2fbfbe98fc30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Simpsons2022/simpsons_characters - row.csv will be skipped\n",
            "/content/drive/MyDrive/Colab Notebooks/Simpsons2022/simpsons_locations row.csv will be skipped\n",
            "118\n",
            "Time taken 0.19947912400039058\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mr.',\n",
              " 'lisa',\n",
              " 'goe',\n",
              " 'washington',\n",
              " 'second',\n",
              " 'episod',\n",
              " 'third',\n",
              " 'season',\n",
              " 'american',\n",
              " 'anim',\n",
              " 'televis',\n",
              " 'seri',\n",
              " 'simpson',\n",
              " 'origin',\n",
              " 'air',\n",
              " 'fox',\n",
              " 'network',\n",
              " 'unit',\n",
              " 'state',\n",
              " 'septemb',\n",
              " '26',\n",
              " '1991',\n",
              " 'episod',\n",
              " 'lisa',\n",
              " 'win',\n",
              " 'patriot',\n",
              " 'essay',\n",
              " 'contest',\n",
              " 'unit',\n",
              " 'state',\n",
              " 'famili',\n",
              " 'attend',\n",
              " 'contest',\n",
              " 'final',\n",
              " 'washington',\n",
              " 'd.c.',\n",
              " 'dismay',\n",
              " 'watch',\n",
              " 'congressman',\n",
              " 'accept',\n",
              " 'bribe',\n",
              " 'lisa',\n",
              " 'lose',\n",
              " 'contest',\n",
              " 'pen',\n",
              " 'scath',\n",
              " 'screed',\n",
              " 'condemn',\n",
              " 'govern',\n",
              " 'system',\n",
              " 'corrupt',\n",
              " 'congressman',\n",
              " 'jail',\n",
              " 'remov',\n",
              " 'offic',\n",
              " 'restor',\n",
              " 'faith',\n",
              " 'government.th',\n",
              " 'episod',\n",
              " 'written']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n4tuVF-zqE9",
        "outputId": "436bd938-8800-44e8-ddfc-4129c76308c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Simpsons2022/simpsons_characters - row.csv will be skipped\n",
            "/content/drive/MyDrive/Colab Notebooks/Simpsons2022/simpsons_locations row.csv will be skipped\n",
            "118\n",
            "First 10 of sorted_token_list: [0: 4.2.txt, 0: 4.3.txt, 0: 4.4.txt, 0: 5.21.txt, 0: 5.21.txt, 0: 5.8.txt, 0: 5.8.txt, 0: 6.4.txt, 0: 7.3.txt, 0: 7.3.txt]\n",
            "It took: 12.3659 seconds to index the whole corpus.\n",
            "It has 9879 entries in total.\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \"main call function\"\n",
        "    index = InvertedIndex() # initilaise the index\n",
        "    corpus = index.read_data('/content/drive/MyDrive/Colab Notebooks/Simpsons2022') # specify the directory path in which files are located\n",
        "    index.index_corpus(corpus) # index documents/corpus\n",
        "    return index\n",
        "index = main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.dump(\"/content/drive/MyDrive/Colab Notebooks/26957722.txt\")"
      ],
      "metadata": {
        "id": "G94h70akKT-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1725738-7d07-404d-a591-6707cd433ecd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1172 total occurances: ['17 in 3.1.txt: [39, 203, 235, 285, 307, 312, 325, 339, 489, 499, 764, 767, 994, 1016, 1121, 1665, 1698]', '4 in 3.10.txt: [850, 1016, 1142, 1223]', '4 in 3.11.txt: [336, 527, 622, 651]', '12 in 3.12.txt: [34, 40, 106, 133, 140, 178, 183, 389, 392, 410, 466, 567]', '28 in 3.13.txt: [1, 21, 45, 56, 89, 127, 130, 140, 165, 212, 224, 230, 242, 248, 272, 285, 301, 537, 615, 637, 696, 734, 810, 814, 846, 863, 1023, 1033]', '2 in 3.14.txt: [296, 316]', '9 in 3.15.txt: [38, 66, 214, 240, 327, 459, 484, 498, 642]', '27 in 3.16.txt: [0, 21, 34, 69, 100, 161, 175, 188, 217, 237, 253, 266, 277, 286, 334, 415, 427, 435, 542, 562, 623, 645, 736, 837, 893, 911, 969]', '1 in 3.17.txt: [906]', '22 in 3.18.txt: [42, 75, 154, 175, 183, 214, 218, 231, 303, 312, 351, 392, 533, 560, 589, 608, 743, 779, 849, 874, 885, 899]', '9 in 3.19.txt: [63, 155, 180, 264, 281, 291, 677, 692, 1166]', '3 in 3.2.txt: [203, 456, 707]', '3 in 3.20.txt: [182, 843, 1563]', '17 in 3.21.txt: [44, 50, 56, 59, 113, 154, 157, 210, 245, 272, 290, 301, 392, 482, 562, 704, 731]', '6 in 3.22.txt: [22, 140, 157, 172, 250, 260]', '24 in 3.23.txt: [0, 25, 43, 51, 102, 143, 151, 176, 184, 197, 209, 233, 238, 241, 252, 382, 399, 420, 421, 430, 438, 485, 610, 697]', '2 in 3.24.txt: [206, 283]', '10 in 3.3.txt: [57, 237, 259, 288, 296, 528, 752, 756, 784, 838]', '31 in 3.4.txt: [0, 21, 35, 43, 115, 141, 159, 173, 198, 208, 214, 228, 240, 246, 291, 302, 322, 502, 505, 514, 531, 549, 574, 584, 602, 620, 658, 707, 765, 785, 839]', '16 in 3.5.txt: [51, 283, 296, 306, 323, 328, 334, 381, 423, 737, 760, 775, 791, 800, 802, 808]', '13 in 3.6.txt: [38, 150, 161, 176, 269, 304, 324, 345, 370, 534, 686, 805, 842]', '21 in 3.7.txt: [34, 80, 230, 243, 260, 306, 330, 335, 351, 359, 368, 377, 766, 784, 939, 946, 952, 983, 984, 1133, 1155]', '1 in 3.8.txt: [244]', '23 in 3.9.txt: [25, 30, 39, 56, 134, 142, 157, 181, 189, 195, 204, 216, 233, 248, 294, 302, 369, 385, 397, 561, 621, 798, 812]', '13 in 4.1.txt: [47, 61, 72, 78, 87, 94, 159, 190, 202, 207, 216, 318, 558]', '20 in 4.10.txt: [135, 226, 240, 246, 256, 262, 265, 383, 396, 436, 444, 455, 1004, 1016, 1029, 1039, 1068, 1079, 1096, 1167]', '3 in 4.11.txt: [270, 424, 478]', '1 in 4.12.txt: [292]', '9 in 4.13.txt: [36, 57, 145, 181, 191, 206, 236, 439, 474]', '17 in 4.14.txt: [26, 101, 112, 123, 173, 284, 318, 485, 493, 507, 518, 534, 555, 568, 658, 665, 667]', '6 in 4.15.txt: [261, 606, 688, 788, 849, 899]', '9 in 4.16.txt: [33, 74, 97, 107, 138, 331, 350, 448, 465]', '16 in 4.18.txt: [29, 32, 119, 124, 190, 204, 227, 382, 535, 591, 593, 602, 606, 617, 637, 714]', '11 in 4.19.txt: [20, 65, 111, 120, 128, 183, 185, 344, 496, 523, 672]', '3 in 4.2.txt: [140, 946, 1516]', '8 in 4.20.txt: [37, 107, 119, 148, 151, 195, 264, 292]', '3 in 4.21.txt: [257, 448, 867]', '7 in 4.22.txt: [42, 135, 255, 263, 282, 316, 1338]', '11 in 4.5.txt: [28, 38, 99, 122, 143, 350, 370, 382, 439, 587, 730]', '19 in 4.6.txt: [23, 40, 72, 84, 98, 114, 117, 133, 141, 164, 172, 174, 181, 204, 211, 219, 228, 247, 623]', '18 in 4.7.txt: [44, 151, 161, 167, 185, 238, 248, 252, 261, 370, 379, 453, 557, 567, 600, 608, 647, 658]', '7 in 4.8.txt: [25, 72, 93, 153, 160, 175, 220]', '1 in 4.9.txt: [706]', '4 in 5.1.txt: [59, 156, 926, 1234]', '2 in 5.10.txt: [49, 196]', '4 in 5.11.txt: [154, 446, 615, 758]', '33 in 5.12.txt: [0, 22, 39, 105, 138, 148, 157, 166, 172, 187, 206, 211, 220, 229, 257, 269, 282, 322, 341, 419, 455, 504, 586, 602, 612, 626, 639, 651, 709, 720, 735, 753, 781]', '2 in 5.13.txt: [457, 461]', '1 in 5.14.txt: [819]', '4 in 5.15.txt: [574, 671, 687, 716]', '2 in 5.16.txt: [465, 850]', '19 in 5.17.txt: [0, 22, 45, 157, 168, 183, 201, 219, 230, 265, 320, 338, 374, 491, 499, 568, 637, 880, 924]', '20 in 5.18.txt: [33, 40, 51, 145, 154, 182, 186, 193, 210, 215, 228, 235, 254, 275, 284, 302, 340, 347, 363, 591]', '19 in 5.19.txt: [34, 130, 138, 191, 217, 272, 280, 291, 295, 340, 357, 368, 378, 413, 470, 562, 624, 739, 765]', '3 in 5.2.txt: [282, 401, 705]', '25 in 5.20.txt: [30, 37, 152, 185, 199, 203, 237, 269, 278, 290, 353, 355, 375, 402, 412, 457, 502, 506, 517, 554, 579, 636, 796, 844, 853]', '8 in 5.21.txt: [174, 192, 209, 234, 623, 647, 749, 786]', '5 in 5.22.txt: [224, 230, 238, 337, 363]', '4 in 5.3.txt: [263, 316, 835, 1352]', '1 in 5.4.txt: [281]', '30 in 5.5.txt: [41, 129, 147, 356, 376, 402, 416, 424, 452, 462, 480, 483, 488, 551, 578, 600, 614, 623, 630, 758, 938, 994, 1036, 1094, 1106, 1250, 1257, 1360, 1392, 1496]', '1 in 5.6.txt: [160]', '17 in 5.7.txt: [0, 37, 43, 53, 69, 152, 190, 218, 248, 294, 297, 310, 320, 326, 376, 403, 843]', '14 in 5.8.txt: [23, 36, 150, 162, 194, 210, 262, 278, 410, 480, 511, 699, 824, 844]', '9 in 5.9.txt: [50, 233, 243, 258, 270, 299, 308, 605, 1225]', '22 in 6.1.txt: [0, 21, 104, 112, 138, 151, 160, 188, 215, 227, 293, 319, 351, 354, 374, 406, 411, 570, 665, 689, 734, 852]', '5 in 6.10.txt: [232, 272, 275, 414, 423]', '1 in 6.12.txt: [227]', '1 in 6.13.txt: [274]', '7 in 6.14.txt: [0, 21, 47, 78, 94, 568, 579]', '30 in 6.16.txt: [0, 22, 29, 49, 100, 123, 135, 145, 163, 179, 182, 203, 211, 225, 233, 244, 264, 271, 281, 308, 312, 337, 459, 554, 585, 632, 700, 763, 790, 1038]', '11 in 6.17.txt: [34, 68, 284, 300, 313, 324, 333, 367, 413, 474, 723]', '5 in 6.18.txt: [555, 563, 572, 580, 710]', '5 in 6.19.txt: [131, 389, 427, 439, 467]', '4 in 6.2.txt: [213, 384, 408, 734]', '6 in 6.20.txt: [203, 226, 249, 269, 281, 523]', '11 in 6.21.txt: [22, 134, 172, 247, 260, 291, 550, 580, 648, 668, 673]', '17 in 6.22.txt: [22, 34, 202, 213, 226, 242, 265, 319, 327, 334, 369, 384, 397, 694, 855, 864, 1083]', '2 in 6.23.txt: [247, 633]', '9 in 6.24.txt: [100, 150, 162, 198, 240, 301, 371, 388, 511]', '4 in 6.25.txt: [263, 316, 835, 1352]', '4 in 6.3.txt: [366, 372, 448, 510]', '7 in 6.4.txt: [67, 96, 102, 121, 147, 473, 591]', '8 in 6.5.txt: [38, 145, 167, 207, 223, 253, 289, 318]', '10 in 6.6.txt: [181, 218, 296, 389, 510, 527, 536, 557, 562, 600]', '41 in 6.7.txt: [0, 25, 31, 51, 71, 123, 134, 146, 156, 162, 174, 183, 205, 210, 221, 229, 265, 270, 284, 298, 313, 390, 407, 434, 512, 537, 610, 624, 648, 651, 672, 715, 728, 748, 764, 792, 820, 870, 880, 884, 908]', '12 in 6.8.txt: [28, 115, 125, 169, 183, 190, 200, 318, 414, 448, 545, 662]', '2 in 6.9.txt: [61, 388]', '4 in 7.1.txt: [263, 316, 835, 1352]', '3 in 7.10.txt: [788, 792, 819]', '23 in 7.11.txt: [24, 33, 110, 125, 146, 157, 174, 185, 197, 207, 216, 231, 241, 254, 267, 279, 468, 487, 574, 588, 602, 660, 719]', '4 in 7.12.txt: [42, 223, 244, 603]', '15 in 7.13.txt: [47, 137, 138, 156, 167, 184, 198, 229, 246, 410, 421, 803, 833, 851, 991]', '18 in 7.15.txt: [0, 21, 39, 111, 119, 131, 143, 151, 198, 202, 222, 255, 543, 576, 608, 628, 677, 690]', '24 in 7.18.txt: [56, 65, 104, 185, 192, 207, 231, 246, 262, 282, 295, 305, 337, 365, 414, 432, 499, 581, 602, 612, 727, 1066, 1214, 1247]', '11 in 7.2.txt: [40, 42, 142, 154, 226, 237, 254, 266, 271, 299, 720]', '22 in 7.20.txt: [0, 21, 41, 162, 175, 197, 248, 266, 289, 300, 303, 322, 332, 345, 390, 434, 574, 663, 739, 752, 773, 880]', '4 in 7.21.txt: [162, 169, 196, 389]', '14 in 7.22.txt: [85, 87, 163, 214, 267, 276, 305, 316, 332, 355, 385, 395, 405, 743]', '2 in 7.24.txt: [122, 192]', '11 in 7.25.txt: [40, 42, 142, 154, 226, 237, 254, 266, 271, 299, 720]', '8 in 7.3.txt: [111, 150, 164, 212, 403, 461, 545, 581]', '44 in 7.4.txt: [0, 22, 46, 134, 171, 179, 180, 198, 203, 209, 239, 248, 262, 271, 282, 286, 297, 350, 539, 593, 624, 675, 698, 742, 770, 781, 798, 801, 812, 851, 881, 892, 903, 916, 921, 1002, 1046, 1068, 1131, 1190, 1198, 1204, 1214, 1223]', '2 in 7.5.txt: [185, 260]', '15 in 7.6.txt: [427, 458, 467, 475, 484, 501, 560, 621, 629, 635, 975, 980, 985, 999, 1237]', '3 in 7.7.txt: [150, 586, 881]', '1 in 7.8.txt: [151]', '6 in 7.9.txt: [36, 224, 295, 306, 320, 336]']\n",
            "343 total occurances: ['7 in 3.1.txt: [3, 12, 822, 844, 1397, 1640, 1791]', '7 in 3.10.txt: [11, 65, 146, 503, 632, 1133, 1327]', '2 in 3.11.txt: [21, 184]', '4 in 3.12.txt: [99, 111, 690, 695]', '2 in 3.13.txt: [139, 348]', '2 in 3.15.txt: [558, 634]', '3 in 3.16.txt: [11, 71, 441]', '5 in 3.17.txt: [118, 419, 510, 963, 1142]', '3 in 3.18.txt: [268, 297, 525]', '2 in 3.19.txt: [824, 858]', '6 in 3.2.txt: [65, 345, 395, 613, 648, 1192]', '6 in 3.20.txt: [419, 653, 689, 772, 1480, 1537]', '3 in 3.21.txt: [8, 437, 447]', '6 in 3.22.txt: [12, 67, 83, 336, 348, 374]', '2 in 3.3.txt: [345, 390]', '6 in 3.4.txt: [56, 142, 359, 480, 789, 822]', '9 in 3.5.txt: [86, 362, 390, 415, 438, 454, 462, 513, 592]', '3 in 3.6.txt: [59, 488, 591]', '7 in 3.7.txt: [12, 45, 147, 256, 517, 1125, 1176]', '5 in 3.8.txt: [81, 134, 446, 540, 665]', '1 in 3.9.txt: [252]', '5 in 4.1.txt: [2, 285, 389, 397, 569]', '19 in 4.10.txt: [1, 12, 30, 37, 44, 102, 126, 254, 294, 297, 316, 459, 660, 823, 908, 923, 965, 1072, 1129]', '6 in 4.12.txt: [97, 388, 404, 640, 781, 1087]', '3 in 4.14.txt: [11, 527, 770]', '2 in 4.15.txt: [343, 361]', '4 in 4.16.txt: [38, 276, 320, 348]', '2 in 4.17.txt: [547, 904]', '5 in 4.18.txt: [65, 70, 312, 428, 432]', '2 in 4.19.txt: [158, 492]', '2 in 4.2.txt: [12, 430]', '3 in 4.20.txt: [80, 373, 473]', '4 in 4.21.txt: [3, 278, 289, 403]', '3 in 4.22.txt: [14, 646, 652]', '5 in 4.3.txt: [382, 389, 397, 418, 749]', '2 in 4.4.txt: [12, 225]', '3 in 4.6.txt: [281, 333, 380]', '2 in 4.8.txt: [75, 350]', '1 in 4.9.txt: [913]', '6 in 5.1.txt: [3, 218, 274, 417, 863, 1381]', '3 in 5.10.txt: [390, 537, 553]', '6 in 5.12.txt: [52, 230, 371, 507, 565, 791]', '5 in 5.13.txt: [264, 372, 447, 467, 924]', '4 in 5.15.txt: [12, 182, 459, 464]', '1 in 5.17.txt: [81]', '2 in 5.18.txt: [318, 379]', '4 in 5.19.txt: [481, 500, 558, 834]', '2 in 5.2.txt: [716, 789]', '2 in 5.21.txt: [4, 522]', '2 in 5.22.txt: [152, 157]', '4 in 5.3.txt: [1031, 1431, 1766, 2175]', '4 in 5.4.txt: [10, 52, 452, 503]', '6 in 5.5.txt: [243, 652, 823, 831, 977, 1158]', '1 in 5.7.txt: [77]', '1 in 5.8.txt: [789]', '3 in 5.9.txt: [242, 244, 877]', '3 in 6.1.txt: [2, 197, 709]', '1 in 6.10.txt: [13]', '1 in 6.11.txt: [11]', '1 in 6.12.txt: [414]', '3 in 6.13.txt: [42, 299, 345]', '2 in 6.14.txt: [296, 370]', '2 in 6.15.txt: [353, 481]', '1 in 6.16.txt: [876]', '1 in 6.17.txt: [351]', '4 in 6.18.txt: [11, 128, 462, 923]', '2 in 6.19.txt: [433, 724]', '3 in 6.2.txt: [64, 393, 472]', '2 in 6.20.txt: [418, 438]', '1 in 6.21.txt: [3]', '6 in 6.22.txt: [87, 120, 495, 574, 645, 691]', '1 in 6.23.txt: [183]', '1 in 6.24.txt: [542]', '4 in 6.25.txt: [1031, 1431, 1766, 2175]', '2 in 6.3.txt: [318, 694]', '1 in 6.4.txt: [12]', '3 in 6.5.txt: [97, 457, 576]', '9 in 6.6.txt: [98, 406, 504, 713, 782, 791, 893, 998, 1317]', '2 in 6.7.txt: [384, 513]', '3 in 6.8.txt: [11, 268, 309]', '1 in 6.9.txt: [516]', '4 in 7.1.txt: [1031, 1431, 1766, 2175]', '1 in 7.10.txt: [406]', '3 in 7.11.txt: [369, 375, 391]', '1 in 7.12.txt: [387]', '2 in 7.13.txt: [653, 669]', '4 in 7.14.txt: [56, 259, 275, 339]', '1 in 7.15.txt: [447]', '3 in 7.16.txt: [67, 617, 968]', '1 in 7.17.txt: [400]', '6 in 7.18.txt: [640, 892, 941, 950, 965, 1177]', '2 in 7.19.txt: [369, 743]', '3 in 7.20.txt: [282, 473, 628]', '4 in 7.21.txt: [5, 564, 573, 745]', '1 in 7.23.txt: [519]', '3 in 7.3.txt: [56, 233, 532]', '3 in 7.4.txt: [12, 430, 520]', '4 in 7.5.txt: [48, 401, 414, 490]', '9 in 7.6.txt: [17, 111, 150, 416, 687, 730, 841, 1059, 1106]', '2 in 7.7.txt: [333, 372]', '3 in 7.8.txt: [11, 37, 45]', '3 in 7.9.txt: [70, 402, 445]']\n",
            "17 total occurances: ['4 in 3.16.txt: [122, 584, 604, 1051]', '1 in 3.18.txt: [694]', '1 in 3.24.txt: [766]', '2 in 3.7.txt: [810, 1073]', '1 in 3.9.txt: [689]', '1 in 5.13.txt: [1162]', '1 in 7.18.txt: [163]', '1 in 7.2.txt: [165]', '1 in 7.21.txt: [1412]', '1 in 7.25.txt: [165]', '1 in 7.5.txt: [1353]', '2 in 7.6.txt: [141, 947]']\n",
            "19 total occurances: ['1 in 3.16.txt: [466]', '1 in 3.21.txt: [644]', '3 in 4.18.txt: [258, 302, 621]', '1 in 4.4.txt: [445]', '3 in 6.3.txt: [395, 402, 501]', '8 in 7.10.txt: [192, 359, 617, 731, 822, 830, 839, 864]', '2 in 7.3.txt: [340, 347]']\n",
            "158 total occurances: ['3 in 3.1.txt: [1161, 1355, 1621]', '2 in 3.10.txt: [165, 1305]', '1 in 3.12.txt: [380]', '13 in 3.13.txt: [34, 170, 183, 189, 209, 245, 295, 385, 557, 596, 617, 941, 970]', '1 in 3.14.txt: [868]', '2 in 3.15.txt: [88, 360]', '3 in 3.16.txt: [231, 842, 888]', '2 in 3.17.txt: [700, 1350]', '2 in 3.18.txt: [832, 913]', '4 in 3.2.txt: [998, 1264, 1318, 1599]', '2 in 3.21.txt: [609, 839]', '1 in 3.22.txt: [502]', '1 in 3.23.txt: [723]', '1 in 3.7.txt: [989]', '1 in 4.1.txt: [568]', '2 in 4.10.txt: [586, 931]', '4 in 4.12.txt: [250, 421, 579, 1063]', '3 in 4.13.txt: [120, 266, 580]', '2 in 4.15.txt: [105, 957]', '1 in 4.17.txt: [465]', '1 in 4.18.txt: [147]', '2 in 4.2.txt: [84, 127]', '3 in 4.21.txt: [717, 809, 815]', '3 in 4.3.txt: [401, 408, 586]', '1 in 4.4.txt: [81]', '2 in 4.9.txt: [49, 181]', '1 in 5.1.txt: [342]', '1 in 5.10.txt: [419]', '2 in 5.13.txt: [784, 930]', '1 in 5.14.txt: [555]', '2 in 5.15.txt: [89, 819]', '1 in 5.16.txt: [698]', '1 in 5.17.txt: [328]', '1 in 5.18.txt: [511]', '3 in 5.19.txt: [142, 175, 262]', '2 in 5.2.txt: [104, 245]', '2 in 5.20.txt: [479, 823]', '1 in 5.21.txt: [754]', '1 in 5.22.txt: [784]', '3 in 5.3.txt: [285, 489, 1505]', '2 in 5.4.txt: [553, 562]', '4 in 5.5.txt: [85, 962, 1055, 1266]', '1 in 5.7.txt: [304]', '2 in 5.8.txt: [83, 405]', '2 in 5.9.txt: [575, 741]', '1 in 6.1.txt: [367]', '1 in 6.10.txt: [81]', '1 in 6.11.txt: [679]', '1 in 6.13.txt: [713]', '2 in 6.15.txt: [602, 615]', '2 in 6.16.txt: [423, 895]', '4 in 6.18.txt: [163, 467, 611, 1130]', '1 in 6.19.txt: [673]', '1 in 6.21.txt: [509]', '2 in 6.22.txt: [101, 536]', '1 in 6.23.txt: [459]', '3 in 6.25.txt: [285, 489, 1505]', '2 in 6.4.txt: [94, 342]', '5 in 6.5.txt: [89, 501, 640, 843, 898]', '3 in 6.6.txt: [652, 1311, 1427]', '1 in 6.8.txt: [51]', '1 in 6.9.txt: [317]', '3 in 7.1.txt: [285, 489, 1505]', '2 in 7.10.txt: [592, 1306]', '3 in 7.11.txt: [324, 591, 724]', '2 in 7.13.txt: [1027, 1043]', '2 in 7.14.txt: [306, 328]', '4 in 7.19.txt: [545, 621, 930, 945]', '1 in 7.20.txt: [778]', '2 in 7.21.txt: [534, 1263]', '1 in 7.24.txt: [570]', '2 in 7.4.txt: [87, 975]', '1 in 7.5.txt: [37]', '2 in 7.6.txt: [502, 537]', '3 in 7.7.txt: [849, 865, 944]', '1 in 7.8.txt: [299]', '1 in 7.9.txt: [791]']\n",
            "105 total occurances: ['1 in 3.1.txt: [1514]', '2 in 3.10.txt: [1170, 1241]', '4 in 3.16.txt: [966, 989, 1035, 1043]', '5 in 3.17.txt: [1096, 1119, 1146, 1234, 1268]', '1 in 3.23.txt: [858]', '1 in 3.5.txt: [827]', '2 in 3.6.txt: [770, 794]', '2 in 3.7.txt: [1183, 1219]', '2 in 3.8.txt: [326, 976]', '1 in 4.1.txt: [644]', '3 in 4.12.txt: [670, 679, 797]', '4 in 4.15.txt: [125, 811, 820, 835]', '1 in 4.16.txt: [543]', '3 in 4.17.txt: [760, 778, 897]', '2 in 4.2.txt: [1141, 1151]', '4 in 4.22.txt: [972, 1053, 1097, 1118]', '1 in 4.3.txt: [758]', '1 in 4.4.txt: [536]', '1 in 4.6.txt: [317]', '1 in 4.8.txt: [423]', '1 in 4.9.txt: [767]', '2 in 5.1.txt: [1325, 1430]', '3 in 5.13.txt: [574, 1051, 1130]', '1 in 5.15.txt: [941]', '1 in 5.18.txt: [403]', '1 in 5.19.txt: [874]', '1 in 5.22.txt: [880]', '1 in 5.3.txt: [1995]', '1 in 5.4.txt: [682]', '2 in 5.7.txt: [124, 599]', '4 in 5.9.txt: [1105, 1125, 1243, 1290]', '3 in 6.14.txt: [327, 367, 571]', '1 in 6.16.txt: [767]', '4 in 6.19.txt: [626, 642, 659, 726]', '3 in 6.2.txt: [106, 517, 679]', '1 in 6.20.txt: [896]', '1 in 6.21.txt: [841]', '1 in 6.23.txt: [429]', '1 in 6.24.txt: [215]', '1 in 6.25.txt: [1995]', '3 in 6.4.txt: [518, 558, 571]', '2 in 6.6.txt: [1191, 1435]', '1 in 6.9.txt: [494]', '1 in 7.1.txt: [1995]', '3 in 7.18.txt: [177, 868, 1048]', '3 in 7.19.txt: [114, 592, 836]', '4 in 7.21.txt: [506, 1048, 1058, 1109]', '2 in 7.24.txt: [554, 591]', '3 in 7.4.txt: [124, 1160, 1208]', '1 in 7.6.txt: [1514]', '6 in 7.7.txt: [484, 494, 737, 744, 806, 1030]']\n",
            "3 total occurances: ['1 in 3.16.txt: [1062]', '1 in 4.12.txt: [687]', '1 in 5.9.txt: [1302]']\n",
            "321 total occurances: ['7 in 3.1.txt: [44, 356, 1337, 1466, 1539, 1546, 1610]', '9 in 3.10.txt: [169, 954, 1002, 1114, 1122, 1248, 1280, 1292, 1313]', '2 in 3.11.txt: [911, 928]', '1 in 3.12.txt: [629]', '7 in 3.13.txt: [784, 793, 837, 865, 889, 912, 973]', '1 in 3.14.txt: [992]', '1 in 3.15.txt: [658]', '3 in 3.16.txt: [826, 1060, 1063]', '6 in 3.17.txt: [117, 474, 1182, 1211, 1221, 1244]', '4 in 3.18.txt: [31, 117, 806, 917]', '2 in 3.19.txt: [1100, 1133]', '4 in 3.2.txt: [526, 1087, 1144, 1171]', '3 in 3.20.txt: [728, 741, 1393]', '2 in 3.21.txt: [365, 617]', '4 in 3.22.txt: [135, 756, 764, 808]', '2 in 3.23.txt: [26, 824]', '3 in 3.24.txt: [907, 997, 1073]', '2 in 3.3.txt: [595, 811]', '2 in 3.4.txt: [699, 742]', '3 in 3.5.txt: [303, 640, 842]', '4 in 3.7.txt: [200, 1200, 1207, 1238]', '5 in 3.8.txt: [276, 723, 797, 876, 912]', '2 in 3.9.txt: [381, 741]', '2 in 4.10.txt: [868, 943]', '1 in 4.11.txt: [323]', '11 in 4.12.txt: [78, 663, 712, 721, 755, 784, 874, 915, 931, 954, 1023]', '2 in 4.14.txt: [90, 717]', '1 in 4.15.txt: [734]', '7 in 4.17.txt: [75, 757, 768, 848, 883, 942, 948]', '5 in 4.2.txt: [735, 1098, 1107, 1176, 1505]', '2 in 4.20.txt: [588, 645]', '5 in 4.22.txt: [1011, 1032, 1039, 1249, 1319]', '3 in 4.3.txt: [112, 816, 832]', '1 in 4.4.txt: [542]', '1 in 4.5.txt: [821]', '1 in 4.6.txt: [652]', '1 in 4.7.txt: [484]', '6 in 4.9.txt: [54, 185, 820, 858, 937, 956]', '4 in 5.1.txt: [425, 894, 1306, 1442]', '1 in 5.10.txt: [817]', '3 in 5.12.txt: [707, 710, 760]', '6 in 5.13.txt: [874, 954, 973, 987, 1000, 1037]', '4 in 5.14.txt: [632, 855, 860, 918]', '3 in 5.15.txt: [96, 932, 1032]', '1 in 5.16.txt: [813]', '3 in 5.17.txt: [767, 777, 787]', '1 in 5.18.txt: [626]', '1 in 5.2.txt: [379]', '1 in 5.21.txt: [683]', '2 in 5.22.txt: [527, 605]', '3 in 5.3.txt: [2029, 2052, 2104]', '5 in 5.4.txt: [132, 702, 711, 752, 812]', '8 in 5.5.txt: [1131, 1342, 1381, 1415, 1431, 1435, 1499, 1501]', '2 in 5.7.txt: [115, 684]', '1 in 5.8.txt: [895]', '5 in 5.9.txt: [110, 1116, 1282, 1303, 1317]', '1 in 6.11.txt: [714]', '7 in 6.12.txt: [64, 306, 350, 433, 494, 551, 562]', '2 in 6.15.txt: [57, 712]', '2 in 6.16.txt: [786, 917]', '1 in 6.17.txt: [543]', '4 in 6.18.txt: [378, 740, 814, 846]', '7 in 6.19.txt: [596, 621, 669, 690, 701, 716, 743]', '1 in 6.2.txt: [671]', '5 in 6.20.txt: [108, 598, 952, 962, 969]', '1 in 6.21.txt: [632]', '1 in 6.22.txt: [342]', '1 in 6.23.txt: [928]', '1 in 6.24.txt: [537]', '3 in 6.25.txt: [2029, 2052, 2104]', '1 in 6.4.txt: [194]', '3 in 6.5.txt: [65, 980, 994]', '12 in 6.6.txt: [1157, 1231, 1243, 1255, 1273, 1301, 1319, 1335, 1345, 1375, 1402, 1417]', '3 in 6.7.txt: [103, 837, 849]', '4 in 6.8.txt: [159, 186, 591, 602]', '1 in 6.9.txt: [511]', '3 in 7.1.txt: [2029, 2052, 2104]', '2 in 7.11.txt: [656, 684]', '4 in 7.12.txt: [571, 734, 767, 792]', '5 in 7.13.txt: [71, 649, 929, 1054, 1063]', '1 in 7.14.txt: [538]', '2 in 7.15.txt: [321, 603]', '2 in 7.16.txt: [1173, 1184]', '1 in 7.17.txt: [660]', '2 in 7.18.txt: [1092, 1119]', '5 in 7.19.txt: [861, 870, 887, 919, 951]', '4 in 7.2.txt: [735, 749, 795, 810]', '3 in 7.20.txt: [101, 836, 864]', '6 in 7.21.txt: [1028, 1093, 1101, 1135, 1155, 1371]', '2 in 7.23.txt: [798, 1019]', '2 in 7.24.txt: [580, 620]', '4 in 7.25.txt: [735, 749, 795, 810]', '4 in 7.3.txt: [281, 285, 516, 540]', '3 in 7.4.txt: [117, 126, 1162]', '5 in 7.5.txt: [1102, 1112, 1123, 1442, 1488]', '3 in 7.6.txt: [1455, 1481, 1497]', '11 in 7.7.txt: [84, 756, 774, 782, 791, 833, 844, 906, 972, 999, 1017]', '2 in 7.8.txt: [879, 891]', '2 in 7.9.txt: [779, 800]']\n",
            "85 total occurances: ['2 in 3.1.txt: [768, 1797]', '1 in 3.11.txt: [921]', '2 in 3.16.txt: [972, 1053]', '1 in 3.17.txt: [1231]', '1 in 3.18.txt: [907]', '1 in 3.19.txt: [400]', '3 in 3.21.txt: [344, 629, 634]', '1 in 3.5.txt: [834]', '1 in 3.7.txt: [1227]', '1 in 3.9.txt: [414]', '1 in 4.1.txt: [384]', '2 in 4.11.txt: [297, 298]', '2 in 4.12.txt: [727, 793]', '2 in 4.15.txt: [510, 832]', '1 in 4.16.txt: [540]', '1 in 4.17.txt: [759]', '3 in 4.2.txt: [628, 1148, 1448]', '3 in 4.21.txt: [368, 375, 393]', '3 in 4.22.txt: [749, 1007, 1259]', '1 in 4.7.txt: [481]', '1 in 4.9.txt: [328]', '4 in 5.1.txt: [108, 978, 1124, 1130]', '1 in 5.10.txt: [792]', '1 in 5.11.txt: [656]', '6 in 5.13.txt: [654, 944, 989, 994, 1011, 1048]', '1 in 5.14.txt: [430]', '1 in 5.2.txt: [679]', '1 in 5.21.txt: [743]', '1 in 5.22.txt: [877]', '1 in 5.3.txt: [982]', '2 in 5.8.txt: [509, 517]', '6 in 6.12.txt: [39, 235, 308, 325, 404, 542]', '1 in 6.2.txt: [170]', '4 in 6.20.txt: [70, 535, 903, 967]', '1 in 6.22.txt: [1064]', '1 in 6.24.txt: [373]', '1 in 6.25.txt: [982]', '2 in 6.4.txt: [555, 568]', '2 in 6.6.txt: [595, 920]', '1 in 7.1.txt: [982]', '3 in 7.10.txt: [325, 929, 1236]', '1 in 7.13.txt: [658]', '1 in 7.14.txt: [415]', '1 in 7.19.txt: [395]', '1 in 7.21.txt: [1106]', '1 in 7.23.txt: [453]', '2 in 7.6.txt: [1063, 1149]', '1 in 7.7.txt: [1027]', '2 in 7.8.txt: [537, 570]']\n",
            "42 total occurances: ['3 in 3.1.txt: [648, 1343, 1430]', '1 in 3.10.txt: [1209]', '2 in 3.13.txt: [822, 904]', '1 in 3.15.txt: [397]', '1 in 3.16.txt: [873]', '1 in 3.20.txt: [1368]', '1 in 3.24.txt: [968]', '2 in 3.3.txt: [648, 749]', '1 in 3.5.txt: [918]', '1 in 3.7.txt: [1252]', '1 in 4.11.txt: [327]', '1 in 4.15.txt: [685]', '2 in 4.19.txt: [166, 209]', '2 in 5.1.txt: [147, 1355]', '1 in 5.10.txt: [521]', '1 in 5.11.txt: [695]', '2 in 5.12.txt: [65, 333]', '1 in 5.13.txt: [602]', '1 in 5.14.txt: [883]', '1 in 5.7.txt: [548]', '1 in 6.10.txt: [618]', '2 in 6.14.txt: [238, 321]', '1 in 6.16.txt: [382]', '1 in 6.22.txt: [1236]', '3 in 6.6.txt: [659, 680, 1208]', '1 in 7.10.txt: [392]', '1 in 7.14.txt: [320]', '1 in 7.17.txt: [469]', '1 in 7.18.txt: [533]', '1 in 7.4.txt: [220]', '2 in 7.5.txt: [1244, 1257]']\n",
            "2 total occurances: ['2 in 6.16.txt: [1011, 1020]']\n",
            "Bart Simpson was not found\n",
            "Gordie Howe was not found\n",
            "24 total occurances: ['1 in 3.1.txt: [607]', '1 in 3.11.txt: [729]', '1 in 3.14.txt: [463]', '1 in 3.16.txt: [503]', '1 in 3.17.txt: [1328]', '1 in 3.19.txt: [278]', '1 in 3.7.txt: [889]', '1 in 5.1.txt: [724]', '1 in 5.16.txt: [749]', '1 in 5.19.txt: [827]', '2 in 5.8.txt: [467, 555]', '1 in 6.11.txt: [675]', '1 in 6.2.txt: [494]', '3 in 6.3.txt: [33, 472, 482]', '1 in 6.4.txt: [494]', '1 in 7.18.txt: [684]', '1 in 7.2.txt: [560]', '1 in 7.21.txt: [1245]', '1 in 7.22.txt: [621]', '1 in 7.25.txt: [560]', '1 in 7.4.txt: [493]']\n",
            "Bart the Lover was not found\n",
            "7 total occurances: ['1 in 3.11.txt: [190]', '1 in 3.16.txt: [392]', '1 in 3.2.txt: [681]', '1 in 4.15.txt: [583]', '1 in 5.1.txt: [1098]', '1 in 5.6.txt: [351]', '1 in 7.4.txt: [404]']\n",
            "won was not found\n",
            "voice-overs was not found\n",
            "Simpsonovi was not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.proximity_search('award', 'winning', 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wld3Ax7Kk5K9",
        "outputId": "8150c5c7-63bb-4680-b14a-1194e10d66c8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doc_ids containing the term1: KeysView(93 total occurances: ['1 in 3.1.txt: [1259]', '1 in 3.12.txt: [770]', '2 in 3.13.txt: [109, 724]', '3 in 3.14.txt: [727, 770, 809]', '4 in 3.21.txt: [363, 364, 380, 616]', '8 in 3.24.txt: [41, 164, 168, 189, 577, 634, 639, 854]', '5 in 3.6.txt: [137, 698, 729, 743, 752]', '2 in 3.7.txt: [209, 1313]', '1 in 3.8.txt: [733]', '1 in 4.10.txt: [463]', '8 in 4.19.txt: [149, 163, 182, 189, 210, 230, 643, 686]', '1 in 4.2.txt: [1223]', '3 in 4.20.txt: [95, 585, 587]', '1 in 4.22.txt: [602]', '3 in 4.9.txt: [62, 967, 990]', '4 in 5.1.txt: [288, 323, 773, 1229]', '1 in 5.13.txt: [843]', '2 in 5.15.txt: [122, 139]', '5 in 5.17.txt: [26, 766, 772, 786, 793]', '2 in 5.3.txt: [1988, 2121]', '1 in 5.9.txt: [340]', '2 in 6.12.txt: [83, 574]', '1 in 6.16.txt: [796]', '1 in 6.18.txt: [371]', '3 in 6.19.txt: [50, 60, 603]', '1 in 6.2.txt: [171]', '2 in 6.22.txt: [969, 979]', '2 in 6.25.txt: [1988, 2121]', '1 in 6.6.txt: [1500]', '1 in 6.7.txt: [422]', '2 in 7.1.txt: [1988, 2121]', '3 in 7.12.txt: [547, 556, 570]', '1 in 7.18.txt: [86]', '8 in 7.5.txt: [129, 132, 134, 1101, 1107, 1122, 1131, 1132]', '5 in 7.6.txt: [195, 209, 1529, 1541, 1560]', '1 in 7.8.txt: [806]'])\n",
            "Doc_ids containing the term2: KeysView(86 total occurances: ['2 in 3.13.txt: [753, 771]', '9 in 3.14.txt: [27, 78, 145, 158, 243, 249, 263, 275, 712]', '8 in 3.17.txt: [30, 41, 151, 198, 278, 423, 426, 954]', '6 in 3.19.txt: [137, 522, 531, 550, 573, 1062]', '3 in 3.2.txt: [24, 239, 280]', '3 in 3.21.txt: [361, 378, 613]', '1 in 3.4.txt: [147]', '3 in 3.6.txt: [549, 742, 751]', '1 in 3.8.txt: [38]', '3 in 3.9.txt: [168, 239, 611]', '6 in 4.10.txt: [191, 194, 199, 211, 464, 722]', '1 in 4.16.txt: [139]', '2 in 4.19.txt: [207, 232]', '2 in 4.2.txt: [23, 1235]', '1 in 4.3.txt: [94]', '3 in 4.4.txt: [105, 209, 405]', '1 in 4.9.txt: [1002]', '1 in 5.1.txt: [286]', '2 in 5.10.txt: [191, 322]', '1 in 5.15.txt: [119]', '3 in 5.16.txt: [119, 126, 144]', '3 in 5.17.txt: [23, 143, 504]', '1 in 5.22.txt: [272]', '1 in 5.8.txt: [891]', '1 in 5.9.txt: [341]', '1 in 6.18.txt: [1260]', '2 in 6.19.txt: [59, 612]', '2 in 6.2.txt: [145, 220]', '1 in 6.22.txt: [978]', '2 in 6.5.txt: [30, 196]', '1 in 6.7.txt: [423]', '1 in 6.8.txt: [649]', '2 in 7.12.txt: [198, 529]', '1 in 7.19.txt: [166]', '1 in 7.2.txt: [236]', '1 in 7.25.txt: [236]', '1 in 7.5.txt: [1296]', '1 in 7.6.txt: [1559]', '1 in 7.8.txt: [827]'])\n",
            "- term1_position 109\n",
            "-- term2_position 753\n",
            "- term1_position 724\n",
            "-- term2_position 753\n",
            "Appended! abs(753 - 724)= 29\n",
            "-- term2_position 771\n",
            "Appended! abs(771 - 724)= 47\n",
            "- term1_position 727\n",
            "-- term2_position 27\n",
            "-- term2_position 78\n",
            "-- term2_position 145\n",
            "-- term2_position 158\n",
            "-- term2_position 243\n",
            "-- term2_position 249\n",
            "-- term2_position 263\n",
            "-- term2_position 275\n",
            "-- term2_position 712\n",
            "Appended! abs(712 - 727)= 15\n",
            "- term1_position 770\n",
            "-- term2_position 27\n",
            "-- term2_position 78\n",
            "-- term2_position 145\n",
            "-- term2_position 158\n",
            "-- term2_position 243\n",
            "-- term2_position 249\n",
            "-- term2_position 263\n",
            "-- term2_position 275\n",
            "-- term2_position 712\n",
            "Appended! abs(712 - 770)= 58\n",
            "- term1_position 809\n",
            "-- term2_position 27\n",
            "-- term2_position 78\n",
            "-- term2_position 145\n",
            "-- term2_position 158\n",
            "-- term2_position 243\n",
            "-- term2_position 249\n",
            "-- term2_position 263\n",
            "-- term2_position 275\n",
            "-- term2_position 712\n",
            "Appended! abs(712 - 809)= 97\n",
            "- term1_position 363\n",
            "-- term2_position 361\n",
            "Appended! abs(361 - 363)= 2\n",
            "-- term2_position 378\n",
            "Appended! abs(378 - 363)= 15\n",
            "-- term2_position 613\n",
            "- term1_position 364\n",
            "-- term2_position 361\n",
            "Appended! abs(361 - 364)= 3\n",
            "-- term2_position 378\n",
            "Appended! abs(378 - 364)= 14\n",
            "-- term2_position 613\n",
            "- term1_position 380\n",
            "-- term2_position 361\n",
            "Appended! abs(361 - 380)= 19\n",
            "-- term2_position 378\n",
            "Appended! abs(378 - 380)= 2\n",
            "-- term2_position 613\n",
            "- term1_position 616\n",
            "-- term2_position 361\n",
            "-- term2_position 378\n",
            "-- term2_position 613\n",
            "Appended! abs(613 - 616)= 3\n",
            "- term1_position 137\n",
            "-- term2_position 549\n",
            "- term1_position 698\n",
            "-- term2_position 549\n",
            "-- term2_position 742\n",
            "Appended! abs(742 - 698)= 44\n",
            "-- term2_position 751\n",
            "Appended! abs(751 - 698)= 53\n",
            "- term1_position 729\n",
            "-- term2_position 549\n",
            "-- term2_position 742\n",
            "Appended! abs(742 - 729)= 13\n",
            "-- term2_position 751\n",
            "Appended! abs(751 - 729)= 22\n",
            "- term1_position 743\n",
            "-- term2_position 549\n",
            "-- term2_position 742\n",
            "Appended! abs(742 - 743)= 1\n",
            "-- term2_position 751\n",
            "Appended! abs(751 - 743)= 8\n",
            "- term1_position 752\n",
            "-- term2_position 549\n",
            "-- term2_position 742\n",
            "Appended! abs(742 - 752)= 10\n",
            "-- term2_position 751\n",
            "Appended! abs(751 - 752)= 1\n",
            "- term1_position 733\n",
            "-- term2_position 38\n",
            "- term1_position 463\n",
            "-- term2_position 191\n",
            "-- term2_position 194\n",
            "-- term2_position 199\n",
            "-- term2_position 211\n",
            "-- term2_position 464\n",
            "Appended! abs(464 - 463)= 1\n",
            "-- term2_position 722\n",
            "- term1_position 149\n",
            "-- term2_position 207\n",
            "Appended! abs(207 - 149)= 58\n",
            "-- term2_position 232\n",
            "Appended! abs(232 - 149)= 83\n",
            "- term1_position 163\n",
            "-- term2_position 207\n",
            "Appended! abs(207 - 163)= 44\n",
            "-- term2_position 232\n",
            "Appended! abs(232 - 163)= 69\n",
            "- term1_position 182\n",
            "-- term2_position 207\n",
            "Appended! abs(207 - 182)= 25\n",
            "-- term2_position 232\n",
            "Appended! abs(232 - 182)= 50\n",
            "- term1_position 189\n",
            "-- term2_position 207\n",
            "Appended! abs(207 - 189)= 18\n",
            "-- term2_position 232\n",
            "Appended! abs(232 - 189)= 43\n",
            "- term1_position 210\n",
            "-- term2_position 207\n",
            "Appended! abs(207 - 210)= 3\n",
            "-- term2_position 232\n",
            "Appended! abs(232 - 210)= 22\n",
            "- term1_position 230\n",
            "-- term2_position 207\n",
            "Appended! abs(207 - 230)= 23\n",
            "-- term2_position 232\n",
            "Appended! abs(232 - 230)= 2\n",
            "- term1_position 643\n",
            "-- term2_position 207\n",
            "-- term2_position 232\n",
            "- term1_position 686\n",
            "-- term2_position 207\n",
            "-- term2_position 232\n",
            "- term1_position 1223\n",
            "-- term2_position 23\n",
            "-- term2_position 1235\n",
            "Appended! abs(1235 - 1223)= 12\n",
            "- term1_position 62\n",
            "-- term2_position 1002\n",
            "- term1_position 967\n",
            "-- term2_position 1002\n",
            "Appended! abs(1002 - 967)= 35\n",
            "- term1_position 990\n",
            "-- term2_position 1002\n",
            "Appended! abs(1002 - 990)= 12\n",
            "- term1_position 288\n",
            "-- term2_position 286\n",
            "Appended! abs(286 - 288)= 2\n",
            "- term1_position 323\n",
            "-- term2_position 286\n",
            "Appended! abs(286 - 323)= 37\n",
            "- term1_position 773\n",
            "-- term2_position 286\n",
            "- term1_position 1229\n",
            "-- term2_position 286\n",
            "- term1_position 122\n",
            "-- term2_position 119\n",
            "Appended! abs(119 - 122)= 3\n",
            "- term1_position 139\n",
            "-- term2_position 119\n",
            "Appended! abs(119 - 139)= 20\n",
            "- term1_position 26\n",
            "-- term2_position 23\n",
            "Appended! abs(23 - 26)= 3\n",
            "-- term2_position 143\n",
            "- term1_position 766\n",
            "-- term2_position 23\n",
            "-- term2_position 143\n",
            "-- term2_position 504\n",
            "- term1_position 772\n",
            "-- term2_position 23\n",
            "-- term2_position 143\n",
            "-- term2_position 504\n",
            "- term1_position 786\n",
            "-- term2_position 23\n",
            "-- term2_position 143\n",
            "-- term2_position 504\n",
            "- term1_position 793\n",
            "-- term2_position 23\n",
            "-- term2_position 143\n",
            "-- term2_position 504\n",
            "- term1_position 340\n",
            "-- term2_position 341\n",
            "Appended! abs(341 - 340)= 1\n",
            "- term1_position 371\n",
            "-- term2_position 1260\n",
            "- term1_position 50\n",
            "-- term2_position 59\n",
            "Appended! abs(59 - 50)= 9\n",
            "-- term2_position 612\n",
            "- term1_position 60\n",
            "-- term2_position 59\n",
            "Appended! abs(59 - 60)= 1\n",
            "-- term2_position 612\n",
            "- term1_position 603\n",
            "-- term2_position 59\n",
            "-- term2_position 612\n",
            "Appended! abs(612 - 603)= 9\n",
            "- term1_position 171\n",
            "-- term2_position 145\n",
            "Appended! abs(145 - 171)= 26\n",
            "-- term2_position 220\n",
            "Appended! abs(220 - 171)= 49\n",
            "- term1_position 969\n",
            "-- term2_position 978\n",
            "Appended! abs(978 - 969)= 9\n",
            "- term1_position 979\n",
            "-- term2_position 978\n",
            "Appended! abs(978 - 979)= 1\n",
            "- term1_position 422\n",
            "-- term2_position 423\n",
            "Appended! abs(423 - 422)= 1\n",
            "- term1_position 547\n",
            "-- term2_position 198\n",
            "-- term2_position 529\n",
            "Appended! abs(529 - 547)= 18\n",
            "- term1_position 556\n",
            "-- term2_position 198\n",
            "-- term2_position 529\n",
            "Appended! abs(529 - 556)= 27\n",
            "- term1_position 570\n",
            "-- term2_position 198\n",
            "-- term2_position 529\n",
            "Appended! abs(529 - 570)= 41\n",
            "- term1_position 129\n",
            "-- term2_position 1296\n",
            "- term1_position 132\n",
            "-- term2_position 1296\n",
            "- term1_position 134\n",
            "-- term2_position 1296\n",
            "- term1_position 1101\n",
            "-- term2_position 1296\n",
            "- term1_position 1107\n",
            "-- term2_position 1296\n",
            "- term1_position 1122\n",
            "-- term2_position 1296\n",
            "- term1_position 1131\n",
            "-- term2_position 1296\n",
            "- term1_position 1132\n",
            "-- term2_position 1296\n",
            "- term1_position 195\n",
            "-- term2_position 1559\n",
            "- term1_position 209\n",
            "-- term2_position 1559\n",
            "- term1_position 1529\n",
            "-- term2_position 1559\n",
            "Appended! abs(1559 - 1529)= 30\n",
            "- term1_position 1541\n",
            "-- term2_position 1559\n",
            "Appended! abs(1559 - 1541)= 18\n",
            "- term1_position 1560\n",
            "-- term2_position 1559\n",
            "Appended! abs(1559 - 1560)= 1\n",
            "- term1_position 806\n",
            "-- term2_position 827\n",
            "Appended! abs(827 - 806)= 21\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'3.13.txt': [(724, 753), (724, 771)],\n",
              " '3.14.txt': [(727, 712), (770, 712), (809, 712)],\n",
              " '3.21.txt': [(363, 361),\n",
              "  (363, 378),\n",
              "  (364, 361),\n",
              "  (364, 378),\n",
              "  (380, 361),\n",
              "  (380, 378),\n",
              "  (616, 613)],\n",
              " '3.6.txt': [(698, 742),\n",
              "  (698, 751),\n",
              "  (729, 742),\n",
              "  (729, 751),\n",
              "  (743, 742),\n",
              "  (743, 751),\n",
              "  (752, 742),\n",
              "  (752, 751)],\n",
              " '3.8.txt': [],\n",
              " '4.10.txt': [(463, 464)],\n",
              " '4.19.txt': [(149, 207),\n",
              "  (149, 232),\n",
              "  (163, 207),\n",
              "  (163, 232),\n",
              "  (182, 207),\n",
              "  (182, 232),\n",
              "  (189, 207),\n",
              "  (189, 232),\n",
              "  (210, 207),\n",
              "  (210, 232),\n",
              "  (230, 207),\n",
              "  (230, 232)],\n",
              " '4.2.txt': [(1223, 1235)],\n",
              " '4.9.txt': [(967, 1002), (990, 1002)],\n",
              " '5.1.txt': [(288, 286), (323, 286)],\n",
              " '5.15.txt': [(122, 119), (139, 119)],\n",
              " '5.17.txt': [(26, 23)],\n",
              " '5.9.txt': [(340, 341)],\n",
              " '6.18.txt': [],\n",
              " '6.19.txt': [(50, 59), (60, 59), (603, 612)],\n",
              " '6.2.txt': [(171, 145), (171, 220)],\n",
              " '6.22.txt': [(969, 978), (979, 978)],\n",
              " '6.7.txt': [(422, 423)],\n",
              " '7.12.txt': [(547, 529), (556, 529), (570, 529)],\n",
              " '7.5.txt': [],\n",
              " '7.6.txt': [(1529, 1559), (1541, 1559), (1560, 1559)],\n",
              " '7.8.txt': [(806, 827)]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}