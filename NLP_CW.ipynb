{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonasVerbickas/test-jupyter/blob/main/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import time\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from collections import Counter\n",
        "from collections import UserDict\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "BTTGCTeE65K-"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm not sure how you will access the corpus on your side.\n",
        "Personally, I've uploaded it to my Google drive."
      ],
      "metadata": {
        "id": "tF3YIutv5fK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A59xTdZA0OzU",
        "outputId": "22455be1-548d-4645-9e27-6d8dae628f94"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter = nltk.PorterStemmer()"
      ],
      "metadata": {
        "id": "9Kh-pY5D8H1e"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download additional NLTK resources\n",
        "These are required for tokenization and stop-word removal"
      ],
      "metadata": {
        "id": "tSyqexBZ3npQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# I convert it into a set, because it results in faster `in` look-ups\n",
        "STOP_WORDS = nltk.corpus.stopwords.words('english')\n",
        "# convert to set() for faster `in` checks\n",
        "STOP_WORDS = set(STOP_WORDS)\n",
        "# every single document has `episode` mentioned in it multiple times\n",
        "# it doesn't help to differentiate episodes and should be considered a stop-word\n",
        "STOP_WORDS.add('episode')\n",
        "STOP_WORDS.add('episodes')\n",
        "# for some reason would is missing by default\n",
        "STOP_WORDS.add('would')\n",
        "# this is supposed to be used for tokenized 'won't' however it eliminates `won` as in winning as well\n",
        "# I will expand all contractions and this stop-word will not be needed\n",
        "STOP_WORDS.remove('won')\n",
        "STOP_WORDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXosFc5y2vyH",
        "outputId": "af2a8516-f736-4767-be07-017a6dc4cb0d"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'after',\n",
              " 'again',\n",
              " 'against',\n",
              " 'ain',\n",
              " 'all',\n",
              " 'am',\n",
              " 'an',\n",
              " 'and',\n",
              " 'any',\n",
              " 'are',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'as',\n",
              " 'at',\n",
              " 'be',\n",
              " 'because',\n",
              " 'been',\n",
              " 'before',\n",
              " 'being',\n",
              " 'below',\n",
              " 'between',\n",
              " 'both',\n",
              " 'but',\n",
              " 'by',\n",
              " 'can',\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'd',\n",
              " 'did',\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'do',\n",
              " 'does',\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'doing',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'down',\n",
              " 'during',\n",
              " 'each',\n",
              " 'episode',\n",
              " 'episodes',\n",
              " 'few',\n",
              " 'for',\n",
              " 'from',\n",
              " 'further',\n",
              " 'had',\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'has',\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'have',\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'having',\n",
              " 'he',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'into',\n",
              " 'is',\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'll',\n",
              " 'm',\n",
              " 'ma',\n",
              " 'me',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'more',\n",
              " 'most',\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'my',\n",
              " 'myself',\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'now',\n",
              " 'o',\n",
              " 'of',\n",
              " 'off',\n",
              " 'on',\n",
              " 'once',\n",
              " 'only',\n",
              " 'or',\n",
              " 'other',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 're',\n",
              " 's',\n",
              " 'same',\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'so',\n",
              " 'some',\n",
              " 'such',\n",
              " 't',\n",
              " 'than',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'the',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'there',\n",
              " 'these',\n",
              " 'they',\n",
              " 'this',\n",
              " 'those',\n",
              " 'through',\n",
              " 'to',\n",
              " 'too',\n",
              " 'under',\n",
              " 'until',\n",
              " 'up',\n",
              " 've',\n",
              " 'very',\n",
              " 'was',\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'we',\n",
              " 'were',\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'what',\n",
              " 'when',\n",
              " 'where',\n",
              " 'which',\n",
              " 'while',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " \"won't\",\n",
              " 'would',\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'y',\n",
              " 'you',\n",
              " \"you'd\",\n",
              " \"you'll\",\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves'}"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "FIZUgB4Qltb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Initialize helper classes\n",
        "I could've coded everything using tuples/lists instead of these helper classes.\n",
        "\n",
        "However, I feel like these make the code more verbose and remove ambiguity that comes from giving positions in a tuple meaning."
      ],
      "metadata": {
        "id": "1aYg16m74cxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StringWithDocId:\n",
        "  \"\"\"\n",
        "  Used in InvertedIndex.read_data method to create a list of document contents with doc_ids \n",
        "  \"\"\" \n",
        "  def __init__(self, string, doc_id):\n",
        "    self.string = string\n",
        "    self.doc_id = doc_id\n",
        "  \n",
        "  def __str__(self):\n",
        "    return f\"{self.string}: {self.doc_id}\"\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"{self.string}: {self.doc_id}\""
      ],
      "metadata": {
        "id": "P_X_2vKt8lbK"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StringWithDocIdAndPosition(StringWithDocId):\n",
        "  \"\"\"\n",
        "  Stores positions as well.\n",
        "  Used to create & sort list of positional terms.\n",
        "  \n",
        "  \"\"\"\n",
        "  def __init__(self, string, doc_id, position):\n",
        "    super().__init__(string, doc_id)\n",
        "    self.position = position\n",
        "  \n",
        "  def __lt__(token_with_doc_A, token_with_doc_B):\n",
        "    if token_with_doc_A.string != token_with_doc_B.string:\n",
        "      return token_with_doc_A.string < token_with_doc_B.string\n",
        "    elif token_with_doc_A.doc_id != token_with_doc_B.doc_id:\n",
        "      return token_with_doc_A.doc_id < token_with_doc_B.doc_id\n",
        "    else:\n",
        "      return token_with_doc_A.position < token_with_doc_B.position"
      ],
      "metadata": {
        "id": "XSBSe0-PxlCV"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Posting(UserDict):\n",
        "  \"\"\"\n",
        "  This stores the positional information for each term in the postional inverted index.\n",
        "  Some methods have been overriden to its objects behave like dictionary.\n",
        "  Keys are all of documents where this term appears;\n",
        "  Values store the positions, where in that document term appears\n",
        "  {docID: [pos1, pos2, ...]}.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.posting_dic = {}\n",
        "    self.total_occurances = 0\n",
        "  \n",
        "  def __contains__(self, doc_id):\n",
        "    return doc_id in self.posting_dic\n",
        "  \n",
        "  def __iter__(self):\n",
        "      return iter(self.posting_dic.items())\n",
        "\n",
        "  def __getitem__(self, doc_id):\n",
        "      return self.posting_dic[doc_id]\n",
        "    \n",
        "  def get(self, k, default=None):\n",
        "    return self[k]\n",
        "  \n",
        "  def __len__(self):\n",
        "      return len(self.posting_dic)\n",
        "\n",
        "  def add(self, doc_id, position):\n",
        "    if doc_id in self.posting_dic:\n",
        "      self.posting_dic[doc_id].append(position)\n",
        "    else:\n",
        "      self.posting_dic[doc_id] = [position]\n",
        "    self.total_occurances += 1\n",
        "  \n",
        "  def __str__(self):\n",
        "    return f\"{self.total_occurances} total occurances: {[f'{len(positions)} in {doc_id}: {positions}' for doc_id, positions in self.posting_dic.items()]}\"\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return str(self)"
      ],
      "metadata": {
        "id": "1Ts7G2B6TGRX"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this map is from https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/bonus%20content/nlp%20proven%20approach/contractions.py\n",
        "# I found it via https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72\n",
        "CONTRACTION_MAP = {\n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}\n",
        "def expandContractions(text):\n",
        "  for k, v in CONTRACTION_MAP.items():\n",
        "    text = text.replace(k, v)\n",
        "  return text"
      ],
      "metadata": {
        "id": "g-ML3mfxc8mU"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wikipediaPreprocessing(text):\n",
        "  # stop-words and regex only contain lower case versions of words\n",
        "  # therefore tokens must be lowercased in order to match them\n",
        "  # casefold() is a more aggresive version of lower()\n",
        "  # https://docs.python.org/3/library/stdtypes.html#str.casefold\n",
        "  text = text.casefold()\n",
        "  # reduce characters into ascii where meaning is preserved & seprate diacritics into individual characters\n",
        "  text = unicodedata.normalize('NFKD', text)\n",
        "  # remove all non ascii character i.e. separated diacritics\n",
        "  text = text.encode('ASCII', 'ignore').decode('UTF-8')\n",
        "  text = text.replace('[edit]', '')\n",
        "  text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "  # remove table of contents\n",
        "  text = re.sub(r'contents\\s+1\\s+plot.+plot', '', text)\n",
        "  # remove navigational hyperlinks\n",
        "  text = re.sub(r'episode chronology(.|\\n)+list of episodes', '', text)\n",
        "  text = re.sub(r'jump to (navigation|search)', '', text)\n",
        "  # remove other irrelevant wikipedia filler\n",
        "  text = text.replace('from wikipedia, the free encyclopedia', '')\n",
        "  text = text.replace('the simpsons episode', '')\n",
        "  # expand contractions\n",
        "  text =  expandContractions(text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "gpJRsN2bk5Iw"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spelling correction!!\n",
        "From P. Norvig's website: https://norvig.com/spell-correct.html."
      ],
      "metadata": {
        "id": "ppA9N4C4LpmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpellCorrect:\n",
        "\n",
        "  def __init__(self, posting_dict):\n",
        "    self.total_num_of_words = 0\n",
        "    self.word_freq_dic = {} \n",
        "    for key, val in posting_dict.items():\n",
        "      self.total_num_of_words += val.total_occurances\n",
        "      # I don't store positions here, because in case of spell check only frequencies are needed\n",
        "      self.word_freq_dic[key] = self.total_num_of_words\n",
        "\n",
        "  def _P(self, word): \n",
        "      \"Probability of `word`.\"\n",
        "      if word in self.word_freq_dic:\n",
        "        return self.word_freq_dic[word] / self.total_num_of_words\n",
        "      # If a word doesn't exist within the index\n",
        "      # It's probality is 0 - this is a way to get rid of words that are not real\n",
        "      else:\n",
        "        return 0\n",
        "\n",
        "  def correction(self, word): \n",
        "      \"Most probable spelling correction for word.\"\n",
        "      most_probable_correction = max(self._candidates(word), key=self._P)\n",
        "      # if no correction is possible just return None\n",
        "      if self._P(most_probable_correction) == 0:\n",
        "        return None\n",
        "      else:\n",
        "        return most_probable_correction\n",
        "\n",
        "  def _candidates(self, word): \n",
        "      \"Generate possible spelling corrections for word.\"\n",
        "      return (self._known([word]) or self._known(self._edits1(word)) or self._known(self._edits2(word)) or [word])\n",
        "\n",
        "  def _known(self, words): \n",
        "      \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "      return set(w for w in words if w in self.word_freq_dic.keys())\n",
        "\n",
        "  def _edits1(self, word):\n",
        "      \"All edits that are one edit away from `word`.\"\n",
        "      letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "      splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "      deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "      transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "      replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "      inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "      return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "  def _edits2(self, word): \n",
        "      \"All edits that are two edits away from `word`.\"\n",
        "      return (e2 for e1 in self._edits1(word) for e2 in self._edits1(e1))"
      ],
      "metadata": {
        "id": "qM1dEHFgNIiH"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiWordTermSet:\n",
        "  \"\"\"\n",
        "  Used to store multi-word terms;\n",
        "  when prompted finds all matching subsequences that match the stored terms\n",
        "  Currently used for multi-token episode titles, character and location names.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    # this will store terms in different sets based on the number of tokens each term has\n",
        "    # key [2] will have a set of processed terms of 2 tokens in length\n",
        "    self.dict_of_sets = dict()\n",
        "\n",
        "  def add(self, processed_tokens):\n",
        "    # anything of size 1, isn't a multi-word term - don't waste space storing it\n",
        "    if len(processed_tokens) > 1:\n",
        "      if len(processed_tokens) not in self.dict_of_sets:\n",
        "        # this is a set because there are some duplicates in the CSV files\n",
        "        self.dict_of_sets[len(processed_tokens)] = set()\n",
        "      self.dict_of_sets[len(processed_tokens)].add(\" \".join(processed_tokens))\n",
        "\n",
        "  def findMatchingSubsequences(self, list_of_processed_tokens: list) -> set:\n",
        "    \"\"\"\n",
        "    Go through list_of_processed_tokens and try to find matching subsequences \n",
        "    Return all found matches\n",
        "    \"\"\"\n",
        "    list_of_processed_tokens = list_of_processed_tokens[:max(self.dict_of_sets.keys())]\n",
        "    matching_subseqs = set()\n",
        "    for i in self.dict_of_sets.keys():\n",
        "      i_joined_tokens = \" \".join(list_of_processed_tokens[:i])\n",
        "      if i_joined_tokens in self.dict_of_sets[i]:\n",
        "        matching_subseqs.add(i_joined_tokens)\n",
        "    return matching_subseqs\n"
      ],
      "metadata": {
        "id": "5n5MJVlTbYlg"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Inverted Index (THE MOST IMPORTANT BIT)"
      ],
      "metadata": {
        "id": "U0qC9x-N40SG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "4WtSmBsrzqE7"
      },
      "outputs": [],
      "source": [
        "class InvertedIndex:\n",
        "    \"\"\"\n",
        "    Construct Inverted Index\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.inverted_index: dict = {}\n",
        "        self.csv_terms = MultiWordTermSet() \n",
        "        self.ep_titles = MultiWordTermSet() \n",
        "  \n",
        "    def _appendCSV(self, path: str) -> None:\n",
        "      \"\"\"\n",
        "      Used to fill up csv_terms that are later used to index multi-word terms within the corpus\n",
        "      1)opens a csv in the given path\n",
        "      2)processes each term, so that it matches the tokenized corpus\n",
        "      3)and appends to csv_terms set\"\"\"\n",
        "      df = pd.read_csv(path)\n",
        "      set_of_csv_entries = df['name']\n",
        "      for term in set_of_csv_entries:\n",
        "        # there is a bunch of numbered entries (~500) like \"Relative #1\" and \"Relative #2\"\n",
        "        # these should be considered to be the same entry,\n",
        "        # because characters aren't numbered like this in the corpus\n",
        "        term = re.sub(r'#\\d+', '', term)\n",
        "        processed_tokens = self.processListOfTokens(self.process_document(term))\n",
        "        self.csv_terms.add(processed_tokens)\n",
        "    \n",
        "    def _appendTitle(self, text):\n",
        "      \"\"\"This will extract the title (first line) from the given text, process it\n",
        "      lastly append it to list of known titles\"\"\"\n",
        "      unprocessed_ep_title = text.strip().split('\\n')[0]\n",
        "      processed_tokens = self.processListOfTokens(self.process_document(unprocessed_ep_title))\n",
        "      self.ep_titles.add(processed_tokens)\n",
        "\n",
        "    def read_data(self, path: str) -> list:\n",
        "        \"\"\"\n",
        "        Read files from a directory and then append the data of each file into a list.\n",
        "        \"\"\"\n",
        "        document_content_list = []\n",
        "        # go through all of the files in the given directory\n",
        "        print('read_data() has been called')\n",
        "        for file in tqdm(os.listdir(path)):\n",
        "          file_ext = os.path.splitext(file)[1].lower()\n",
        "          filename_with_path = os.path.join(path, file)\n",
        "          # if it's a txt file - append its contents to the output list\n",
        "          if file_ext == '.txt':\n",
        "            with open(filename_with_path, 'r') as f:\n",
        "              text = f.read()\n",
        "              document_content_list.append(StringWithDocId(text, file))\n",
        "              # extract the title and use it as a multi-token indexing\n",
        "              self._appendTitle(text)\n",
        "          # if it's a csv file - assume it's a character/location list and use it for multi-token indexing\n",
        "          elif file_ext == '.csv':\n",
        "            self._appendCSV(filename_with_path)\n",
        "          else:\n",
        "            print(filename_with_path, \" doesn't have the required file extension 'txt' or 'csv' - it will be skipped\")\n",
        "        print(\"Number of documents within the corpus:\", len(document_content_list)) \n",
        "        return document_content_list\n",
        "      \n",
        "    def processListOfTokens(self, tokenized: list) -> list:\n",
        "      \"\"\"\n",
        "      in a given list of tokens: removes stop-words, punctuation and stems the words.\n",
        "      \"\"\"\n",
        "      output = []\n",
        "      for token in tokenized:\n",
        "        # ignore tokens that don't have words/numbers in them i.e. punctuation only\n",
        "        if not re.search('\\w', token):\n",
        "          continue\n",
        "        # delete hyphens\n",
        "        token = token.replace('-', '')\n",
        "        # ignore stop-words\n",
        "        if token in STOP_WORDS:\n",
        "          continue\n",
        "        # apply stemming\n",
        "        stemmed = porter.stem(token)\n",
        "        output.append(stemmed)\n",
        "      return output\n",
        "\n",
        "    def process_document(self, document: str) -> list:\n",
        "        \"\"\"\n",
        "        pre-process a document and return a list of its terms\n",
        "        str->list\"\"\"\n",
        "        # Wikipedia hyperlinks should be removed\n",
        "        text = wikipediaPreprocessing(document)\n",
        "        tokenized = nltk.tokenize.word_tokenize(text)\n",
        "        # remove stop-words & apply stemming\n",
        "        filtered_tokens = self.processListOfTokens(tokenized)\n",
        "        return filtered_tokens\n",
        "\n",
        "    def _findMultiWordTerms(self, processed_token_subseq: list):\n",
        "      \"\"\"\n",
        "      This method tries to find all known multi-token subsections; starting from index [0] of the given processed_substring\n",
        "      \"\"\"        \n",
        "      csv_subseqs = self.csv_terms.findMatchingSubsequences(processed_token_subseq)\n",
        "      title_subseqs = self.ep_titles.findMatchingSubsequences(processed_token_subseq)\n",
        "      return csv_subseqs.union(title_subseqs)\n",
        "    \n",
        "    def index_corpus(self, documents: list) -> None:\n",
        "        \"\"\"\n",
        "        index given documents\n",
        "        list->None\"\"\"\n",
        "        starting_time = time.perf_counter()\n",
        "        token_list = []\n",
        "\n",
        "        # 1. Generate token list\n",
        "        print(\"1. Generate token list\")\n",
        "        for doc in tqdm(documents):\n",
        "          curr_doc_id = doc.doc_id\n",
        "          tokenized_doc = self.process_document(doc.string)\n",
        "          for i, token in enumerate(tokenized_doc):\n",
        "            matching_subseqs = self._findMultiWordTerms(tokenized_doc[i:])\n",
        "            # append all multi-word matches\n",
        "            for match in matching_subseqs:\n",
        "              match_with_doc_id_and_pos = StringWithDocIdAndPosition(match, curr_doc_id, i)\n",
        "              token_list.append(match_with_doc_id_and_pos)\n",
        "            # append current word\n",
        "            token_with_doc_id_and_pos = StringWithDocIdAndPosition(token, curr_doc_id, i)\n",
        "            token_list.append(token_with_doc_id_and_pos)\n",
        "        # 2. Sort\n",
        "        print(\"Sorting token list\")\n",
        "        sorted_token_list = sorted(token_list)\n",
        "        # 3. Convert into dictionary of postings\n",
        "        print(\"Creating a positional dictionary of postings\")\n",
        "        for i, token in enumerate(tqdm(sorted_token_list)):\n",
        "          if token.string not in self.inverted_index:\n",
        "            self.inverted_index[token.string] = Posting()\n",
        "          self.inverted_index[token.string].add(token.doc_id, token.position)\n",
        "        # Initialize spell-correct\n",
        "        self.spell_correct = SpellCorrect(self.inverted_index)\n",
        "        # Print out some details about the dataset\n",
        "        total_time_taken = round(time.perf_counter() - starting_time, 4)\n",
        "        print(f\"It took: {total_time_taken} seconds to index the whole corpus.\")\n",
        "        print(f\"It has {len(self.inverted_index)} entries in total.\")\n",
        "\n",
        "    def _processQuery(self, q: str) -> str:\n",
        "        query_as_list_of_processed_tokens = self.processListOfTokens(self.process_document(q))\n",
        "        # if query is a stop-word it will return None\n",
        "        if len(query_as_list_of_processed_tokens) == 0:\n",
        "          print(f\"Query '{q}' a stop-word\")\n",
        "          return None\n",
        "        # join a processed multi-word query\n",
        "        term = \" \".join(query_as_list_of_processed_tokens)\n",
        "        print(f\"{q} -> {term}\", end=\"; \")\n",
        "        if term in self.inverted_index:\n",
        "          return term\n",
        "        # attempt spell-correct\n",
        "        else:\n",
        "          most_probable_correction = self.spell_correct.correction(term)\n",
        "          if most_probable_correction == None:\n",
        "            print(\"No viable spelling fix was found\")\n",
        "          return most_probable_correction\n",
        "      \n",
        "    def dump(self, path: str) -> None:\n",
        "        \"\"\"\n",
        "        provide a dump function to show index entries for a given set of terms        \n",
        "        \"\"\"\n",
        "        print(\"passed_in_query -> query_after_processing: [list_of_occurances]\")\n",
        "        if os.path.exists(path) == False:\n",
        "          print(\"Path to file you provided doesn't exist\")\n",
        "          return\n",
        "        with open(path, 'r') as f:\n",
        "          file_contents = f.read()\n",
        "          examples = file_contents.split('\\n')\n",
        "          for query in examples:\n",
        "            processed_query = self._processQuery(query)\n",
        "            # if even after spell-correction no matching terms are found processed query will be None\n",
        "            if processed_query is not None:\n",
        "              print(processed_query, self.inverted_index[processed_query])\n",
        "     \n",
        "    def proximity_search(self, term1: str, term2: str, window_size: int = 3) -> dict:\n",
        "        \"\"\"\n",
        "        1) check whether given two terms appear within a window\n",
        "        2) calculate the number of their co-existance in a document\n",
        "        3) add the document id and the number of matches into a dict\n",
        "        return the dict\"\"\"\n",
        "        term1 = self._processQuery(term1)\n",
        "        if term1 is None:\n",
        "          print(\"Cannot find an entry in Inverted Index for\", term1)\n",
        "          return\n",
        "        term2 = self._processQuery(term2)\n",
        "        if term2 is None:\n",
        "          print(\"Cannot find an entry in Inverted Index for\", term2)\n",
        "          return\n",
        "        documents_containing_both_terms = {}\n",
        "        # i'm aware that this is usually implemented using `while` loops\n",
        "        # however in python I can do it using for loops\n",
        "        for term1_doc_id, term1_positions in self.inverted_index[term1]:\n",
        "          # if both terms can be found in the same document\n",
        "          if term1_doc_id in self.inverted_index[term2]:\n",
        "            for term1_position in term1_positions:\n",
        "              for term2_position in self.inverted_index[term2][term1_doc_id]:\n",
        "                if abs(term2_position - term1_position) <= window_size:\n",
        "                  if term1_doc_id not in documents_containing_both_terms:\n",
        "                    documents_containing_both_terms[term1_doc_id] = []\n",
        "                  documents_containing_both_terms[term1_doc_id].append((term1_position, term2_position))\n",
        "                # if term2 has passed the window of term1, move on to another term1 position\n",
        "                elif term2_position - term1_position > window_size:\n",
        "                  break\n",
        "        return documents_containing_both_terms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing my implementation"
      ],
      "metadata": {
        "id": "oFcrQZ0nJMeF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "3n4tuVF-zqE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19df0d5a-e499-4189-90e3-9afff2fdb856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read_data() has been called\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:02<00:00, 41.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents within the corpus: 118\n",
            "1. Generate token list\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [00:07<00:00, 15.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorting token list\n",
            "Creating a positional dictionary of postings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 129241/129241 [00:00<00:00, 210047.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took: 8.8111 seconds to index the whole corpus.\n",
            "It has 11471 entries in total.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    \"main call function\"\n",
        "    index = InvertedIndex() # initilaise the index\n",
        "    corpus = index.read_data('/content/drive/MyDrive/Colab Notebooks/Simpsons2022') # specify the directory path in which files are located\n",
        "    index.index_corpus(corpus) # index documents/corpus\n",
        "    return index\n",
        "index = main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test `dump` method using `.txt` provided on BlackBoard"
      ],
      "metadata": {
        "id": "_fvVChQ0l0NZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.dump(\"/content/drive/MyDrive/Colab Notebooks/26957722.txt\")"
      ],
      "metadata": {
        "id": "G94h70akKT-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbae63f-c5e8-42d7-d61e-31f2d27c6378"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passed_in_query -> query_after_processing: [list_of_occurances]\n",
            "Bart -> bart; bart 1231 total occurances: ['17 in 3.1.txt: [117, 287, 318, 368, 391, 396, 410, 424, 573, 583, 845, 848, 1072, 1093, 1197, 1727, 1759]', '4 in 3.10.txt: [922, 1090, 1213, 1290]', '4 in 3.11.txt: [418, 609, 707, 735]', '12 in 3.12.txt: [115, 122, 184, 213, 220, 266, 271, 482, 485, 504, 557, 654]', '30 in 3.13.txt: [1, 3, 49, 67, 91, 102, 132, 187, 191, 201, 228, 275, 288, 294, 306, 312, 336, 349, 365, 597, 674, 696, 756, 791, 860, 864, 896, 913, 1072, 1082]', '2 in 3.14.txt: [365, 385]', '9 in 3.15.txt: [91, 119, 278, 303, 393, 523, 547, 560, 698]', '29 in 3.16.txt: [0, 2, 45, 64, 77, 110, 141, 209, 222, 234, 265, 286, 302, 315, 326, 335, 382, 464, 475, 483, 587, 608, 670, 692, 781, 880, 933, 953, 1010]', '1 in 3.17.txt: [995]', '25 in 3.18.txt: [26, 39, 95, 125, 210, 230, 239, 271, 275, 288, 356, 365, 402, 442, 474, 587, 614, 645, 664, 802, 835, 903, 928, 938, 953]', '9 in 3.19.txt: [124, 230, 254, 341, 359, 370, 769, 786, 1258]', '3 in 3.2.txt: [281, 532, 782]', '3 in 3.20.txt: [286, 952, 1664]', '17 in 3.21.txt: [114, 121, 127, 131, 201, 243, 246, 300, 335, 361, 378, 389, 477, 566, 646, 792, 819]', '6 in 3.22.txt: [86, 215, 232, 247, 328, 338]', '26 in 3.23.txt: [0, 5, 10, 78, 101, 120, 129, 177, 230, 237, 262, 271, 284, 296, 321, 326, 329, 341, 474, 491, 512, 513, 522, 530, 577, 702]', '2 in 3.24.txt: [270, 351]', '10 in 3.3.txt: [110, 297, 320, 350, 358, 584, 799, 803, 833, 887]', '34 in 3.4.txt: [0, 2, 42, 70, 89, 103, 111, 196, 223, 242, 256, 281, 292, 298, 313, 325, 331, 376, 389, 410, 590, 593, 601, 617, 635, 661, 673, 691, 711, 750, 793, 853, 875, 928]', '17 in 3.5.txt: [37, 112, 357, 370, 380, 396, 401, 406, 453, 494, 801, 824, 836, 851, 861, 863, 869]', '14 in 3.6.txt: [48, 106, 233, 244, 260, 355, 391, 411, 433, 458, 620, 770, 890, 925]', '21 in 3.7.txt: [79, 124, 283, 298, 316, 363, 388, 393, 409, 416, 425, 435, 815, 834, 992, 999, 1006, 1038, 1039, 1190, 1214]', '1 in 3.8.txt: [327]', '21 in 3.9.txt: [78, 83, 92, 111, 200, 208, 224, 248, 256, 264, 273, 285, 303, 318, 363, 371, 437, 457, 469, 635, 695]', '13 in 4.1.txt: [111, 125, 137, 144, 153, 161, 229, 261, 274, 279, 289, 390, 622]', '22 in 4.10.txt: [12, 14, 228, 318, 332, 338, 348, 354, 357, 469, 481, 522, 530, 541, 1080, 1092, 1106, 1116, 1147, 1158, 1175, 1245]', '3 in 4.11.txt: [334, 477, 533]', '1 in 4.12.txt: [372]', '9 in 4.13.txt: [98, 135, 224, 260, 270, 285, 315, 516, 549]', '16 in 4.14.txt: [84, 175, 186, 197, 246, 359, 392, 560, 568, 582, 593, 609, 630, 643, 737, 739]', '6 in 4.15.txt: [342, 687, 766, 871, 927, 978]', '10 in 4.16.txt: [93, 148, 173, 183, 214, 334, 408, 428, 527, 544]', '18 in 4.18.txt: [77, 80, 186, 191, 257, 271, 293, 446, 506, 602, 662, 664, 670, 676, 681, 693, 717, 799]', '11 in 4.19.txt: [70, 128, 175, 184, 194, 249, 251, 406, 551, 578, 726]', '3 in 4.2.txt: [229, 1035, 1586]', '8 in 4.20.txt: [88, 173, 185, 215, 218, 263, 332, 361]', '3 in 4.21.txt: [337, 515, 913]', '7 in 4.22.txt: [120, 227, 350, 358, 377, 412, 1410]', '1 in 4.4.txt: [45]', '11 in 4.5.txt: [86, 96, 182, 205, 226, 441, 462, 474, 531, 676, 816]', '19 in 4.6.txt: [67, 84, 130, 142, 156, 173, 176, 193, 201, 225, 233, 236, 243, 266, 273, 283, 292, 311, 671]', '18 in 4.7.txt: [113, 241, 251, 257, 275, 329, 339, 343, 352, 460, 469, 545, 643, 654, 686, 695, 734, 747]', '7 in 4.8.txt: [102, 170, 191, 253, 260, 276, 321]', '1 in 4.9.txt: [792]', '4 in 5.1.txt: [147, 264, 1034, 1350]', '2 in 5.10.txt: [121, 273]', '4 in 5.11.txt: [210, 496, 668, 812]', '37 in 5.12.txt: [0, 3, 6, 14, 72, 92, 111, 172, 211, 221, 230, 239, 245, 259, 278, 283, 292, 301, 329, 341, 355, 395, 412, 485, 519, 567, 647, 663, 672, 687, 700, 713, 770, 782, 799, 817, 843]', '1 in 5.13.txt: [499]', '1 in 5.14.txt: [873]', '4 in 5.15.txt: [665, 759, 777, 807]', '2 in 5.16.txt: [518, 910]', '22 in 5.17.txt: [0, 3, 54, 74, 96, 196, 213, 222, 236, 255, 275, 286, 323, 377, 395, 431, 540, 548, 612, 682, 922, 965]', '21 in 5.18.txt: [43, 92, 100, 111, 211, 220, 249, 253, 260, 278, 283, 296, 303, 322, 345, 354, 372, 410, 418, 435, 660]', '19 in 5.19.txt: [109, 208, 217, 271, 298, 354, 363, 374, 378, 424, 442, 453, 464, 500, 551, 642, 704, 822, 848]', '3 in 5.2.txt: [332, 456, 751]', '26 in 5.20.txt: [93, 100, 204, 217, 251, 265, 269, 304, 336, 346, 358, 422, 424, 443, 469, 479, 525, 570, 574, 584, 619, 644, 705, 866, 914, 922]', '8 in 5.21.txt: [249, 269, 286, 312, 706, 731, 833, 871]', '5 in 5.22.txt: [283, 290, 298, 394, 419]', '4 in 5.3.txt: [340, 395, 911, 1427]', '1 in 5.4.txt: [326]', '31 in 5.5.txt: [44, 134, 215, 240, 443, 463, 489, 503, 511, 539, 549, 568, 571, 577, 640, 667, 689, 703, 713, 720, 841, 1011, 1063, 1108, 1162, 1176, 1320, 1328, 1434, 1465, 1569]', '1 in 5.6.txt: [221]', '19 in 5.7.txt: [0, 4, 63, 99, 106, 116, 132, 213, 258, 287, 317, 362, 366, 378, 389, 395, 444, 472, 902]', '15 in 5.8.txt: [86, 98, 185, 211, 223, 254, 270, 322, 338, 466, 536, 566, 755, 873, 893]', '10 in 5.9.txt: [44, 113, 301, 311, 327, 339, 369, 378, 666, 1285]', '25 in 6.1.txt: [0, 2, 54, 73, 131, 161, 169, 195, 208, 217, 245, 272, 284, 351, 378, 410, 413, 433, 466, 471, 628, 724, 751, 797, 917]', '6 in 6.10.txt: [42, 297, 337, 340, 477, 487]', '1 in 6.12.txt: [292]', '1 in 6.13.txt: [335]', '9 in 6.14.txt: [0, 3, 49, 69, 94, 132, 149, 617, 629]', '33 in 6.16.txt: [0, 3, 58, 78, 85, 104, 141, 159, 182, 194, 204, 223, 240, 243, 264, 272, 285, 293, 304, 324, 331, 341, 367, 371, 395, 515, 604, 635, 681, 749, 814, 839, 1076]', '11 in 6.17.txt: [91, 123, 351, 367, 380, 391, 400, 433, 478, 535, 779]', '6 in 6.18.txt: [614, 616, 625, 638, 646, 778]', '5 in 6.19.txt: [192, 439, 477, 487, 514]', '4 in 6.2.txt: [277, 455, 477, 814]', '6 in 6.20.txt: [269, 292, 315, 335, 346, 580]', '11 in 6.21.txt: [83, 207, 248, 323, 337, 370, 624, 656, 729, 749, 754]', '18 in 6.22.txt: [94, 107, 262, 276, 287, 300, 317, 339, 394, 401, 409, 445, 462, 475, 759, 918, 927, 1138]', '2 in 6.23.txt: [308, 703]', '8 in 6.24.txt: [148, 198, 210, 247, 289, 350, 422, 440]', '4 in 6.25.txt: [340, 395, 911, 1427]', '4 in 6.3.txt: [432, 439, 518, 583]', '8 in 6.4.txt: [111, 127, 158, 165, 185, 211, 536, 646]', '8 in 6.5.txt: [102, 211, 234, 275, 291, 322, 359, 387]', '10 in 6.6.txt: [250, 288, 366, 463, 587, 604, 613, 634, 639, 679]', '43 in 6.7.txt: [0, 3, 65, 89, 96, 117, 136, 194, 206, 218, 228, 234, 247, 256, 278, 284, 295, 303, 340, 345, 359, 373, 389, 465, 482, 508, 585, 612, 681, 695, 720, 724, 745, 791, 803, 824, 840, 868, 895, 947, 957, 961, 984]', '12 in 6.8.txt: [75, 166, 176, 218, 232, 239, 249, 362, 458, 493, 591, 702]', '2 in 6.9.txt: [124, 449]', '4 in 7.1.txt: [340, 395, 911, 1427]', '3 in 7.10.txt: [835, 839, 866]', '24 in 7.11.txt: [87, 96, 155, 176, 189, 210, 221, 239, 251, 263, 273, 282, 298, 310, 321, 334, 347, 525, 542, 624, 638, 650, 706, 759]', '5 in 7.12.txt: [95, 279, 301, 647, 653]', '16 in 7.13.txt: [28, 101, 193, 194, 213, 225, 243, 258, 289, 306, 471, 484, 855, 883, 902, 1038]', '20 in 7.15.txt: [0, 5, 63, 82, 100, 172, 180, 193, 206, 214, 263, 268, 288, 320, 598, 625, 656, 677, 728, 741]', '25 in 7.18.txt: [17, 142, 150, 190, 275, 282, 297, 321, 336, 352, 372, 385, 396, 428, 456, 505, 523, 582, 665, 687, 698, 810, 1146, 1290, 1322]', '12 in 7.2.txt: [92, 94, 198, 211, 282, 293, 311, 323, 328, 357, 764, 772]', '24 in 7.20.txt: [0, 18, 61, 80, 101, 222, 235, 258, 310, 328, 351, 362, 366, 385, 395, 408, 451, 495, 632, 635, 724, 796, 808, 829]', '4 in 7.21.txt: [266, 274, 298, 500]', '14 in 7.22.txt: [147, 150, 231, 283, 336, 346, 378, 389, 405, 428, 458, 467, 477, 802]', '1 in 7.23.txt: [62]', '2 in 7.24.txt: [181, 254]', '12 in 7.25.txt: [92, 94, 198, 211, 282, 293, 311, 323, 328, 357, 764, 772]', '9 in 7.3.txt: [41, 178, 217, 230, 278, 460, 519, 596, 630]', '47 in 7.4.txt: [0, 3, 6, 57, 77, 101, 186, 231, 239, 240, 258, 264, 270, 300, 309, 324, 333, 344, 349, 360, 416, 601, 657, 688, 736, 759, 804, 832, 843, 861, 864, 875, 913, 942, 953, 965, 978, 983, 1066, 1105, 1127, 1182, 1240, 1248, 1255, 1265, 1275]', '2 in 7.5.txt: [240, 316]', '16 in 7.6.txt: [462, 500, 530, 539, 547, 556, 573, 633, 694, 702, 708, 1036, 1040, 1046, 1060, 1296]', '3 in 7.7.txt: [221, 643, 928]', '1 in 7.8.txt: [237]', '6 in 7.9.txt: [104, 290, 363, 374, 389, 404]']\n",
            "first -> first; first 344 total occurances: ['7 in 3.1.txt: [83, 91, 902, 923, 1469, 1701, 1851]', '7 in 3.10.txt: [74, 129, 208, 576, 706, 1204, 1390]', '2 in 3.11.txt: [99, 263]', '4 in 3.12.txt: [177, 192, 781, 788]', '2 in 3.13.txt: [200, 412]', '2 in 3.15.txt: [617, 690]', '3 in 3.16.txt: [55, 112, 490]', '5 in 3.17.txt: [193, 512, 600, 1051, 1221]', '3 in 3.18.txt: [324, 351, 579]', '3 in 3.19.txt: [44, 921, 955]', '5 in 3.2.txt: [117, 423, 473, 692, 1258]', '6 in 3.20.txt: [530, 758, 795, 878, 1582, 1640]', '2 in 3.21.txt: [524, 533]', '6 in 3.22.txt: [77, 131, 146, 416, 429, 455]', '2 in 3.3.txt: [405, 448]', '6 in 3.4.txt: [122, 224, 445, 570, 880, 912]', '9 in 3.5.txt: [146, 434, 462, 487, 509, 524, 532, 584, 663]', '2 in 3.6.txt: [127, 573]', '7 in 3.7.txt: [59, 88, 190, 312, 572, 1183, 1235]', '6 in 3.8.txt: [43, 150, 217, 519, 613, 733]', '1 in 3.9.txt: [322]', '5 in 4.1.txt: [51, 360, 458, 465, 634]', '22 in 4.10.txt: [2, 6, 10, 63, 73, 90, 98, 106, 164, 219, 346, 388, 392, 409, 546, 745, 909, 991, 1006, 1047, 1151, 1209]', '6 in 4.12.txt: [173, 467, 481, 714, 840, 1131]', '3 in 4.14.txt: [70, 602, 843]', '2 in 4.15.txt: [426, 443]', '4 in 4.16.txt: [98, 354, 399, 426]', '2 in 4.17.txt: [627, 965]', '5 in 4.18.txt: [115, 120, 379, 490, 494]', '2 in 4.19.txt: [224, 547]', '2 in 4.2.txt: [75, 524]', '3 in 4.20.txt: [129, 439, 535]', '3 in 4.21.txt: [358, 368, 474]', '3 in 4.22.txt: [91, 736, 742]', '5 in 4.3.txt: [453, 459, 466, 487, 809]', '3 in 4.4.txt: [42, 79, 313]', '3 in 4.6.txt: [343, 393, 438]', '2 in 4.8.txt: [173, 443]', '1 in 4.9.txt: [995]', '5 in 5.1.txt: [93, 330, 388, 532, 969]', '3 in 5.10.txt: [467, 604, 618]', '6 in 5.12.txt: [123, 302, 442, 570, 628, 852]', '5 in 5.13.txt: [315, 419, 489, 510, 948]', '4 in 5.15.txt: [95, 271, 548, 553]', '1 in 5.17.txt: [131]', '2 in 5.18.txt: [388, 452]', '4 in 5.19.txt: [562, 580, 638, 919]', '2 in 5.2.txt: [762, 834]', '1 in 5.21.txt: [603]', '2 in 5.22.txt: [211, 216]', '4 in 5.3.txt: [1098, 1505, 1837, 2248]', '4 in 5.4.txt: [57, 99, 500, 547]', '6 in 5.5.txt: [335, 742, 902, 910, 1048, 1229]', '1 in 5.7.txt: [139]', '1 in 5.8.txt: [839]', '3 in 5.9.txt: [310, 313, 939]', '3 in 6.1.txt: [56, 254, 772]', '1 in 6.10.txt: [76]', '1 in 6.11.txt: [84]', '1 in 6.12.txt: [477]', '3 in 6.13.txt: [95, 361, 406]', '2 in 6.14.txt: [349, 421]', '2 in 6.15.txt: [428, 559]', '1 in 6.16.txt: [921]', '1 in 6.17.txt: [418]', '4 in 6.18.txt: [81, 192, 528, 990]', '2 in 6.19.txt: [483, 775]', '3 in 6.2.txt: [122, 465, 539]', '2 in 6.20.txt: [479, 498]', '1 in 6.21.txt: [35]', '6 in 6.22.txt: [159, 189, 572, 645, 712, 756]', '1 in 6.23.txt: [245]', '2 in 6.24.txt: [25, 592]', '4 in 6.25.txt: [1098, 1505, 1837, 2248]', '2 in 6.3.txt: [386, 755]', '1 in 6.4.txt: [65]', '3 in 6.5.txt: [155, 520, 643]', '9 in 6.6.txt: [162, 480, 581, 784, 850, 859, 954, 1058, 1367]', '2 in 6.7.txt: [459, 587]', '3 in 6.8.txt: [59, 315, 354]', '1 in 6.9.txt: [570]', '4 in 7.1.txt: [1098, 1505, 1837, 2248]', '2 in 7.10.txt: [68, 465]', '3 in 7.11.txt: [431, 436, 451]', '1 in 7.12.txt: [440]', '2 in 7.13.txt: [708, 724]', '4 in 7.14.txt: [106, 312, 327, 388]', '1 in 7.15.txt: [501]', '3 in 7.16.txt: [121, 681, 1037]', '1 in 7.17.txt: [426]', '6 in 7.18.txt: [724, 973, 1022, 1030, 1045, 1254]', '2 in 7.19.txt: [434, 809]', '3 in 7.20.txt: [344, 533, 689]', '3 in 7.21.txt: [670, 679, 847]', '1 in 7.23.txt: [605]', '3 in 7.3.txt: [120, 297, 585]', '3 in 7.4.txt: [68, 493, 582]', '4 in 7.5.txt: [103, 455, 467, 541]', '9 in 7.6.txt: [94, 185, 221, 489, 759, 799, 904, 1121, 1166]', '2 in 7.7.txt: [404, 439]', '3 in 7.8.txt: [88, 114, 121]', '3 in 7.9.txt: [136, 468, 508]']\n",
            "image -> imag; imag 21 total occurances: ['4 in 3.16.txt: [163, 630, 651, 1090]', '1 in 3.18.txt: [749]', '1 in 3.24.txt: [819]', '2 in 3.7.txt: [861, 1135]', '1 in 3.9.txt: [759]', '1 in 4.15.txt: [9]', '1 in 5.12.txt: [12]', '1 in 5.13.txt: [1173]', '1 in 5.4.txt: [5]', '2 in 7.18.txt: [7, 253]', '1 in 7.2.txt: [222]', '1 in 7.21.txt: [1485]', '1 in 7.25.txt: [222]', '1 in 7.5.txt: [1377]', '2 in 7.6.txt: [213, 1009]']\n",
            "montage -> montag; montag 20 total occurances: ['1 in 3.16.txt: [513]', '1 in 3.21.txt: [733]', '3 in 4.18.txt: [324, 369, 697]', '1 in 4.4.txt: [523]', '3 in 6.3.txt: [464, 471, 574]', '9 in 7.10.txt: [55, 264, 421, 670, 777, 869, 876, 884, 908]', '2 in 7.3.txt: [396, 402]']\n",
            "well -> well; well 146 total occurances: ['3 in 3.1.txt: [1238, 1427, 1683]', '2 in 3.10.txt: [226, 1368]', '13 in 3.13.txt: [80, 233, 246, 252, 272, 309, 359, 446, 620, 656, 676, 990, 1019]', '1 in 3.14.txt: [918]', '2 in 3.15.txt: [143, 428]', '3 in 3.16.txt: [279, 885, 928]', '2 in 3.17.txt: [792, 1415]', '2 in 3.18.txt: [887, 969]', '3 in 3.2.txt: [1329, 1381, 1657]', '2 in 3.21.txt: [695, 925]', '1 in 3.22.txt: [581]', '1 in 3.23.txt: [810]', '1 in 3.7.txt: [1045]', '1 in 4.1.txt: [633]', '1 in 4.10.txt: [671]', '3 in 4.12.txt: [497, 651, 1108]', '3 in 4.13.txt: [199, 344, 654]', '2 in 4.15.txt: [164, 1035]', '1 in 4.17.txt: [539]', '1 in 4.18.txt: [214]', '2 in 4.2.txt: [146, 187]', '3 in 4.21.txt: [772, 856, 862]', '2 in 4.3.txt: [470, 477]', '1 in 4.4.txt: [145]', '2 in 4.9.txt: [110, 270]', '1 in 5.1.txt: [457]', '1 in 5.10.txt: [495]', '2 in 5.13.txt: [812, 953]', '1 in 5.14.txt: [608]', '1 in 5.15.txt: [905]', '1 in 5.16.txt: [761]', '1 in 5.17.txt: [385]', '3 in 5.19.txt: [221, 254, 345]', '2 in 5.2.txt: [149, 295]', '2 in 5.20.txt: [547, 893]', '1 in 5.21.txt: [839]', '1 in 5.22.txt: [844]', '3 in 5.3.txt: [363, 568, 1575]', '2 in 5.4.txt: [596, 604]', '2 in 5.5.txt: [174, 1338]', '2 in 5.8.txt: [141, 461]', '2 in 5.9.txt: [636, 801]', '1 in 6.1.txt: [426]', '1 in 6.10.txt: [140]', '1 in 6.11.txt: [757]', '1 in 6.13.txt: [768]', '2 in 6.15.txt: [680, 693]', '2 in 6.16.txt: [479, 939]', '4 in 6.18.txt: [226, 533, 678, 1197]', '1 in 6.19.txt: [725]', '1 in 6.21.txt: [582]', '2 in 6.22.txt: [171, 610]', '1 in 6.23.txt: [521]', '3 in 6.25.txt: [363, 568, 1575]', '2 in 6.4.txt: [156, 400]', '5 in 6.5.txt: [147, 564, 710, 917, 970]', '3 in 6.6.txt: [729, 1360, 1479]', '1 in 6.9.txt: [378]', '3 in 7.1.txt: [363, 568, 1575]', '2 in 7.10.txt: [646, 1337]', '2 in 7.11.txt: [390, 640]', '2 in 7.13.txt: [1072, 1087]', '2 in 7.14.txt: [356, 376]', '4 in 7.19.txt: [612, 687, 986, 1003]', '1 in 7.20.txt: [834]', '2 in 7.21.txt: [640, 1341]', '1 in 7.24.txt: [616]', '2 in 7.4.txt: [142, 1037]', '1 in 7.5.txt: [92]', '2 in 7.6.txt: [574, 610]', '3 in 7.7.txt: [895, 912, 990]', '1 in 7.8.txt: [386]', '1 in 7.9.txt: [846]']\n",
            "top -> top; top 100 total occurances: ['1 in 3.1.txt: [1580]', '2 in 3.10.txt: [1245, 1308]', '4 in 3.16.txt: [1008, 1030, 1073, 1081]', '5 in 3.17.txt: [1179, 1200, 1225, 1304, 1334]', '1 in 3.23.txt: [946]', '1 in 3.4.txt: [57]', '1 in 3.5.txt: [888]', '2 in 3.6.txt: [857, 879]', '2 in 3.7.txt: [1242, 1278]', '2 in 3.8.txt: [400, 1044]', '1 in 4.1.txt: [700]', '3 in 4.12.txt: [746, 754, 854]', '4 in 4.15.txt: [183, 893, 899, 913]', '1 in 4.16.txt: [619]', '3 in 4.17.txt: [833, 849, 959]', '2 in 4.2.txt: [1222, 1232]', '3 in 4.22.txt: [1062, 1183, 1203]', '1 in 4.3.txt: [817]', '1 in 4.6.txt: [377]', '1 in 4.8.txt: [517]', '1 in 4.9.txt: [855]', '2 in 5.1.txt: [1441, 1540]', '3 in 5.13.txt: [610, 1071, 1144]', '1 in 5.15.txt: [1020]', '1 in 5.18.txt: [475]', '1 in 5.22.txt: [935]', '1 in 5.3.txt: [2076]', '1 in 5.4.txt: [730]', '3 in 5.9.txt: [1171, 1187, 1353]', '1 in 6.1.txt: [36]', '1 in 6.14.txt: [621]', '1 in 6.15.txt: [54]', '1 in 6.16.txt: [819]', '4 in 6.19.txt: [675, 693, 710, 777]', '3 in 6.2.txt: [169, 585, 756]', '1 in 6.20.txt: [952]', '1 in 6.21.txt: [917]', '1 in 6.23.txt: [492]', '1 in 6.24.txt: [264]', '1 in 6.25.txt: [2076]', '3 in 6.4.txt: [581, 618, 629]', '2 in 6.6.txt: [1254, 1488]', '1 in 6.9.txt: [552]', '1 in 7.1.txt: [2076]', '3 in 7.18.txt: [267, 949, 1128]', '3 in 7.19.txt: [166, 658, 897]', '4 in 7.21.txt: [612, 1143, 1151, 1198]', '2 in 7.24.txt: [603, 636]', '3 in 7.4.txt: [177, 1211, 1259]', '1 in 7.6.txt: [1565]', '6 in 7.7.txt: [545, 555, 793, 799, 854, 1075]']\n",
            "arguably -> arguabl; arguabl 3 total occurances: ['1 in 3.16.txt: [1099]', '1 in 4.12.txt: [759]', '1 in 5.9.txt: [1365]']\n",
            "best -> best; best 307 total occurances: ['6 in 3.1.txt: [122, 441, 1410, 1538, 1610, 1673]', '9 in 3.10.txt: [230, 1024, 1075, 1187, 1195, 1314, 1343, 1354, 1376]', '2 in 3.11.txt: [990, 1008]', '1 in 3.12.txt: [718]', '6 in 3.13.txt: [844, 887, 915, 938, 962, 1022]', '1 in 3.14.txt: [1041]', '1 in 3.15.txt: [716]', '3 in 3.16.txt: [870, 1097, 1100]', '6 in 3.17.txt: [192, 564, 1258, 1283, 1292, 1312]', '4 in 3.18.txt: [84, 172, 860, 974]', '1 in 3.19.txt: [1192]', '4 in 3.2.txt: [604, 1159, 1214, 1238]', '3 in 3.20.txt: [834, 847, 1497]', '2 in 3.21.txt: [451, 703]', '4 in 3.22.txt: [194, 830, 839, 883]', '2 in 3.23.txt: [103, 913]', '3 in 3.24.txt: [955, 1043, 1121]', '2 in 3.3.txt: [647, 860]', '2 in 3.4.txt: [786, 829]', '3 in 3.5.txt: [377, 710, 903]', '4 in 3.7.txt: [238, 1260, 1266, 1298]', '5 in 3.8.txt: [354, 789, 862, 941, 979]', '2 in 3.9.txt: [453, 810]', '2 in 4.10.txt: [951, 1025]', '1 in 4.11.txt: [383]', '11 in 4.12.txt: [156, 740, 778, 787, 818, 843, 927, 964, 979, 1002, 1071]', '2 in 4.14.txt: [147, 788]', '1 in 4.15.txt: [816]', '5 in 4.17.txt: [132, 830, 915, 945, 1003]', '4 in 4.2.txt: [1181, 1191, 1256, 1575]', '2 in 4.20.txt: [647, 702]', '4 in 4.22.txt: [1101, 1129, 1327, 1392]', '3 in 4.3.txt: [187, 876, 891]', '1 in 4.4.txt: [614]', '1 in 4.5.txt: [905]', '1 in 4.6.txt: [703]', '1 in 4.7.txt: [577]', '6 in 4.9.txt: [115, 274, 901, 939, 1021, 1040]', '3 in 5.1.txt: [1002, 1424, 1552]', '1 in 5.10.txt: [883]', '3 in 5.12.txt: [769, 771, 824]', '6 in 5.13.txt: [895, 977, 996, 1010, 1022, 1058]', '4 in 5.14.txt: [685, 907, 912, 970]', '2 in 5.15.txt: [173, 1105]', '1 in 5.16.txt: [876]', '4 in 5.17.txt: [29, 811, 821, 829]', '1 in 5.18.txt: [694]', '1 in 5.2.txt: [432]', '1 in 5.21.txt: [768]', '2 in 5.22.txt: [585, 663]', '3 in 5.3.txt: [2108, 2128, 2179]', '5 in 5.4.txt: [172, 748, 757, 794, 852]', '7 in 5.5.txt: [1416, 1455, 1488, 1505, 1508, 1573, 1575]', '2 in 5.7.txt: [175, 749]', '1 in 5.8.txt: [940]', '5 in 5.9.txt: [172, 1179, 1344, 1366, 1380]', '1 in 6.11.txt: [794]', '7 in 6.12.txt: [122, 369, 412, 500, 559, 613, 626]', '2 in 6.15.txt: [119, 790]', '1 in 6.16.txt: [960]', '4 in 6.18.txt: [447, 811, 888, 919]', '6 in 6.19.txt: [646, 721, 741, 752, 767, 791]', '1 in 6.2.txt: [748]', '5 in 6.20.txt: [165, 654, 1007, 1015, 1021]', '1 in 6.21.txt: [714]', '1 in 6.22.txt: [417]', '1 in 6.23.txt: [998]', '1 in 6.24.txt: [587]', '3 in 6.25.txt: [2108, 2128, 2179]', '1 in 6.4.txt: [258]', '3 in 6.5.txt: [125, 1053, 1064]', '12 in 6.6.txt: [1220, 1290, 1301, 1311, 1327, 1351, 1369, 1386, 1396, 1425, 1452, 1470]', '3 in 6.7.txt: [167, 912, 926]', '3 in 6.8.txt: [208, 235, 632]', '1 in 6.9.txt: [566]', '3 in 7.1.txt: [2108, 2128, 2179]', '2 in 7.11.txt: [703, 729]', '4 in 7.12.txt: [622, 778, 812, 837]', '5 in 7.13.txt: [124, 703, 979, 1098, 1105]', '1 in 7.14.txt: [581]', '2 in 7.15.txt: [384, 652]', '2 in 7.16.txt: [1236, 1246]', '1 in 7.17.txt: [671]', '2 in 7.18.txt: [1172, 1199]', '5 in 7.19.txt: [919, 928, 946, 977, 1009]', '4 in 7.2.txt: [782, 795, 837, 850]', '2 in 7.20.txt: [891, 917]', '6 in 7.21.txt: [1125, 1183, 1190, 1220, 1239, 1446]', '2 in 7.23.txt: [876, 1088]', '2 in 7.24.txt: [626, 664]', '4 in 7.25.txt: [782, 795, 837, 850]', '4 in 7.3.txt: [341, 345, 568, 592]', '3 in 7.4.txt: [171, 179, 1213]', '5 in 7.5.txt: [1132, 1142, 1151, 1469, 1514]', '3 in 7.6.txt: [1507, 1533, 1548]', '11 in 7.7.txt: [147, 810, 826, 833, 841, 879, 890, 952, 1018, 1046, 1063]', '2 in 7.8.txt: [961, 973]', '2 in 7.9.txt: [833, 855]']\n",
            "number -> number; number 83 total occurances: ['2 in 3.1.txt: [849, 1857]', '1 in 3.11.txt: [1001]', '2 in 3.16.txt: [1013, 1091]', '1 in 3.17.txt: [1301]', '1 in 3.18.txt: [963]', '1 in 3.19.txt: [482]', '3 in 3.21.txt: [432, 717, 723]', '1 in 3.5.txt: [895]', '1 in 3.7.txt: [1286]', '1 in 3.9.txt: [486]', '1 in 4.1.txt: [454]', '2 in 4.11.txt: [361, 362]', '2 in 4.12.txt: [792, 851]', '1 in 4.15.txt: [910]', '1 in 4.16.txt: [616]', '1 in 4.17.txt: [832]', '3 in 4.2.txt: [718, 1229, 1519]', '3 in 4.21.txt: [441, 447, 465]', '3 in 4.22.txt: [837, 1096, 1335]', '1 in 4.7.txt: [574]', '1 in 4.9.txt: [416]', '3 in 5.1.txt: [1090, 1238, 1245]', '1 in 5.10.txt: [859]', '1 in 5.11.txt: [711]', '6 in 5.13.txt: [689, 966, 1012, 1017, 1031, 1068]', '1 in 5.14.txt: [484]', '1 in 5.2.txt: [724]', '1 in 5.21.txt: [828]', '1 in 5.22.txt: [931]', '1 in 5.3.txt: [1049]', '2 in 5.8.txt: [564, 572]', '6 in 6.12.txt: [32, 98, 301, 371, 387, 468]', '1 in 6.2.txt: [235]', '4 in 6.20.txt: [131, 592, 959, 1019]', '1 in 6.22.txt: [1120]', '1 in 6.24.txt: [424]', '1 in 6.25.txt: [1049]', '2 in 6.4.txt: [614, 626]', '2 in 6.6.txt: [673, 981]', '1 in 7.1.txt: [1049]', '3 in 7.10.txt: [390, 970, 1273]', '1 in 7.13.txt: [713]', '1 in 7.14.txt: [464]', '1 in 7.19.txt: [460]', '1 in 7.21.txt: [1195]', '1 in 7.23.txt: [540]', '2 in 7.6.txt: [1125, 1209]', '1 in 7.7.txt: [1072]', '2 in 7.8.txt: [626, 658]']\n",
            "humor -> humor; humor 43 total occurances: ['3 in 3.1.txt: [733, 1416, 1500]', '1 in 3.10.txt: [1277]', '2 in 3.13.txt: [874, 953]', '1 in 3.15.txt: [462]', '1 in 3.16.txt: [915]', '1 in 3.20.txt: [1474]', '1 in 3.24.txt: [1016]', '2 in 3.3.txt: [698, 796]', '1 in 3.5.txt: [981]', '1 in 3.7.txt: [1312]', '1 in 4.11.txt: [388]', '1 in 4.15.txt: [763]', '2 in 4.19.txt: [232, 275]', '2 in 5.1.txt: [232, 1470]', '1 in 5.10.txt: [590]', '1 in 5.11.txt: [750]', '2 in 5.12.txt: [133, 404]', '1 in 5.13.txt: [638]', '1 in 5.14.txt: [934]', '1 in 5.7.txt: [613]', '1 in 6.10.txt: [687]', '2 in 6.14.txt: [293, 372]', '1 in 6.16.txt: [440]', '1 in 6.20.txt: [40]', '1 in 6.22.txt: [1289]', '3 in 6.6.txt: [735, 754, 1269]', '1 in 7.10.txt: [452]', '1 in 7.14.txt: [369]', '1 in 7.17.txt: [492]', '1 in 7.18.txt: [617]', '1 in 7.4.txt: [281]', '2 in 7.5.txt: [1268, 1281]']\n",
            "dollarydoos -> dollarydoo; dollarydoo 2 total occurances: ['2 in 6.16.txt: [1051, 1059]']\n",
            "Bart Simpson -> bart simpson; bart simpson 31 total occurances: ['1 in 3.13.txt: [288]', '2 in 3.4.txt: [42, 593]', '1 in 4.1.txt: [622]', '1 in 4.2.txt: [1586]', '1 in 4.7.txt: [686]', '1 in 5.1.txt: [147]', '1 in 5.15.txt: [665]', '1 in 5.3.txt: [911]', '11 in 5.5.txt: [44, 134, 215, 571, 1063, 1108, 1162, 1176, 1434, 1465, 1569]', '1 in 6.14.txt: [69]', '1 in 6.18.txt: [638]', '1 in 6.21.txt: [83]', '1 in 6.23.txt: [703]', '1 in 6.25.txt: [911]', '1 in 6.5.txt: [211]', '1 in 6.7.txt: [508]', '1 in 7.1.txt: [911]', '3 in 7.4.txt: [258, 344, 983]']\n",
            "Gordie Howe -> gordi howe; No viable spelling fix was found\n",
            "recalled -> recal; recal 24 total occurances: ['1 in 3.1.txt: [693]', '1 in 3.11.txt: [813]', '1 in 3.14.txt: [527]', '1 in 3.16.txt: [549]', '1 in 3.17.txt: [1395]', '1 in 3.19.txt: [356]', '1 in 3.7.txt: [939]', '1 in 5.1.txt: [832]', '1 in 5.16.txt: [814]', '1 in 5.19.txt: [911]', '2 in 5.8.txt: [523, 610]', '1 in 6.11.txt: [753]', '1 in 6.2.txt: [559]', '3 in 6.3.txt: [110, 543, 555]', '1 in 6.4.txt: [558]', '1 in 7.18.txt: [767]', '1 in 7.2.txt: [614]', '1 in 7.21.txt: [1323]', '1 in 7.22.txt: [684]', '1 in 7.25.txt: [614]', '1 in 7.4.txt: [556]']\n",
            "Bart the Lover -> bart lover; bart lover 7 total occurances: ['7 in 3.16.txt: [0, 2, 45, 464, 880, 953, 1010]']\n",
            "cents -> cent; cent 6 total occurances: ['1 in 3.11.txt: [269]', '1 in 3.16.txt: [440]', '1 in 4.15.txt: [664]', '1 in 5.1.txt: [1212]', '1 in 5.6.txt: [413]', '1 in 7.4.txt: [468]']\n",
            "won -> won; won 35 total occurances: ['1 in 3.14.txt: [574]', '1 in 3.16.txt: [821]', '1 in 3.17.txt: [1033]', '2 in 3.18.txt: [799, 831]', '1 in 3.24.txt: [288]', '5 in 3.6.txt: [202, 783, 811, 840, 847]', '1 in 3.8.txt: [749]', '1 in 4.10.txt: [818]', '1 in 4.17.txt: [226]', '1 in 4.2.txt: [1355]', '1 in 4.20.txt: [144]', '1 in 4.22.txt: [1135]', '2 in 4.6.txt: [277, 280]', '4 in 4.9.txt: [120, 1049, 1061, 1119]', '1 in 5.15.txt: [219]', '2 in 5.17.txt: [599, 807]', '1 in 5.8.txt: [938]', '2 in 6.19.txt: [105, 654]', '2 in 7.12.txt: [616, 619]', '2 in 7.5.txt: [174, 1128]', '1 in 7.6.txt: [1629]', '1 in 7.8.txt: [923]']\n",
            "voice-overs -> voiceov; voiceov 14 total occurances: ['1 in 3.1.txt: [1449]', '1 in 3.12.txt: [858]', '1 in 3.14.txt: [862]', '2 in 3.16.txt: [824, 939]', '1 in 3.18.txt: [567]', '2 in 3.6.txt: [208, 817]', '1 in 3.8.txt: [802]', '1 in 4.3.txt: [600]', '2 in 4.9.txt: [126, 1053]', '1 in 5.13.txt: [624]', '1 in 6.6.txt: [1049]']\n",
            "Simpsonovi -> simpsonovi; simpsoni 1 total occurances: ['1 in 6.18.txt: [865]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing spell-correct"
      ],
      "metadata": {
        "id": "oDqxbcp5ldUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.dump(\"/content/drive/MyDrive/Colab Notebooks/typos.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr-co1cqcvq3",
        "outputId": "443cbf80-1130-467a-e6e1-e94de2dce74d"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "passed_in_query -> query_after_processing: [list_of_occurances]\n",
            "brat -> brat; rat 2 total occurances: ['1 in 3.4.txt: [245]', '1 in 5.20.txt: [462]']\n",
            "sipmsons -> sipmson; simpson 1374 total occurances: ['29 in 3.1.txt: [58, 90, 232, 363, 470, 750, 903, 990, 1005, 1038, 1045, 1062, 1082, 1085, 1183, 1188, 1263, 1388, 1404, 1444, 1473, 1492, 1574, 1582, 1604, 1620, 1653, 1746, 1774]', '16 in 3.10.txt: [5, 73, 231, 698, 1016, 1025, 1113, 1161, 1173, 1188, 1275, 1310, 1329, 1335, 1345, 1355]', '14 in 3.11.txt: [98, 213, 309, 570, 655, 680, 693, 878, 879, 885, 919, 943, 985, 1026]', '7 in 3.12.txt: [91, 135, 180, 530, 891, 913, 1001]', '12 in 3.13.txt: [57, 289, 473, 811, 817, 837, 888, 916, 924, 930, 940, 974]', '4 in 3.14.txt: [71, 109, 869, 905]', '5 in 3.15.txt: [64, 496, 618, 663, 683]', '9 in 3.16.txt: [54, 852, 871, 883, 912, 982, 1034, 1083, 1101]', '14 in 3.17.txt: [88, 1026, 1054, 1106, 1121, 1185, 1202, 1227, 1244, 1271, 1293, 1295, 1306, 1403]', '11 in 3.18.txt: [64, 311, 550, 695, 719, 751, 765, 851, 859, 885, 910]', '13 in 3.19.txt: [69, 200, 214, 246, 289, 377, 416, 420, 459, 730, 799, 987, 1140]', '28 in 3.2.txt: [66, 268, 385, 414, 475, 490, 506, 607, 680, 819, 857, 891, 910, 1138, 1160, 1163, 1206, 1259, 1269, 1346, 1442, 1476, 1524, 1527, 1599, 1605, 1656, 1697]', '22 in 3.20.txt: [90, 139, 241, 282, 811, 837, 860, 868, 918, 923, 991, 1085, 1438, 1447, 1473, 1499, 1557, 1685, 1731, 1735, 1795, 1809]', '12 in 3.21.txt: [88, 181, 286, 313, 331, 529, 643, 658, 779, 846, 862, 933]', '8 in 3.22.txt: [76, 124, 167, 476, 695, 725, 855, 898]', '4 in 3.23.txt: [54, 91, 752, 763]', '7 in 3.24.txt: [68, 343, 368, 727, 852, 918, 1046]', '9 in 3.3.txt: [31, 63, 185, 508, 512, 555, 648, 680, 717]', '7 in 3.4.txt: [43, 79, 545, 594, 605, 787, 810]', '6 in 3.5.txt: [72, 514, 781, 890, 907, 984]', '9 in 3.6.txt: [81, 94, 231, 746, 826, 833, 859, 867, 904]', '5 in 3.7.txt: [58, 318, 683, 973, 1174]', '13 in 3.8.txt: [78, 148, 360, 380, 446, 517, 573, 706, 790, 838, 924, 1050, 1069]', '5 in 3.9.txt: [64, 388, 426, 829, 998]', '4 in 4.1.txt: [58, 623, 672, 688]', '21 in 4.10.txt: [38, 46, 72, 82, 123, 206, 260, 400, 595, 598, 871, 893, 924, 935, 980, 1004, 1100, 1227, 1233, 1249, 1258]', '7 in 4.11.txt: [40, 67, 92, 197, 323, 431, 604]', '21 in 4.12.txt: [56, 91, 157, 748, 763, 768, 827, 836, 844, 846, 856, 864, 899, 932, 1020, 1054, 1057, 1063, 1073, 1156, 1173]', '5 in 4.13.txt: [45, 72, 151, 642, 664]', '9 in 4.14.txt: [69, 376, 455, 716, 752, 789, 815, 820, 848]', '7 in 4.15.txt: [71, 430, 434, 545, 821, 848, 915]', '2 in 4.16.txt: [68, 586]', '18 in 4.17.txt: [46, 69, 83, 210, 329, 452, 460, 535, 546, 551, 875, 877, 911, 919, 963, 987, 1008, 1048]', '12 in 4.18.txt: [1, 5, 51, 61, 99, 114, 375, 378, 593, 623, 636, 844]', '18 in 4.19.txt: [1, 34, 60, 83, 105, 419, 425, 657, 665, 681, 694, 700, 718, 737, 760, 787, 851, 897]', '20 in 4.2.txt: [74, 121, 140, 622, 646, 751, 782, 802, 817, 1099, 1106, 1129, 1234, 1249, 1338, 1341, 1507, 1538, 1544, 1587]', '3 in 4.20.txt: [34, 62, 731]', '14 in 4.21.txt: [70, 154, 162, 186, 242, 489, 508, 530, 535, 651, 691, 820, 877, 905]', '16 in 4.22.txt: [90, 700, 1014, 1053, 1065, 1102, 1112, 1123, 1170, 1174, 1205, 1254, 1308, 1382, 1386, 1416]', '16 in 4.3.txt: [74, 311, 488, 515, 606, 617, 622, 723, 730, 786, 819, 857, 862, 868, 878, 892]', '3 in 4.4.txt: [78, 409, 602]', '8 in 4.5.txt: [70, 174, 492, 526, 592, 811, 877, 926]', '6 in 4.6.txt: [55, 513, 564, 633, 662, 707]', '4 in 4.7.txt: [81, 101, 541, 687]', '9 in 4.8.txt: [62, 88, 153, 274, 289, 298, 502, 519, 531]', '13 in 4.9.txt: [10, 74, 585, 618, 714, 915, 972, 1026, 1032, 1042, 1078, 1102, 1105]', '14 in 5.1.txt: [100, 116, 142, 148, 337, 445, 574, 774, 949, 954, 1528, 1542, 1554, 1564]', '7 in 5.10.txt: [92, 523, 542, 557, 602, 628, 897]', '9 in 5.11.txt: [36, 63, 138, 198, 428, 488, 501, 506, 700]', '9 in 5.12.txt: [82, 150, 370, 407, 458, 496, 564, 650, 756]', '11 in 5.13.txt: [69, 287, 314, 424, 656, 662, 887, 936, 999, 1060, 1169]', '8 in 5.14.txt: [68, 455, 688, 898, 936, 962, 972, 1004]', '18 in 5.15.txt: [94, 106, 148, 165, 203, 501, 666, 696, 750, 933, 947, 955, 1012, 1022, 1026, 1073, 1106, 1108]', '12 in 5.16.txt: [64, 110, 229, 237, 314, 351, 403, 526, 781, 799, 836, 840]', '9 in 5.17.txt: [64, 86, 283, 351, 472, 559, 579, 708, 867]', '9 in 5.18.txt: [38, 71, 341, 352, 371, 489, 578, 608, 621]', '9 in 5.19.txt: [46, 90, 138, 203, 627, 632, 665, 873, 979]', '5 in 5.2.txt: [62, 104, 361, 691, 765]', '6 in 5.20.txt: [3, 48, 74, 552, 842, 1008]', '7 in 5.21.txt: [84, 95, 193, 386, 441, 808, 860]', '5 in 5.22.txt: [71, 640, 711, 802, 904]', '25 in 5.3.txt: [76, 139, 394, 443, 617, 625, 635, 669, 767, 908, 912, 1032, 1090, 1099, 1158, 1356, 1964, 2039, 2098, 2109, 2116, 2118, 2130, 2140, 2212]', '14 in 5.4.txt: [1, 56, 85, 173, 578, 689, 736, 795, 797, 801, 810, 838, 844, 854]', '29 in 5.5.txt: [32, 45, 107, 130, 135, 209, 216, 254, 351, 354, 392, 572, 760, 802, 906, 974, 1028, 1042, 1064, 1109, 1142, 1163, 1177, 1372, 1404, 1435, 1461, 1466, 1570]', '5 in 5.6.txt: [64, 396, 521, 615, 646]', '15 in 5.7.txt: [41, 74, 159, 176, 255, 354, 464, 486, 520, 534, 657, 750, 760, 787, 832]', '6 in 5.8.txt: [76, 472, 696, 786, 858, 866]', '10 in 5.9.txt: [49, 75, 175, 501, 523, 1180, 1202, 1211, 1249, 1347]', '8 in 6.1.txt: [31, 63, 179, 344, 527, 576, 855, 898]', '11 in 6.10.txt: [75, 124, 217, 248, 302, 593, 613, 634, 730, 745, 754]', '11 in 6.11.txt: [2, 59, 83, 147, 237, 511, 580, 698, 840, 862, 871]', '5 in 6.12.txt: [71, 134, 288, 393, 509]', '10 in 6.13.txt: [63, 96, 370, 380, 490, 524, 626, 681, 736, 765]', '7 in 6.14.txt: [33, 59, 70, 366, 497, 573, 625]', '12 in 6.15.txt: [3, 49, 73, 125, 130, 366, 379, 385, 710, 776, 782, 792]', '19 in 6.16.txt: [45, 68, 297, 387, 393, 431, 519, 522, 524, 676, 713, 754, 837, 869, 889, 900, 957, 978, 989]', '14 in 6.17.txt: [70, 115, 158, 180, 206, 217, 423, 550, 559, 615, 691, 714, 723, 739]', '20 in 6.18.txt: [80, 120, 131, 149, 166, 420, 475, 498, 513, 520, 639, 826, 910, 965, 988, 1063, 1091, 1156, 1211, 1283]', '13 in 6.19.txt: [67, 114, 141, 369, 663, 701, 742, 749, 753, 768, 783, 792, 803]', '9 in 6.2.txt: [38, 43, 69, 91, 508, 749, 758, 787, 811]', '15 in 6.20.txt: [74, 204, 232, 365, 410, 468, 480, 481, 529, 546, 656, 663, 867, 1030, 1062]', '11 in 6.21.txt: [73, 84, 118, 645, 704, 719, 770, 850, 921, 952, 989]', '11 in 6.22.txt: [84, 185, 598, 626, 634, 951, 975, 991, 996, 1051, 1116]', '11 in 6.23.txt: [68, 145, 157, 291, 372, 704, 712, 845, 935, 954, 967]', '6 in 6.24.txt: [31, 60, 335, 540, 558, 607]', '25 in 6.25.txt: [76, 139, 394, 443, 617, 625, 635, 669, 767, 908, 912, 1032, 1090, 1099, 1158, 1356, 1964, 2039, 2098, 2109, 2116, 2118, 2130, 2140, 2212]', '12 in 6.3.txt: [1, 5, 59, 80, 90, 108, 260, 262, 392, 559, 767, 790]', '11 in 6.4.txt: [64, 78, 193, 207, 226, 239, 252, 410, 631, 633, 679]', '10 in 6.5.txt: [53, 76, 115, 212, 271, 381, 851, 886, 1027, 1103]', '20 in 6.6.txt: [78, 117, 263, 429, 484, 658, 828, 885, 924, 955, 1241, 1256, 1279, 1322, 1332, 1352, 1354, 1437, 1490, 1502]', '12 in 6.7.txt: [50, 75, 170, 431, 446, 509, 575, 631, 648, 657, 787, 915]', '5 in 6.8.txt: [31, 58, 286, 495, 582]', '8 in 6.9.txt: [67, 209, 243, 293, 485, 547, 567, 583]', '25 in 7.1.txt: [76, 139, 394, 443, 617, 625, 635, 669, 767, 908, 912, 1032, 1090, 1099, 1158, 1356, 1964, 2039, 2098, 2109, 2116, 2118, 2130, 2140, 2212]', '28 in 7.10.txt: [0, 3, 43, 47, 81, 91, 107, 109, 113, 130, 213, 257, 265, 292, 296, 303, 307, 311, 348, 406, 417, 468, 481, 913, 945, 1250, 1262, 1286]', '8 in 7.11.txt: [74, 418, 438, 537, 546, 609, 731, 751]', '8 in 7.12.txt: [30, 42, 64, 398, 467, 527, 543, 876]', '23 in 7.13.txt: [66, 94, 184, 283, 363, 380, 392, 412, 447, 450, 467, 517, 533, 542, 623, 643, 780, 792, 982, 1008, 1013, 1056, 1069]', '7 in 7.14.txt: [65, 160, 348, 404, 518, 599, 619]', '6 in 7.15.txt: [45, 72, 163, 365, 670, 720]', '9 in 7.16.txt: [63, 677, 694, 793, 1199, 1256, 1300, 1316, 1334]', '5 in 7.17.txt: [26, 49, 332, 401, 688]', '13 in 7.18.txt: [75, 98, 144, 340, 518, 529, 602, 619, 639, 1175, 1269, 1301, 1309]', '9 in 7.19.txt: [39, 66, 463, 544, 949, 1022, 1034, 1037, 1058]', '15 in 7.2.txt: [40, 67, 77, 116, 204, 339, 386, 422, 468, 694, 821, 823, 829, 839, 851]', '6 in 7.20.txt: [43, 70, 506, 591, 619, 766]', '20 in 7.21.txt: [77, 119, 203, 702, 1086, 1117, 1127, 1145, 1173, 1200, 1206, 1213, 1254, 1287, 1303, 1318, 1342, 1421, 1510, 1607]', '11 in 7.22.txt: [2, 11, 64, 78, 90, 142, 280, 588, 757, 863, 872]', '6 in 7.23.txt: [101, 506, 658, 728, 905, 931]', '10 in 7.24.txt: [65, 100, 377, 499, 567, 605, 638, 674, 699, 730]', '15 in 7.25.txt: [40, 67, 77, 116, 204, 339, 386, 422, 468, 694, 821, 823, 829, 839, 851]', '11 in 7.3.txt: [79, 89, 215, 254, 288, 306, 311, 378, 621, 668, 673]', '20 in 7.4.txt: [38, 67, 161, 174, 259, 345, 435, 448, 674, 728, 787, 839, 976, 984, 1132, 1146, 1164, 1172, 1207, 1229]', '24 in 7.5.txt: [45, 66, 109, 217, 473, 641, 723, 747, 762, 776, 816, 822, 856, 1084, 1105, 1191, 1204, 1262, 1327, 1350, 1431, 1472, 1485, 1504]', '11 in 7.6.txt: [62, 89, 225, 332, 595, 631, 908, 1020, 1454, 1569, 1623]', '13 in 7.7.txt: [46, 76, 118, 240, 407, 798, 842, 856, 1010, 1049, 1055, 1065, 1077]', '21 in 7.8.txt: [1, 6, 7, 9, 52, 60, 79, 87, 338, 398, 476, 514, 541, 623, 648, 743, 759, 839, 870, 948, 974]', '7 in 7.9.txt: [50, 81, 137, 261, 428, 509, 802]']\n",
            "mrage -> mrage; rage 11 total occurances: ['1 in 4.3.txt: [415]', '2 in 5.3.txt: [451, 531]', '2 in 6.25.txt: [451, 531]', '2 in 7.1.txt: [451, 531]', '4 in 7.22.txt: [0, 9, 62, 859]']\n",
            "margee -> marg; marg 660 total occurances: ['3 in 3.1.txt: [348, 1004, 1244]', '1 in 3.10.txt: [1081]', '40 in 3.12.txt: [1, 3, 8, 11, 83, 101, 119, 132, 161, 210, 247, 280, 281, 299, 320, 334, 351, 382, 388, 403, 421, 427, 455, 459, 478, 494, 509, 521, 538, 553, 609, 622, 642, 651, 693, 726, 826, 847, 940, 964]', '1 in 3.13.txt: [325]', '8 in 3.14.txt: [171, 175, 361, 398, 467, 483, 489, 768]', '22 in 3.15.txt: [83, 127, 132, 217, 258, 269, 286, 332, 351, 354, 369, 401, 414, 424, 486, 585, 612, 694, 712, 741, 769, 791]', '4 in 3.16.txt: [285, 352, 390, 436]', '1 in 3.19.txt: [260]', '1 in 3.2.txt: [516]', '16 in 3.20.txt: [101, 124, 293, 308, 314, 322, 372, 403, 417, 473, 499, 514, 515, 672, 1355, 1603]', '3 in 3.21.txt: [310, 387, 633]', '5 in 3.22.txt: [96, 239, 310, 323, 337]', '3 in 3.23.txt: [370, 386, 564]', '3 in 3.24.txt: [348, 737, 765]', '3 in 3.5.txt: [384, 408, 794]', '4 in 3.7.txt: [175, 301, 557, 934]', '2 in 3.8.txt: [299, 313]', '7 in 3.9.txt: [181, 275, 359, 361, 513, 537, 544]', '4 in 4.1.txt: [206, 382, 480, 525]', '8 in 4.10.txt: [92, 214, 227, 237, 350, 428, 527, 739]', '3 in 4.11.txt: [133, 179, 421]', '19 in 4.12.txt: [0, 3, 6, 81, 113, 146, 275, 288, 317, 358, 388, 435, 487, 697, 733, 884, 955, 1080, 1182]', '7 in 4.13.txt: [141, 153, 248, 304, 473, 484, 652]', '1 in 4.14.txt: [286]', '1 in 4.15.txt: [257]', '6 in 4.16.txt: [86, 161, 268, 278, 324, 492]', '1 in 4.17.txt: [219]', '5 in 4.18.txt: [272, 295, 512, 577, 789]', '3 in 4.19.txt: [139, 263, 602]', '31 in 4.2.txt: [2, 5, 66, 84, 106, 235, 272, 279, 290, 307, 312, 345, 364, 374, 382, 391, 440, 452, 475, 491, 510, 516, 536, 546, 652, 1086, 1140, 1296, 1439, 1446, 1555]', '3 in 4.20.txt: [97, 226, 264]', '23 in 4.21.txt: [0, 2, 60, 80, 106, 114, 128, 173, 246, 265, 282, 296, 319, 330, 351, 490, 526, 568, 577, 592, 786, 826, 917]', '6 in 4.22.txt: [765, 1287, 1298, 1301, 1398, 1403]', '8 in 4.3.txt: [106, 142, 191, 211, 219, 226, 264, 734]', '3 in 4.4.txt: [44, 231, 556]', '10 in 4.5.txt: [164, 277, 325, 348, 355, 369, 377, 414, 431, 741]', '7 in 4.6.txt: [76, 118, 129, 136, 257, 264, 615]', '17 in 4.7.txt: [0, 3, 71, 91, 107, 155, 173, 181, 193, 199, 223, 236, 379, 389, 400, 408, 599]', '2 in 4.8.txt: [186, 206]', '3 in 4.9.txt: [171, 384, 1070]', '4 in 5.1.txt: [354, 371, 432, 465]', '9 in 5.10.txt: [117, 228, 259, 313, 360, 381, 754, 870, 907]', '2 in 5.11.txt: [206, 494]', '4 in 5.12.txt: [334, 353, 419, 653]', '1 in 5.13.txt: [910]', '1 in 5.15.txt: [335]', '4 in 5.16.txt: [439, 463, 471, 515]', '6 in 5.17.txt: [342, 443, 546, 721, 751, 938]', '3 in 5.18.txt: [98, 272, 281]', '1 in 5.19.txt: [702]', '2 in 5.2.txt: [368, 447]', '1 in 5.20.txt: [499]', '8 in 5.21.txt: [98, 204, 245, 553, 554, 558, 772, 824]', '17 in 5.22.txt: [109, 191, 231, 239, 270, 287, 310, 316, 472, 494, 542, 559, 591, 860, 891, 920, 956]', '6 in 5.3.txt: [311, 339, 499, 817, 1287, 1424]', '5 in 5.5.txt: [317, 361, 376, 717, 763]', '22 in 5.6.txt: [0, 2, 55, 74, 143, 148, 181, 201, 215, 233, 249, 291, 313, 329, 336, 398, 448, 541, 574, 588, 622, 682]', '6 in 5.7.txt: [84, 261, 277, 302, 323, 339]', '10 in 5.9.txt: [111, 273, 432, 440, 512, 663, 872, 999, 1139, 1269]', '1 in 6.1.txt: [304]', '7 in 6.10.txt: [86, 183, 198, 221, 402, 439, 672]', '14 in 6.11.txt: [99, 248, 263, 284, 314, 318, 339, 370, 401, 587, 605, 649, 713, 781]', '1 in 6.12.txt: [282]', '7 in 6.13.txt: [205, 212, 229, 239, 254, 263, 534]', '2 in 6.16.txt: [279, 365]', '8 in 6.17.txt: [188, 285, 306, 331, 581, 648, 659, 748]', '7 in 6.18.txt: [267, 277, 313, 342, 392, 426, 803]', '3 in 6.19.txt: [189, 262, 434]', '3 in 6.2.txt: [380, 397, 601]', '2 in 6.20.txt: [238, 1058]', '3 in 6.21.txt: [252, 265, 321]', '2 in 6.22.txt: [283, 728]', '35 in 6.23.txt: [78, 148, 163, 208, 222, 227, 246, 269, 293, 300, 323, 348, 357, 391, 411, 456, 482, 486, 515, 569, 584, 597, 626, 647, 730, 783, 802, 819, 825, 869, 876, 901, 907, 957, 990]', '1 in 6.24.txt: [146]', '6 in 6.25.txt: [311, 339, 499, 817, 1287, 1424]', '16 in 6.3.txt: [100, 192, 213, 231, 243, 413, 454, 494, 511, 542, 554, 573, 579, 589, 649, 776]', '6 in 6.4.txt: [120, 143, 183, 261, 475, 554]', '7 in 6.6.txt: [232, 253, 317, 329, 355, 646, 712]', '4 in 6.7.txt: [297, 445, 642, 865]', '3 in 6.8.txt: [264, 504, 693]', '5 in 6.9.txt: [116, 132, 161, 170, 261]', '6 in 7.1.txt: [311, 339, 499, 817, 1287, 1424]', '7 in 7.10.txt: [555, 569, 679, 790, 809, 822, 832]', '19 in 7.11.txt: [0, 2, 65, 84, 161, 197, 242, 257, 266, 275, 295, 319, 332, 359, 507, 568, 622, 651, 757]', '3 in 7.12.txt: [486, 516, 575]', '2 in 7.13.txt: [27, 391]', '20 in 7.14.txt: [75, 84, 171, 176, 185, 193, 209, 249, 252, 271, 284, 298, 377, 418, 425, 522, 536, 544, 559, 618]', '1 in 7.15.txt: [171]', '1 in 7.16.txt: [693]', '2 in 7.17.txt: [212, 507]', '2 in 7.18.txt: [343, 870]', '3 in 7.19.txt: [271, 277, 719]', '4 in 7.2.txt: [209, 239, 322, 780]', '5 in 7.20.txt: [215, 398, 403, 427, 782]', '3 in 7.21.txt: [305, 432, 666]', '1 in 7.22.txt: [768]', '1 in 7.23.txt: [61]', '1 in 7.24.txt: [423]', '4 in 7.25.txt: [209, 239, 322, 780]', '9 in 7.3.txt: [40, 99, 195, 243, 263, 487, 576, 594, 604]', '1 in 7.5.txt: [227]', '6 in 7.6.txt: [391, 503, 667, 712, 795, 856]', '4 in 7.7.txt: [214, 242, 522, 1026]', '2 in 7.8.txt: [169, 249]']\n",
            "homerr -> homerr; homer 1978 total occurances: ['17 in 3.1.txt: [9, 100, 279, 305, 316, 327, 344, 350, 360, 385, 542, 550, 560, 688, 1202, 1311, 1703]', '22 in 3.10.txt: [83, 88, 97, 112, 272, 289, 292, 303, 324, 340, 385, 394, 432, 436, 444, 481, 489, 893, 904, 1033, 1072, 1234]', '28 in 3.11.txt: [10, 122, 200, 242, 271, 324, 364, 376, 387, 404, 406, 479, 494, 591, 660, 674, 690, 702, 704, 756, 767, 778, 807, 822, 951, 975, 988, 1060]', '36 in 3.12.txt: [6, 113, 264, 275, 290, 300, 308, 324, 327, 356, 381, 393, 411, 430, 433, 449, 451, 466, 488, 491, 500, 515, 537, 552, 558, 643, 670, 680, 704, 717, 749, 764, 795, 946, 956, 991]', '8 in 3.13.txt: [172, 225, 324, 329, 340, 506, 591, 626]', '25 in 3.14.txt: [36, 81, 172, 191, 199, 207, 218, 238, 248, 262, 273, 292, 302, 317, 335, 350, 486, 515, 532, 695, 766, 914, 933, 954, 985]', '23 in 3.15.txt: [0, 5, 55, 98, 104, 120, 161, 249, 285, 297, 333, 337, 350, 364, 383, 394, 528, 545, 561, 596, 615, 707, 775]', '16 in 3.16.txt: [89, 92, 118, 280, 347, 400, 424, 427, 433, 444, 498, 514, 527, 940, 967, 990]', '23 in 3.17.txt: [0, 2, 79, 106, 169, 247, 371, 478, 495, 509, 521, 527, 776, 877, 896, 1001, 1037, 1155, 1218, 1342, 1361, 1402, 1416]', '10 in 3.19.txt: [41, 50, 228, 250, 563, 656, 775, 924, 1150, 1206]', '5 in 3.2.txt: [36, 241, 282, 890, 1382]', '65 in 3.20.txt: [1, 3, 8, 82, 100, 107, 118, 128, 198, 222, 232, 292, 298, 319, 327, 344, 359, 374, 383, 395, 415, 418, 430, 441, 451, 461, 477, 503, 510, 517, 524, 556, 577, 598, 609, 641, 646, 671, 705, 793, 798, 1065, 1096, 1109, 1158, 1215, 1252, 1261, 1274, 1313, 1354, 1367, 1405, 1418, 1538, 1580, 1588, 1656, 1698, 1715, 1729, 1763, 1770, 1786, 1807]', '3 in 3.21.txt: [261, 308, 824]', '12 in 3.22.txt: [95, 238, 322, 334, 354, 372, 567, 584, 609, 618, 630, 742]', '13 in 3.23.txt: [143, 361, 376, 388, 409, 501, 505, 534, 804, 856, 873, 923, 960]', '24 in 3.24.txt: [93, 106, 116, 168, 221, 230, 249, 261, 274, 287, 295, 300, 337, 359, 440, 473, 692, 714, 760, 813, 830, 925, 993, 1112]', '13 in 3.3.txt: [73, 97, 216, 222, 247, 254, 268, 548, 743, 817, 820, 866, 874]', '3 in 3.4.txt: [320, 411, 836]', '30 in 3.5.txt: [0, 2, 63, 82, 97, 155, 181, 217, 237, 248, 254, 266, 288, 299, 305, 318, 321, 333, 341, 353, 536, 543, 646, 718, 767, 814, 848, 992, 995, 1018]', '2 in 3.6.txt: [54, 722]', '29 in 3.7.txt: [80, 106, 127, 140, 281, 288, 345, 383, 402, 420, 427, 438, 463, 478, 485, 493, 501, 682, 849, 874, 901, 977, 1036, 1061, 1076, 1090, 1111, 1124, 1308]', '28 in 3.8.txt: [40, 49, 88, 112, 120, 209, 226, 237, 257, 263, 295, 308, 331, 339, 347, 501, 559, 581, 592, 601, 646, 672, 740, 791, 888, 895, 999, 1011]', '27 in 3.9.txt: [74, 88, 101, 104, 183, 197, 221, 253, 267, 277, 294, 301, 400, 413, 509, 542, 551, 584, 617, 628, 634, 691, 891, 905, 915, 934, 964]', '6 in 4.1.txt: [123, 142, 205, 210, 294, 381]', '12 in 4.10.txt: [226, 240, 323, 361, 366, 464, 489, 519, 529, 1097, 1127, 1137]', '27 in 4.11.txt: [0, 4, 56, 77, 88, 128, 164, 173, 188, 199, 266, 276, 320, 325, 336, 385, 400, 414, 433, 450, 472, 490, 502, 512, 520, 537, 566]', '9 in 4.12.txt: [269, 371, 391, 402, 602, 673, 694, 708, 1023]', '9 in 4.13.txt: [134, 222, 257, 299, 320, 411, 483, 515, 653]', '21 in 4.14.txt: [79, 93, 172, 211, 213, 230, 243, 249, 497, 519, 562, 572, 588, 607, 627, 632, 724, 761, 791, 810, 845]', '3 in 4.15.txt: [364, 368, 603]', '13 in 4.16.txt: [82, 218, 231, 255, 270, 275, 312, 411, 421, 491, 506, 519, 596]', '24 in 4.17.txt: [82, 221, 245, 265, 276, 282, 286, 294, 304, 333, 341, 357, 365, 432, 437, 441, 448, 618, 697, 782, 874, 876, 1010, 1035]', '44 in 4.18.txt: [72, 82, 87, 96, 105, 182, 199, 212, 225, 243, 252, 267, 276, 280, 297, 302, 314, 448, 510, 514, 521, 524, 533, 548, 551, 581, 605, 614, 617, 625, 643, 655, 660, 672, 691, 701, 719, 726, 739, 769, 787, 801, 826, 917]', '9 in 4.19.txt: [90, 136, 262, 272, 283, 295, 302, 603, 614]', '21 in 4.2.txt: [98, 228, 261, 294, 366, 370, 379, 384, 390, 417, 435, 443, 458, 465, 493, 527, 549, 789, 1034, 1075, 1549]', '2 in 4.20.txt: [710, 713]', '3 in 4.21.txt: [100, 513, 638]', '4 in 4.22.txt: [139, 226, 557, 1245]', '36 in 4.3.txt: [0, 2, 4, 65, 84, 134, 147, 180, 222, 230, 244, 249, 252, 272, 281, 295, 326, 332, 342, 348, 362, 383, 434, 447, 456, 474, 484, 640, 654, 685, 731, 738, 778, 811, 852, 887]', '11 in 4.4.txt: [43, 88, 186, 225, 233, 370, 382, 389, 396, 427, 475]', '33 in 4.5.txt: [84, 92, 128, 146, 166, 201, 220, 237, 250, 262, 296, 301, 315, 342, 365, 375, 389, 392, 402, 409, 430, 500, 506, 599, 643, 652, 664, 708, 717, 732, 756, 764, 935]', '20 in 4.6.txt: [71, 78, 93, 119, 135, 168, 181, 187, 212, 223, 241, 251, 261, 276, 278, 297, 309, 320, 524, 667]', '7 in 4.7.txt: [55, 154, 160, 171, 218, 222, 427]', '11 in 4.8.txt: [115, 159, 184, 193, 209, 235, 238, 354, 428, 437, 493]', '31 in 4.9.txt: [9, 84, 102, 131, 173, 182, 195, 213, 216, 225, 254, 271, 298, 299, 309, 324, 338, 349, 377, 396, 468, 550, 566, 592, 602, 656, 731, 934, 997, 1056, 1168]', '42 in 5.1.txt: [0, 4, 10, 89, 115, 154, 159, 211, 267, 271, 287, 310, 342, 364, 367, 378, 417, 427, 448, 472, 519, 536, 541, 578, 611, 884, 910, 924, 1045, 1057, 1150, 1168, 1206, 1248, 1269, 1291, 1312, 1476, 1487, 1510, 1534, 1571]', '15 in 5.10.txt: [113, 239, 255, 348, 356, 379, 388, 405, 511, 647, 728, 756, 805, 862, 922]', '25 in 5.11.txt: [0, 2, 54, 85, 91, 105, 129, 229, 245, 267, 279, 296, 314, 334, 470, 573, 581, 599, 622, 752, 761, 787, 791, 797, 820]', '4 in 5.12.txt: [410, 481, 706, 815]', '31 in 5.13.txt: [0, 2, 60, 79, 104, 193, 201, 216, 236, 248, 289, 309, 316, 332, 344, 357, 490, 498, 652, 733, 739, 752, 843, 905, 927, 1037, 1066, 1116, 1214, 1222, 1226]', '3 in 5.14.txt: [744, 908, 1007]', '47 in 5.15.txt: [2, 5, 86, 105, 202, 215, 223, 231, 248, 270, 273, 287, 295, 324, 346, 365, 396, 415, 433, 446, 456, 467, 470, 497, 519, 523, 606, 615, 643, 718, 728, 754, 764, 774, 792, 801, 806, 845, 848, 871, 903, 923, 1006, 1035, 1071, 1075, 1118]', '34 in 5.16.txt: [0, 3, 54, 77, 89, 171, 184, 189, 204, 209, 214, 246, 250, 285, 298, 310, 317, 334, 343, 382, 395, 502, 551, 566, 584, 657, 679, 717, 810, 835, 839, 881, 897, 924]', '21 in 5.17.txt: [90, 107, 111, 300, 316, 324, 341, 361, 374, 391, 413, 424, 451, 637, 671, 731, 745, 754, 881, 921, 935]', '9 in 5.18.txt: [47, 225, 231, 245, 247, 271, 400, 532, 689]', '2 in 5.19.txt: [59, 385]', '40 in 5.2.txt: [0, 3, 52, 72, 83, 91, 101, 214, 243, 251, 262, 283, 301, 314, 326, 350, 358, 370, 389, 399, 408, 424, 434, 450, 460, 472, 478, 489, 535, 570, 579, 588, 625, 644, 663, 731, 741, 789, 802, 842]', '17 in 5.20.txt: [365, 374, 391, 406, 410, 490, 533, 536, 724, 741, 777, 793, 802, 931, 969, 977, 984]', '5 in 5.21.txt: [214, 257, 284, 533, 867]', '35 in 5.22.txt: [81, 112, 188, 199, 228, 254, 263, 275, 281, 292, 303, 312, 323, 331, 343, 380, 386, 391, 403, 408, 427, 435, 442, 471, 483, 495, 508, 538, 772, 833, 854, 890, 897, 917, 942]', '34 in 5.3.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '11 in 5.4.txt: [7, 245, 340, 364, 384, 401, 425, 427, 698, 781, 863]', '29 in 5.5.txt: [12, 31, 129, 208, 253, 260, 281, 286, 314, 328, 349, 366, 373, 401, 405, 411, 595, 716, 736, 751, 905, 960, 1186, 1205, 1241, 1257, 1423, 1460, 1511]', '18 in 5.6.txt: [83, 150, 169, 178, 216, 230, 239, 257, 289, 323, 351, 423, 443, 470, 479, 492, 509, 638]', '9 in 5.7.txt: [253, 265, 275, 305, 320, 340, 454, 703, 884]', '18 in 5.8.txt: [97, 189, 244, 255, 267, 276, 296, 315, 325, 369, 376, 618, 626, 704, 756, 833, 888, 901]', '54 in 5.9.txt: [2, 5, 67, 93, 104, 207, 216, 257, 262, 269, 280, 389, 413, 420, 429, 441, 447, 467, 506, 518, 534, 535, 546, 547, 552, 563, 614, 642, 646, 772, 788, 796, 833, 839, 860, 868, 938, 951, 978, 991, 1006, 1026, 1036, 1046, 1069, 1080, 1091, 1114, 1138, 1201, 1214, 1236, 1266, 1418]', '3 in 6.1.txt: [172, 303, 311]', '23 in 6.10.txt: [85, 96, 104, 182, 192, 220, 245, 259, 266, 276, 333, 347, 364, 372, 401, 411, 417, 438, 597, 632, 644, 671, 681]', '12 in 6.11.txt: [192, 216, 266, 305, 373, 483, 557, 596, 620, 631, 639, 852]', '20 in 6.12.txt: [0, 8, 62, 81, 166, 199, 205, 232, 241, 254, 275, 276, 291, 304, 345, 431, 443, 579, 592, 647]', '26 in 6.13.txt: [35, 73, 159, 167, 193, 204, 231, 251, 265, 278, 285, 303, 313, 325, 345, 422, 435, 476, 482, 536, 582, 638, 654, 715, 742, 785]', '3 in 6.14.txt: [175, 197, 210]', '18 in 6.15.txt: [83, 134, 192, 215, 230, 237, 243, 254, 262, 384, 405, 424, 567, 599, 608, 620, 715, 761]', '2 in 6.16.txt: [342, 750]', '37 in 6.17.txt: [0, 4, 59, 80, 133, 152, 168, 183, 190, 248, 266, 277, 292, 303, 319, 335, 342, 411, 558, 565, 584, 589, 603, 618, 634, 646, 657, 670, 674, 693, 700, 705, 712, 746, 765, 777, 816]', '6 in 6.18.txt: [53, 309, 383, 633, 637, 850]', '8 in 6.19.txt: [217, 238, 305, 353, 380, 391, 416, 444]', '9 in 6.2.txt: [104, 354, 365, 400, 415, 423, 443, 579, 645]', '2 in 6.20.txt: [237, 382]', '5 in 6.21.txt: [779, 792, 806, 858, 932]', '3 in 6.22.txt: [61, 282, 912]', '17 in 6.23.txt: [36, 207, 215, 262, 280, 299, 305, 625, 627, 651, 667, 686, 738, 745, 766, 848, 1000]', '4 in 6.24.txt: [226, 351, 373, 503]', '34 in 6.25.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '15 in 6.3.txt: [200, 206, 226, 242, 401, 411, 425, 475, 479, 483, 504, 506, 566, 578, 777]', '7 in 6.4.txt: [157, 173, 186, 212, 231, 474, 591]', '2 in 6.5.txt: [541, 850]', '31 in 6.6.txt: [126, 134, 251, 295, 305, 311, 319, 323, 334, 348, 359, 379, 396, 409, 439, 451, 469, 511, 528, 834, 843, 852, 1003, 1017, 1083, 1109, 1133, 1140, 1421, 1517, 1536]', '5 in 6.7.txt: [293, 583, 807, 864, 950]', '4 in 6.8.txt: [212, 267, 682, 692]', '28 in 6.9.txt: [0, 2, 27, 58, 77, 90, 115, 130, 151, 164, 176, 185, 198, 212, 218, 229, 248, 263, 289, 298, 307, 309, 334, 418, 451, 457, 515, 557]', '34 in 7.1.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '9 in 7.10.txt: [678, 781, 795, 821, 853, 863, 872, 988, 1058]', '4 in 7.11.txt: [42, 196, 258, 671]', '23 in 7.12.txt: [1, 3, 56, 74, 163, 175, 207, 214, 263, 275, 375, 426, 517, 564, 573, 596, 640, 687, 732, 744, 788, 839, 884]', '19 in 7.13.txt: [34, 95, 222, 226, 244, 253, 257, 288, 299, 327, 341, 348, 470, 613, 627, 705, 901, 921, 1039]', '9 in 7.14.txt: [39, 228, 243, 277, 457, 467, 528, 575, 598]', '3 in 7.15.txt: [398, 654, 723]', '12 in 7.16.txt: [93, 254, 268, 383, 459, 840, 941, 1148, 1304, 1306, 1323, 1326]', '20 in 7.17.txt: [0, 2, 40, 63, 169, 170, 199, 208, 233, 245, 264, 279, 297, 364, 476, 499, 566, 607, 619, 664]', '3 in 7.18.txt: [376, 584, 588]', '3 in 7.19.txt: [261, 268, 845]', '4 in 7.2.txt: [254, 344, 582, 717]', '10 in 7.20.txt: [103, 233, 319, 356, 368, 392, 421, 559, 778, 844]', '3 in 7.21.txt: [378, 774, 1298]', '1 in 7.22.txt: [42]', '16 in 7.23.txt: [69, 124, 202, 234, 260, 304, 370, 401, 424, 434, 759, 878, 885, 921, 1051, 1060]', '26 in 7.24.txt: [40, 75, 149, 164, 179, 186, 202, 217, 235, 259, 267, 273, 288, 354, 361, 422, 471, 475, 480, 481, 497, 498, 505, 515, 544, 618]', '4 in 7.25.txt: [254, 344, 582, 717]', '9 in 7.3.txt: [39, 98, 196, 242, 244, 262, 279, 575, 602]', '2 in 7.4.txt: [1225, 1243]', '20 in 7.5.txt: [241, 281, 291, 295, 315, 330, 346, 356, 431, 437, 547, 559, 588, 657, 831, 843, 860, 1096, 1365, 1464]', '25 in 7.6.txt: [145, 217, 296, 342, 394, 449, 626, 642, 658, 676, 689, 701, 724, 833, 900, 978, 1059, 1071, 1227, 1323, 1329, 1358, 1381, 1417, 1469]', '48 in 7.7.txt: [1, 3, 8, 68, 86, 185, 196, 226, 247, 254, 291, 314, 332, 358, 374, 384, 397, 449, 456, 461, 474, 476, 488, 492, 509, 515, 531, 537, 553, 572, 600, 647, 656, 692, 726, 739, 761, 808, 835, 859, 885, 893, 907, 924, 954, 984, 1019, 1029]', '26 in 7.8.txt: [12, 102, 125, 148, 163, 175, 185, 194, 205, 213, 250, 312, 325, 341, 374, 380, 393, 404, 413, 420, 435, 481, 701, 710, 724, 926]']\n",
            "hhomer -> hhomer; homer 1978 total occurances: ['17 in 3.1.txt: [9, 100, 279, 305, 316, 327, 344, 350, 360, 385, 542, 550, 560, 688, 1202, 1311, 1703]', '22 in 3.10.txt: [83, 88, 97, 112, 272, 289, 292, 303, 324, 340, 385, 394, 432, 436, 444, 481, 489, 893, 904, 1033, 1072, 1234]', '28 in 3.11.txt: [10, 122, 200, 242, 271, 324, 364, 376, 387, 404, 406, 479, 494, 591, 660, 674, 690, 702, 704, 756, 767, 778, 807, 822, 951, 975, 988, 1060]', '36 in 3.12.txt: [6, 113, 264, 275, 290, 300, 308, 324, 327, 356, 381, 393, 411, 430, 433, 449, 451, 466, 488, 491, 500, 515, 537, 552, 558, 643, 670, 680, 704, 717, 749, 764, 795, 946, 956, 991]', '8 in 3.13.txt: [172, 225, 324, 329, 340, 506, 591, 626]', '25 in 3.14.txt: [36, 81, 172, 191, 199, 207, 218, 238, 248, 262, 273, 292, 302, 317, 335, 350, 486, 515, 532, 695, 766, 914, 933, 954, 985]', '23 in 3.15.txt: [0, 5, 55, 98, 104, 120, 161, 249, 285, 297, 333, 337, 350, 364, 383, 394, 528, 545, 561, 596, 615, 707, 775]', '16 in 3.16.txt: [89, 92, 118, 280, 347, 400, 424, 427, 433, 444, 498, 514, 527, 940, 967, 990]', '23 in 3.17.txt: [0, 2, 79, 106, 169, 247, 371, 478, 495, 509, 521, 527, 776, 877, 896, 1001, 1037, 1155, 1218, 1342, 1361, 1402, 1416]', '10 in 3.19.txt: [41, 50, 228, 250, 563, 656, 775, 924, 1150, 1206]', '5 in 3.2.txt: [36, 241, 282, 890, 1382]', '65 in 3.20.txt: [1, 3, 8, 82, 100, 107, 118, 128, 198, 222, 232, 292, 298, 319, 327, 344, 359, 374, 383, 395, 415, 418, 430, 441, 451, 461, 477, 503, 510, 517, 524, 556, 577, 598, 609, 641, 646, 671, 705, 793, 798, 1065, 1096, 1109, 1158, 1215, 1252, 1261, 1274, 1313, 1354, 1367, 1405, 1418, 1538, 1580, 1588, 1656, 1698, 1715, 1729, 1763, 1770, 1786, 1807]', '3 in 3.21.txt: [261, 308, 824]', '12 in 3.22.txt: [95, 238, 322, 334, 354, 372, 567, 584, 609, 618, 630, 742]', '13 in 3.23.txt: [143, 361, 376, 388, 409, 501, 505, 534, 804, 856, 873, 923, 960]', '24 in 3.24.txt: [93, 106, 116, 168, 221, 230, 249, 261, 274, 287, 295, 300, 337, 359, 440, 473, 692, 714, 760, 813, 830, 925, 993, 1112]', '13 in 3.3.txt: [73, 97, 216, 222, 247, 254, 268, 548, 743, 817, 820, 866, 874]', '3 in 3.4.txt: [320, 411, 836]', '30 in 3.5.txt: [0, 2, 63, 82, 97, 155, 181, 217, 237, 248, 254, 266, 288, 299, 305, 318, 321, 333, 341, 353, 536, 543, 646, 718, 767, 814, 848, 992, 995, 1018]', '2 in 3.6.txt: [54, 722]', '29 in 3.7.txt: [80, 106, 127, 140, 281, 288, 345, 383, 402, 420, 427, 438, 463, 478, 485, 493, 501, 682, 849, 874, 901, 977, 1036, 1061, 1076, 1090, 1111, 1124, 1308]', '28 in 3.8.txt: [40, 49, 88, 112, 120, 209, 226, 237, 257, 263, 295, 308, 331, 339, 347, 501, 559, 581, 592, 601, 646, 672, 740, 791, 888, 895, 999, 1011]', '27 in 3.9.txt: [74, 88, 101, 104, 183, 197, 221, 253, 267, 277, 294, 301, 400, 413, 509, 542, 551, 584, 617, 628, 634, 691, 891, 905, 915, 934, 964]', '6 in 4.1.txt: [123, 142, 205, 210, 294, 381]', '12 in 4.10.txt: [226, 240, 323, 361, 366, 464, 489, 519, 529, 1097, 1127, 1137]', '27 in 4.11.txt: [0, 4, 56, 77, 88, 128, 164, 173, 188, 199, 266, 276, 320, 325, 336, 385, 400, 414, 433, 450, 472, 490, 502, 512, 520, 537, 566]', '9 in 4.12.txt: [269, 371, 391, 402, 602, 673, 694, 708, 1023]', '9 in 4.13.txt: [134, 222, 257, 299, 320, 411, 483, 515, 653]', '21 in 4.14.txt: [79, 93, 172, 211, 213, 230, 243, 249, 497, 519, 562, 572, 588, 607, 627, 632, 724, 761, 791, 810, 845]', '3 in 4.15.txt: [364, 368, 603]', '13 in 4.16.txt: [82, 218, 231, 255, 270, 275, 312, 411, 421, 491, 506, 519, 596]', '24 in 4.17.txt: [82, 221, 245, 265, 276, 282, 286, 294, 304, 333, 341, 357, 365, 432, 437, 441, 448, 618, 697, 782, 874, 876, 1010, 1035]', '44 in 4.18.txt: [72, 82, 87, 96, 105, 182, 199, 212, 225, 243, 252, 267, 276, 280, 297, 302, 314, 448, 510, 514, 521, 524, 533, 548, 551, 581, 605, 614, 617, 625, 643, 655, 660, 672, 691, 701, 719, 726, 739, 769, 787, 801, 826, 917]', '9 in 4.19.txt: [90, 136, 262, 272, 283, 295, 302, 603, 614]', '21 in 4.2.txt: [98, 228, 261, 294, 366, 370, 379, 384, 390, 417, 435, 443, 458, 465, 493, 527, 549, 789, 1034, 1075, 1549]', '2 in 4.20.txt: [710, 713]', '3 in 4.21.txt: [100, 513, 638]', '4 in 4.22.txt: [139, 226, 557, 1245]', '36 in 4.3.txt: [0, 2, 4, 65, 84, 134, 147, 180, 222, 230, 244, 249, 252, 272, 281, 295, 326, 332, 342, 348, 362, 383, 434, 447, 456, 474, 484, 640, 654, 685, 731, 738, 778, 811, 852, 887]', '11 in 4.4.txt: [43, 88, 186, 225, 233, 370, 382, 389, 396, 427, 475]', '33 in 4.5.txt: [84, 92, 128, 146, 166, 201, 220, 237, 250, 262, 296, 301, 315, 342, 365, 375, 389, 392, 402, 409, 430, 500, 506, 599, 643, 652, 664, 708, 717, 732, 756, 764, 935]', '20 in 4.6.txt: [71, 78, 93, 119, 135, 168, 181, 187, 212, 223, 241, 251, 261, 276, 278, 297, 309, 320, 524, 667]', '7 in 4.7.txt: [55, 154, 160, 171, 218, 222, 427]', '11 in 4.8.txt: [115, 159, 184, 193, 209, 235, 238, 354, 428, 437, 493]', '31 in 4.9.txt: [9, 84, 102, 131, 173, 182, 195, 213, 216, 225, 254, 271, 298, 299, 309, 324, 338, 349, 377, 396, 468, 550, 566, 592, 602, 656, 731, 934, 997, 1056, 1168]', '42 in 5.1.txt: [0, 4, 10, 89, 115, 154, 159, 211, 267, 271, 287, 310, 342, 364, 367, 378, 417, 427, 448, 472, 519, 536, 541, 578, 611, 884, 910, 924, 1045, 1057, 1150, 1168, 1206, 1248, 1269, 1291, 1312, 1476, 1487, 1510, 1534, 1571]', '15 in 5.10.txt: [113, 239, 255, 348, 356, 379, 388, 405, 511, 647, 728, 756, 805, 862, 922]', '25 in 5.11.txt: [0, 2, 54, 85, 91, 105, 129, 229, 245, 267, 279, 296, 314, 334, 470, 573, 581, 599, 622, 752, 761, 787, 791, 797, 820]', '4 in 5.12.txt: [410, 481, 706, 815]', '31 in 5.13.txt: [0, 2, 60, 79, 104, 193, 201, 216, 236, 248, 289, 309, 316, 332, 344, 357, 490, 498, 652, 733, 739, 752, 843, 905, 927, 1037, 1066, 1116, 1214, 1222, 1226]', '3 in 5.14.txt: [744, 908, 1007]', '47 in 5.15.txt: [2, 5, 86, 105, 202, 215, 223, 231, 248, 270, 273, 287, 295, 324, 346, 365, 396, 415, 433, 446, 456, 467, 470, 497, 519, 523, 606, 615, 643, 718, 728, 754, 764, 774, 792, 801, 806, 845, 848, 871, 903, 923, 1006, 1035, 1071, 1075, 1118]', '34 in 5.16.txt: [0, 3, 54, 77, 89, 171, 184, 189, 204, 209, 214, 246, 250, 285, 298, 310, 317, 334, 343, 382, 395, 502, 551, 566, 584, 657, 679, 717, 810, 835, 839, 881, 897, 924]', '21 in 5.17.txt: [90, 107, 111, 300, 316, 324, 341, 361, 374, 391, 413, 424, 451, 637, 671, 731, 745, 754, 881, 921, 935]', '9 in 5.18.txt: [47, 225, 231, 245, 247, 271, 400, 532, 689]', '2 in 5.19.txt: [59, 385]', '40 in 5.2.txt: [0, 3, 52, 72, 83, 91, 101, 214, 243, 251, 262, 283, 301, 314, 326, 350, 358, 370, 389, 399, 408, 424, 434, 450, 460, 472, 478, 489, 535, 570, 579, 588, 625, 644, 663, 731, 741, 789, 802, 842]', '17 in 5.20.txt: [365, 374, 391, 406, 410, 490, 533, 536, 724, 741, 777, 793, 802, 931, 969, 977, 984]', '5 in 5.21.txt: [214, 257, 284, 533, 867]', '35 in 5.22.txt: [81, 112, 188, 199, 228, 254, 263, 275, 281, 292, 303, 312, 323, 331, 343, 380, 386, 391, 403, 408, 427, 435, 442, 471, 483, 495, 508, 538, 772, 833, 854, 890, 897, 917, 942]', '34 in 5.3.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '11 in 5.4.txt: [7, 245, 340, 364, 384, 401, 425, 427, 698, 781, 863]', '29 in 5.5.txt: [12, 31, 129, 208, 253, 260, 281, 286, 314, 328, 349, 366, 373, 401, 405, 411, 595, 716, 736, 751, 905, 960, 1186, 1205, 1241, 1257, 1423, 1460, 1511]', '18 in 5.6.txt: [83, 150, 169, 178, 216, 230, 239, 257, 289, 323, 351, 423, 443, 470, 479, 492, 509, 638]', '9 in 5.7.txt: [253, 265, 275, 305, 320, 340, 454, 703, 884]', '18 in 5.8.txt: [97, 189, 244, 255, 267, 276, 296, 315, 325, 369, 376, 618, 626, 704, 756, 833, 888, 901]', '54 in 5.9.txt: [2, 5, 67, 93, 104, 207, 216, 257, 262, 269, 280, 389, 413, 420, 429, 441, 447, 467, 506, 518, 534, 535, 546, 547, 552, 563, 614, 642, 646, 772, 788, 796, 833, 839, 860, 868, 938, 951, 978, 991, 1006, 1026, 1036, 1046, 1069, 1080, 1091, 1114, 1138, 1201, 1214, 1236, 1266, 1418]', '3 in 6.1.txt: [172, 303, 311]', '23 in 6.10.txt: [85, 96, 104, 182, 192, 220, 245, 259, 266, 276, 333, 347, 364, 372, 401, 411, 417, 438, 597, 632, 644, 671, 681]', '12 in 6.11.txt: [192, 216, 266, 305, 373, 483, 557, 596, 620, 631, 639, 852]', '20 in 6.12.txt: [0, 8, 62, 81, 166, 199, 205, 232, 241, 254, 275, 276, 291, 304, 345, 431, 443, 579, 592, 647]', '26 in 6.13.txt: [35, 73, 159, 167, 193, 204, 231, 251, 265, 278, 285, 303, 313, 325, 345, 422, 435, 476, 482, 536, 582, 638, 654, 715, 742, 785]', '3 in 6.14.txt: [175, 197, 210]', '18 in 6.15.txt: [83, 134, 192, 215, 230, 237, 243, 254, 262, 384, 405, 424, 567, 599, 608, 620, 715, 761]', '2 in 6.16.txt: [342, 750]', '37 in 6.17.txt: [0, 4, 59, 80, 133, 152, 168, 183, 190, 248, 266, 277, 292, 303, 319, 335, 342, 411, 558, 565, 584, 589, 603, 618, 634, 646, 657, 670, 674, 693, 700, 705, 712, 746, 765, 777, 816]', '6 in 6.18.txt: [53, 309, 383, 633, 637, 850]', '8 in 6.19.txt: [217, 238, 305, 353, 380, 391, 416, 444]', '9 in 6.2.txt: [104, 354, 365, 400, 415, 423, 443, 579, 645]', '2 in 6.20.txt: [237, 382]', '5 in 6.21.txt: [779, 792, 806, 858, 932]', '3 in 6.22.txt: [61, 282, 912]', '17 in 6.23.txt: [36, 207, 215, 262, 280, 299, 305, 625, 627, 651, 667, 686, 738, 745, 766, 848, 1000]', '4 in 6.24.txt: [226, 351, 373, 503]', '34 in 6.25.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '15 in 6.3.txt: [200, 206, 226, 242, 401, 411, 425, 475, 479, 483, 504, 506, 566, 578, 777]', '7 in 6.4.txt: [157, 173, 186, 212, 231, 474, 591]', '2 in 6.5.txt: [541, 850]', '31 in 6.6.txt: [126, 134, 251, 295, 305, 311, 319, 323, 334, 348, 359, 379, 396, 409, 439, 451, 469, 511, 528, 834, 843, 852, 1003, 1017, 1083, 1109, 1133, 1140, 1421, 1517, 1536]', '5 in 6.7.txt: [293, 583, 807, 864, 950]', '4 in 6.8.txt: [212, 267, 682, 692]', '28 in 6.9.txt: [0, 2, 27, 58, 77, 90, 115, 130, 151, 164, 176, 185, 198, 212, 218, 229, 248, 263, 289, 298, 307, 309, 334, 418, 451, 457, 515, 557]', '34 in 7.1.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '9 in 7.10.txt: [678, 781, 795, 821, 853, 863, 872, 988, 1058]', '4 in 7.11.txt: [42, 196, 258, 671]', '23 in 7.12.txt: [1, 3, 56, 74, 163, 175, 207, 214, 263, 275, 375, 426, 517, 564, 573, 596, 640, 687, 732, 744, 788, 839, 884]', '19 in 7.13.txt: [34, 95, 222, 226, 244, 253, 257, 288, 299, 327, 341, 348, 470, 613, 627, 705, 901, 921, 1039]', '9 in 7.14.txt: [39, 228, 243, 277, 457, 467, 528, 575, 598]', '3 in 7.15.txt: [398, 654, 723]', '12 in 7.16.txt: [93, 254, 268, 383, 459, 840, 941, 1148, 1304, 1306, 1323, 1326]', '20 in 7.17.txt: [0, 2, 40, 63, 169, 170, 199, 208, 233, 245, 264, 279, 297, 364, 476, 499, 566, 607, 619, 664]', '3 in 7.18.txt: [376, 584, 588]', '3 in 7.19.txt: [261, 268, 845]', '4 in 7.2.txt: [254, 344, 582, 717]', '10 in 7.20.txt: [103, 233, 319, 356, 368, 392, 421, 559, 778, 844]', '3 in 7.21.txt: [378, 774, 1298]', '1 in 7.22.txt: [42]', '16 in 7.23.txt: [69, 124, 202, 234, 260, 304, 370, 401, 424, 434, 759, 878, 885, 921, 1051, 1060]', '26 in 7.24.txt: [40, 75, 149, 164, 179, 186, 202, 217, 235, 259, 267, 273, 288, 354, 361, 422, 471, 475, 480, 481, 497, 498, 505, 515, 544, 618]', '4 in 7.25.txt: [254, 344, 582, 717]', '9 in 7.3.txt: [39, 98, 196, 242, 244, 262, 279, 575, 602]', '2 in 7.4.txt: [1225, 1243]', '20 in 7.5.txt: [241, 281, 291, 295, 315, 330, 346, 356, 431, 437, 547, 559, 588, 657, 831, 843, 860, 1096, 1365, 1464]', '25 in 7.6.txt: [145, 217, 296, 342, 394, 449, 626, 642, 658, 676, 689, 701, 724, 833, 900, 978, 1059, 1071, 1227, 1323, 1329, 1358, 1381, 1417, 1469]', '48 in 7.7.txt: [1, 3, 8, 68, 86, 185, 196, 226, 247, 254, 291, 314, 332, 358, 374, 384, 397, 449, 456, 461, 474, 476, 488, 492, 509, 515, 531, 537, 553, 572, 600, 647, 656, 692, 726, 739, 761, 808, 835, 859, 885, 893, 907, 924, 954, 984, 1019, 1029]', '26 in 7.8.txt: [12, 102, 125, 148, 163, 175, 185, 194, 205, 213, 250, 312, 325, 341, 374, 380, 393, 404, 413, 420, 435, 481, 701, 710, 724, 926]']\n",
            "hmoer -> hmoer; homer 1978 total occurances: ['17 in 3.1.txt: [9, 100, 279, 305, 316, 327, 344, 350, 360, 385, 542, 550, 560, 688, 1202, 1311, 1703]', '22 in 3.10.txt: [83, 88, 97, 112, 272, 289, 292, 303, 324, 340, 385, 394, 432, 436, 444, 481, 489, 893, 904, 1033, 1072, 1234]', '28 in 3.11.txt: [10, 122, 200, 242, 271, 324, 364, 376, 387, 404, 406, 479, 494, 591, 660, 674, 690, 702, 704, 756, 767, 778, 807, 822, 951, 975, 988, 1060]', '36 in 3.12.txt: [6, 113, 264, 275, 290, 300, 308, 324, 327, 356, 381, 393, 411, 430, 433, 449, 451, 466, 488, 491, 500, 515, 537, 552, 558, 643, 670, 680, 704, 717, 749, 764, 795, 946, 956, 991]', '8 in 3.13.txt: [172, 225, 324, 329, 340, 506, 591, 626]', '25 in 3.14.txt: [36, 81, 172, 191, 199, 207, 218, 238, 248, 262, 273, 292, 302, 317, 335, 350, 486, 515, 532, 695, 766, 914, 933, 954, 985]', '23 in 3.15.txt: [0, 5, 55, 98, 104, 120, 161, 249, 285, 297, 333, 337, 350, 364, 383, 394, 528, 545, 561, 596, 615, 707, 775]', '16 in 3.16.txt: [89, 92, 118, 280, 347, 400, 424, 427, 433, 444, 498, 514, 527, 940, 967, 990]', '23 in 3.17.txt: [0, 2, 79, 106, 169, 247, 371, 478, 495, 509, 521, 527, 776, 877, 896, 1001, 1037, 1155, 1218, 1342, 1361, 1402, 1416]', '10 in 3.19.txt: [41, 50, 228, 250, 563, 656, 775, 924, 1150, 1206]', '5 in 3.2.txt: [36, 241, 282, 890, 1382]', '65 in 3.20.txt: [1, 3, 8, 82, 100, 107, 118, 128, 198, 222, 232, 292, 298, 319, 327, 344, 359, 374, 383, 395, 415, 418, 430, 441, 451, 461, 477, 503, 510, 517, 524, 556, 577, 598, 609, 641, 646, 671, 705, 793, 798, 1065, 1096, 1109, 1158, 1215, 1252, 1261, 1274, 1313, 1354, 1367, 1405, 1418, 1538, 1580, 1588, 1656, 1698, 1715, 1729, 1763, 1770, 1786, 1807]', '3 in 3.21.txt: [261, 308, 824]', '12 in 3.22.txt: [95, 238, 322, 334, 354, 372, 567, 584, 609, 618, 630, 742]', '13 in 3.23.txt: [143, 361, 376, 388, 409, 501, 505, 534, 804, 856, 873, 923, 960]', '24 in 3.24.txt: [93, 106, 116, 168, 221, 230, 249, 261, 274, 287, 295, 300, 337, 359, 440, 473, 692, 714, 760, 813, 830, 925, 993, 1112]', '13 in 3.3.txt: [73, 97, 216, 222, 247, 254, 268, 548, 743, 817, 820, 866, 874]', '3 in 3.4.txt: [320, 411, 836]', '30 in 3.5.txt: [0, 2, 63, 82, 97, 155, 181, 217, 237, 248, 254, 266, 288, 299, 305, 318, 321, 333, 341, 353, 536, 543, 646, 718, 767, 814, 848, 992, 995, 1018]', '2 in 3.6.txt: [54, 722]', '29 in 3.7.txt: [80, 106, 127, 140, 281, 288, 345, 383, 402, 420, 427, 438, 463, 478, 485, 493, 501, 682, 849, 874, 901, 977, 1036, 1061, 1076, 1090, 1111, 1124, 1308]', '28 in 3.8.txt: [40, 49, 88, 112, 120, 209, 226, 237, 257, 263, 295, 308, 331, 339, 347, 501, 559, 581, 592, 601, 646, 672, 740, 791, 888, 895, 999, 1011]', '27 in 3.9.txt: [74, 88, 101, 104, 183, 197, 221, 253, 267, 277, 294, 301, 400, 413, 509, 542, 551, 584, 617, 628, 634, 691, 891, 905, 915, 934, 964]', '6 in 4.1.txt: [123, 142, 205, 210, 294, 381]', '12 in 4.10.txt: [226, 240, 323, 361, 366, 464, 489, 519, 529, 1097, 1127, 1137]', '27 in 4.11.txt: [0, 4, 56, 77, 88, 128, 164, 173, 188, 199, 266, 276, 320, 325, 336, 385, 400, 414, 433, 450, 472, 490, 502, 512, 520, 537, 566]', '9 in 4.12.txt: [269, 371, 391, 402, 602, 673, 694, 708, 1023]', '9 in 4.13.txt: [134, 222, 257, 299, 320, 411, 483, 515, 653]', '21 in 4.14.txt: [79, 93, 172, 211, 213, 230, 243, 249, 497, 519, 562, 572, 588, 607, 627, 632, 724, 761, 791, 810, 845]', '3 in 4.15.txt: [364, 368, 603]', '13 in 4.16.txt: [82, 218, 231, 255, 270, 275, 312, 411, 421, 491, 506, 519, 596]', '24 in 4.17.txt: [82, 221, 245, 265, 276, 282, 286, 294, 304, 333, 341, 357, 365, 432, 437, 441, 448, 618, 697, 782, 874, 876, 1010, 1035]', '44 in 4.18.txt: [72, 82, 87, 96, 105, 182, 199, 212, 225, 243, 252, 267, 276, 280, 297, 302, 314, 448, 510, 514, 521, 524, 533, 548, 551, 581, 605, 614, 617, 625, 643, 655, 660, 672, 691, 701, 719, 726, 739, 769, 787, 801, 826, 917]', '9 in 4.19.txt: [90, 136, 262, 272, 283, 295, 302, 603, 614]', '21 in 4.2.txt: [98, 228, 261, 294, 366, 370, 379, 384, 390, 417, 435, 443, 458, 465, 493, 527, 549, 789, 1034, 1075, 1549]', '2 in 4.20.txt: [710, 713]', '3 in 4.21.txt: [100, 513, 638]', '4 in 4.22.txt: [139, 226, 557, 1245]', '36 in 4.3.txt: [0, 2, 4, 65, 84, 134, 147, 180, 222, 230, 244, 249, 252, 272, 281, 295, 326, 332, 342, 348, 362, 383, 434, 447, 456, 474, 484, 640, 654, 685, 731, 738, 778, 811, 852, 887]', '11 in 4.4.txt: [43, 88, 186, 225, 233, 370, 382, 389, 396, 427, 475]', '33 in 4.5.txt: [84, 92, 128, 146, 166, 201, 220, 237, 250, 262, 296, 301, 315, 342, 365, 375, 389, 392, 402, 409, 430, 500, 506, 599, 643, 652, 664, 708, 717, 732, 756, 764, 935]', '20 in 4.6.txt: [71, 78, 93, 119, 135, 168, 181, 187, 212, 223, 241, 251, 261, 276, 278, 297, 309, 320, 524, 667]', '7 in 4.7.txt: [55, 154, 160, 171, 218, 222, 427]', '11 in 4.8.txt: [115, 159, 184, 193, 209, 235, 238, 354, 428, 437, 493]', '31 in 4.9.txt: [9, 84, 102, 131, 173, 182, 195, 213, 216, 225, 254, 271, 298, 299, 309, 324, 338, 349, 377, 396, 468, 550, 566, 592, 602, 656, 731, 934, 997, 1056, 1168]', '42 in 5.1.txt: [0, 4, 10, 89, 115, 154, 159, 211, 267, 271, 287, 310, 342, 364, 367, 378, 417, 427, 448, 472, 519, 536, 541, 578, 611, 884, 910, 924, 1045, 1057, 1150, 1168, 1206, 1248, 1269, 1291, 1312, 1476, 1487, 1510, 1534, 1571]', '15 in 5.10.txt: [113, 239, 255, 348, 356, 379, 388, 405, 511, 647, 728, 756, 805, 862, 922]', '25 in 5.11.txt: [0, 2, 54, 85, 91, 105, 129, 229, 245, 267, 279, 296, 314, 334, 470, 573, 581, 599, 622, 752, 761, 787, 791, 797, 820]', '4 in 5.12.txt: [410, 481, 706, 815]', '31 in 5.13.txt: [0, 2, 60, 79, 104, 193, 201, 216, 236, 248, 289, 309, 316, 332, 344, 357, 490, 498, 652, 733, 739, 752, 843, 905, 927, 1037, 1066, 1116, 1214, 1222, 1226]', '3 in 5.14.txt: [744, 908, 1007]', '47 in 5.15.txt: [2, 5, 86, 105, 202, 215, 223, 231, 248, 270, 273, 287, 295, 324, 346, 365, 396, 415, 433, 446, 456, 467, 470, 497, 519, 523, 606, 615, 643, 718, 728, 754, 764, 774, 792, 801, 806, 845, 848, 871, 903, 923, 1006, 1035, 1071, 1075, 1118]', '34 in 5.16.txt: [0, 3, 54, 77, 89, 171, 184, 189, 204, 209, 214, 246, 250, 285, 298, 310, 317, 334, 343, 382, 395, 502, 551, 566, 584, 657, 679, 717, 810, 835, 839, 881, 897, 924]', '21 in 5.17.txt: [90, 107, 111, 300, 316, 324, 341, 361, 374, 391, 413, 424, 451, 637, 671, 731, 745, 754, 881, 921, 935]', '9 in 5.18.txt: [47, 225, 231, 245, 247, 271, 400, 532, 689]', '2 in 5.19.txt: [59, 385]', '40 in 5.2.txt: [0, 3, 52, 72, 83, 91, 101, 214, 243, 251, 262, 283, 301, 314, 326, 350, 358, 370, 389, 399, 408, 424, 434, 450, 460, 472, 478, 489, 535, 570, 579, 588, 625, 644, 663, 731, 741, 789, 802, 842]', '17 in 5.20.txt: [365, 374, 391, 406, 410, 490, 533, 536, 724, 741, 777, 793, 802, 931, 969, 977, 984]', '5 in 5.21.txt: [214, 257, 284, 533, 867]', '35 in 5.22.txt: [81, 112, 188, 199, 228, 254, 263, 275, 281, 292, 303, 312, 323, 331, 343, 380, 386, 391, 403, 408, 427, 435, 442, 471, 483, 495, 508, 538, 772, 833, 854, 890, 897, 917, 942]', '34 in 5.3.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '11 in 5.4.txt: [7, 245, 340, 364, 384, 401, 425, 427, 698, 781, 863]', '29 in 5.5.txt: [12, 31, 129, 208, 253, 260, 281, 286, 314, 328, 349, 366, 373, 401, 405, 411, 595, 716, 736, 751, 905, 960, 1186, 1205, 1241, 1257, 1423, 1460, 1511]', '18 in 5.6.txt: [83, 150, 169, 178, 216, 230, 239, 257, 289, 323, 351, 423, 443, 470, 479, 492, 509, 638]', '9 in 5.7.txt: [253, 265, 275, 305, 320, 340, 454, 703, 884]', '18 in 5.8.txt: [97, 189, 244, 255, 267, 276, 296, 315, 325, 369, 376, 618, 626, 704, 756, 833, 888, 901]', '54 in 5.9.txt: [2, 5, 67, 93, 104, 207, 216, 257, 262, 269, 280, 389, 413, 420, 429, 441, 447, 467, 506, 518, 534, 535, 546, 547, 552, 563, 614, 642, 646, 772, 788, 796, 833, 839, 860, 868, 938, 951, 978, 991, 1006, 1026, 1036, 1046, 1069, 1080, 1091, 1114, 1138, 1201, 1214, 1236, 1266, 1418]', '3 in 6.1.txt: [172, 303, 311]', '23 in 6.10.txt: [85, 96, 104, 182, 192, 220, 245, 259, 266, 276, 333, 347, 364, 372, 401, 411, 417, 438, 597, 632, 644, 671, 681]', '12 in 6.11.txt: [192, 216, 266, 305, 373, 483, 557, 596, 620, 631, 639, 852]', '20 in 6.12.txt: [0, 8, 62, 81, 166, 199, 205, 232, 241, 254, 275, 276, 291, 304, 345, 431, 443, 579, 592, 647]', '26 in 6.13.txt: [35, 73, 159, 167, 193, 204, 231, 251, 265, 278, 285, 303, 313, 325, 345, 422, 435, 476, 482, 536, 582, 638, 654, 715, 742, 785]', '3 in 6.14.txt: [175, 197, 210]', '18 in 6.15.txt: [83, 134, 192, 215, 230, 237, 243, 254, 262, 384, 405, 424, 567, 599, 608, 620, 715, 761]', '2 in 6.16.txt: [342, 750]', '37 in 6.17.txt: [0, 4, 59, 80, 133, 152, 168, 183, 190, 248, 266, 277, 292, 303, 319, 335, 342, 411, 558, 565, 584, 589, 603, 618, 634, 646, 657, 670, 674, 693, 700, 705, 712, 746, 765, 777, 816]', '6 in 6.18.txt: [53, 309, 383, 633, 637, 850]', '8 in 6.19.txt: [217, 238, 305, 353, 380, 391, 416, 444]', '9 in 6.2.txt: [104, 354, 365, 400, 415, 423, 443, 579, 645]', '2 in 6.20.txt: [237, 382]', '5 in 6.21.txt: [779, 792, 806, 858, 932]', '3 in 6.22.txt: [61, 282, 912]', '17 in 6.23.txt: [36, 207, 215, 262, 280, 299, 305, 625, 627, 651, 667, 686, 738, 745, 766, 848, 1000]', '4 in 6.24.txt: [226, 351, 373, 503]', '34 in 6.25.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '15 in 6.3.txt: [200, 206, 226, 242, 401, 411, 425, 475, 479, 483, 504, 506, 566, 578, 777]', '7 in 6.4.txt: [157, 173, 186, 212, 231, 474, 591]', '2 in 6.5.txt: [541, 850]', '31 in 6.6.txt: [126, 134, 251, 295, 305, 311, 319, 323, 334, 348, 359, 379, 396, 409, 439, 451, 469, 511, 528, 834, 843, 852, 1003, 1017, 1083, 1109, 1133, 1140, 1421, 1517, 1536]', '5 in 6.7.txt: [293, 583, 807, 864, 950]', '4 in 6.8.txt: [212, 267, 682, 692]', '28 in 6.9.txt: [0, 2, 27, 58, 77, 90, 115, 130, 151, 164, 176, 185, 198, 212, 218, 229, 248, 263, 289, 298, 307, 309, 334, 418, 451, 457, 515, 557]', '34 in 7.1.txt: [138, 304, 329, 344, 432, 442, 452, 462, 477, 624, 628, 642, 653, 664, 668, 689, 697, 714, 726, 737, 750, 752, 792, 1086, 1190, 1382, 1428, 1441, 1449, 1471, 1717, 1963, 1968, 2038]', '9 in 7.10.txt: [678, 781, 795, 821, 853, 863, 872, 988, 1058]', '4 in 7.11.txt: [42, 196, 258, 671]', '23 in 7.12.txt: [1, 3, 56, 74, 163, 175, 207, 214, 263, 275, 375, 426, 517, 564, 573, 596, 640, 687, 732, 744, 788, 839, 884]', '19 in 7.13.txt: [34, 95, 222, 226, 244, 253, 257, 288, 299, 327, 341, 348, 470, 613, 627, 705, 901, 921, 1039]', '9 in 7.14.txt: [39, 228, 243, 277, 457, 467, 528, 575, 598]', '3 in 7.15.txt: [398, 654, 723]', '12 in 7.16.txt: [93, 254, 268, 383, 459, 840, 941, 1148, 1304, 1306, 1323, 1326]', '20 in 7.17.txt: [0, 2, 40, 63, 169, 170, 199, 208, 233, 245, 264, 279, 297, 364, 476, 499, 566, 607, 619, 664]', '3 in 7.18.txt: [376, 584, 588]', '3 in 7.19.txt: [261, 268, 845]', '4 in 7.2.txt: [254, 344, 582, 717]', '10 in 7.20.txt: [103, 233, 319, 356, 368, 392, 421, 559, 778, 844]', '3 in 7.21.txt: [378, 774, 1298]', '1 in 7.22.txt: [42]', '16 in 7.23.txt: [69, 124, 202, 234, 260, 304, 370, 401, 424, 434, 759, 878, 885, 921, 1051, 1060]', '26 in 7.24.txt: [40, 75, 149, 164, 179, 186, 202, 217, 235, 259, 267, 273, 288, 354, 361, 422, 471, 475, 480, 481, 497, 498, 505, 515, 544, 618]', '4 in 7.25.txt: [254, 344, 582, 717]', '9 in 7.3.txt: [39, 98, 196, 242, 244, 262, 279, 575, 602]', '2 in 7.4.txt: [1225, 1243]', '20 in 7.5.txt: [241, 281, 291, 295, 315, 330, 346, 356, 431, 437, 547, 559, 588, 657, 831, 843, 860, 1096, 1365, 1464]', '25 in 7.6.txt: [145, 217, 296, 342, 394, 449, 626, 642, 658, 676, 689, 701, 724, 833, 900, 978, 1059, 1071, 1227, 1323, 1329, 1358, 1381, 1417, 1469]', '48 in 7.7.txt: [1, 3, 8, 68, 86, 185, 196, 226, 247, 254, 291, 314, 332, 358, 374, 384, 397, 449, 456, 461, 474, 476, 488, 492, 509, 515, 531, 537, 553, 572, 600, 647, 656, 692, 726, 739, 761, 808, 835, 859, 885, 893, 907, 924, 954, 984, 1019, 1029]', '26 in 7.8.txt: [12, 102, 125, 148, 163, 175, 185, 194, 205, 213, 250, 312, 325, 341, 374, 380, 393, 404, 413, 420, 435, 481, 701, 710, 724, 926]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print out most frequent words within the corpus"
      ],
      "metadata": {
        "id": "1tJzmR9xvFop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted([(k,v.total_occurances) for k, v in index.inverted_index.items()], key=lambda x: x[1], reverse=True)[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmH_ixZQtzma",
        "outputId": "d73fccd4-6222-4812-b1e4-32e2acae0ad9"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"'s\", 2725),\n",
              " ('homer', 1978),\n",
              " ('simpson', 1374),\n",
              " ('bart', 1231),\n",
              " ('show', 1083),\n",
              " ('lisa', 861),\n",
              " ('refer', 849),\n",
              " ('one', 751),\n",
              " ('marg', 660),\n",
              " ('burn', 632),\n",
              " ('season', 599),\n",
              " ('origin', 542),\n",
              " ('air', 540),\n",
              " ('film', 516),\n",
              " ('scene', 498),\n",
              " ('rate', 492),\n",
              " ('product', 442),\n",
              " ('anim', 433),\n",
              " ('appear', 425),\n",
              " ('direct', 393),\n",
              " ('fox', 391),\n",
              " ('written', 390),\n",
              " ('televis', 386),\n",
              " ('guest', 382),\n",
              " ('springfield', 377),\n",
              " ('name', 372),\n",
              " ('get', 367),\n",
              " ('famili', 366),\n",
              " ('seri', 366),\n",
              " ('recept', 353),\n",
              " ('first', 344),\n",
              " ('make', 343),\n",
              " ('time', 343),\n",
              " ('david', 335),\n",
              " ('plot', 335),\n",
              " ('song', 335),\n",
              " ('charact', 333),\n",
              " ('writer', 330),\n",
              " ('featur', 327),\n",
              " ('also', 322),\n",
              " ('critic', 321),\n",
              " ('use', 319),\n",
              " ('week', 314),\n",
              " ('cultur', 313),\n",
              " ('mr.', 309),\n",
              " ('said', 308),\n",
              " ('best', 307),\n",
              " ('star', 290),\n",
              " ('network', 288),\n",
              " ('call', 286),\n",
              " ('like', 275),\n",
              " ('end', 272),\n",
              " ('parodi', 269),\n",
              " ('american', 265),\n",
              " ('krusti', 263),\n",
              " ('gag', 258),\n",
              " ('dvd', 257),\n",
              " ('mr. burn', 250),\n",
              " ('state', 249),\n",
              " ('groen', 245),\n",
              " ('includ', 243),\n",
              " ('receiv', 241),\n",
              " ('two', 240),\n",
              " ('play', 239),\n",
              " ('part', 237),\n",
              " ('oakley', 232),\n",
              " ('mirkin', 229),\n",
              " ('voic', 228),\n",
              " ('couch', 219),\n",
              " ('book', 218),\n",
              " ('5', 215),\n",
              " ('new', 215),\n",
              " ('say', 215),\n",
              " ('produc', 214),\n",
              " ('tri', 213),\n",
              " ('work', 212),\n",
              " ('sever', 208),\n",
              " ('4', 202),\n",
              " ('guid', 202),\n",
              " ('want', 202),\n",
              " ('bill', 200),\n",
              " ('line', 194),\n",
              " ('review', 194),\n",
              " ('day', 193),\n",
              " ('matt', 192),\n",
              " ('music', 188),\n",
              " ('nielsen', 188),\n",
              " ('write', 188),\n",
              " ('3', 187),\n",
              " ('matt groen', 186),\n",
              " ('school', 185),\n",
              " ('see', 184),\n",
              " ('idea', 182),\n",
              " ('stori', 182),\n",
              " ('unit', 182),\n",
              " ('decid', 181),\n",
              " ('perform', 181),\n",
              " ('take', 181),\n",
              " ('jean', 179),\n",
              " ('love', 177)]"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test positional indexing"
      ],
      "metadata": {
        "id": "Kms5rGcflhG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# it's possible to find Gordie Howe using Boolean queries, even though he's not in the index\n",
        "index.proximity_search('Gordie', 'Howe', 1)"
      ],
      "metadata": {
        "id": "wld3Ax7Kk5K9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e79bea11-3f79-412e-d949-c579ac3182d7"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gordie -> gordi; Howe -> howe; "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'3.16.txt': [(147, 148),\n",
              "  (271, 272),\n",
              "  (461, 462),\n",
              "  (614, 615),\n",
              "  (1071, 1072),\n",
              "  (1087, 1088)]}"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# diacritics will be converted to ascii and matched\n",
        "index.proximity_search('üter', 'character', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5f6wUg29uq6",
        "outputId": "360adf7e-d0fd-495f-9a4d-5f15f47b1232"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üter -> uter; character -> charact; "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'5.5.txt': [(1044, 1043), (1044, 1045)]}"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}